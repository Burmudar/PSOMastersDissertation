\documentclass[11pt,a4paper]{book}
\usepackage{ujthesis,float,enumerate,amssymb,amsmath,algorithm,algpseudocode}
\usepackage{cite,graphicx,tikz,xcolor,appendix,hyperref}
\usepackage[acronym,toc]{glossaries}
\usetikzlibrary{plothandlers}
\usetikzlibrary{positioning}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{patterns}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{shapes.symbols}
\usetikzlibrary{shapes.misc}
\raggedbottom
\usepackage[nottoc]{tocbibind}
\linespread{1.2}
\dissertation
\coverFont{\large}
\setlength{\parskip}{0.5ex plus0.5ex minus0.2ex}
\setlength{\spaceLength}{7mm}
\approvedtitle{Optimising the Frequency Assignment Problem utilizing Particle Swarm Optimisation}
\student{William Bezuidenhout}
\degree{Magister Scientiae}
\field{Information Technology}
\faculty{Faculty of Science}
\supervisorName{Dr G.B. O'Reilly}
\submissionDate{May 2012}
%glossary definitions
\makeglossaries
\newacronym{FAP}{FAP}{frequency assignment problem}
\newacronym{gsm}{GSM}{general system for mobile communication}
\newacronym{SMS}{SMS}{short message service}
\newacronym{MMS}{MMS}{multimedia message service}
\newacronym{GPRS}{GPRS}{general packet radio system}
\newacronym{EDGE}{EDGE}{enhanced data global evolution}
\newacronym{HSCSD}{HSCSD}{high speed circuit switched data}
\newacronym{ISDN}{ISDN}{integrated service digital network}
\newacronym{DCS1800}{DCS1800}{digital cellular system}
\newacronym{TDMA}{TDMA}{time division multiple access}
\newacronym{SIR}{SIR}{signal-to-noise ratio}
\newacronym{UMTS}{UMTS}{universal mobile telecommunications system}
\newacronym{DS-CDMA}{DS-CDMA}{direct sequence collision detection multiple access}
\newacronym{WCDMA}{WCDMA}{wide band collision detection multiple access}
\newacronym{CDMA}{CDMA}{code division multiple access}
\newacronym{LTE}{LTE}{long term evolution}
\newacronym{WIMAX}{WiMAX}{worlwide interoperability for microwave access}
\newacronym{MS}{MS}{mobile station}
\newacronym{POS}{POS}{[point of sale}
\newacronym{SIM}{SIM}{subscriber identification module}
\newacronym{IMSI}{IMSI}{international mobile subscriber identity}
\newacronym{IMEI}{IMEI}{international mobile equipment identity}
\newacronym{BTS}{BTS}{base tranceiver stations}
\newacronym{MSC}{MSC}{mobile switching centre}
\newacronym{BSS}{BSS}{base station subsystem}
\newacronym{BSC}{BSC}{base station controller}
\newacronym{LA}{LA}{location area}
\newacronym{TRX}{TRX}{transceiver}
\newacronym{TDM}{TDM}{time division multiplexing}
\newacronym{FDM}{FDM}{frequency division multiplexing}
\newacronym{NSS}{NSS}{network switching subsystem}
\newacronym{VLR}{VLR}{visitor location register}
\newacronym{HLR}{HLR}{home location register}
\newacronym{PSTN}{PSTN}{public switching telephone network}
\newacronym{AUC}{AUC}{authentication centre}
\newacronym{EIR}{EIR}{equipment identity register}
\newacronym{SRES}{SRES}{signed response}
\newacronym{OMC}{OMC}{operations and management centre}
\newacronym{NMC}{NMC}{network management centre}
\newacronym{LAPDm}{LAPDm}{link access protocol D channel modified}
\newacronym{TCH}{TCH}{traffic channel}
\newacronym{BCH}{BCH}{broadcast channel}
\newacronym{CCCH}{CCCH}{common control channel}
\newacronym{DCCH}{DCCH}{dedicated control channel}
\newacronym{BCCH}{BCCH}{broadcast control channel}
\newacronym{FCCH}{FCCH}{frequency control channel}
\newacronym{SCH}{SCH}{sychronisation channel}
\newacronym{RACH}{RACH}{random access channel}
\newacronym{AGCH}{AGCH}{access grant channel}
\newacronym{PCH}{PCH}{paging channel}
\newacronym{NCH}{NCH}{notification channel}
\newacronym{D/ACCH}{D/ACCH}{dedicated/associated control channel}
\newacronym{SDCCH}{SDCCH}{stand-alone dedicated control channel}
\newacronym{SACCH}{SACCH}{slow associated control channel}
\newacronym{FACCH}{FACCH}{fast associated control channel}
\newacronym{CBCH}{CBCH}{cell broadcast control channel}
\newacronym{AFP}{AFP}{automatic frequency planning}
\newacronym{CAP}{CAP}{channel assignment problem}
\newacronym{FFA}{FFA}{fixed frequency allocation}
\newacronym{FCA}{FCA}{fixed channel allocation}
\newacronym{DFA}{DFA}{dynamic frequency allocation}
\newacronym{DCA}{DCA}{dynamic channel allocation}
\newacronym{QoS}{QoS}{quality of service}
\newacronym{SINR}{SINR}{signal to interference noise power ration}
\newacronym{BER}{BER}{bit error rate}
\newacronym{MO-FAP}{MO-FAP}{minimum-order frequency assignment problem}
\newacronym{MS-FAP}{MS-FAP}{minimum span frequency assignment problem}
\newacronym{MI-FAP}{MI-FAP}{minimum interference frequency assignment problem}
\newacronym{FS-FAP}{FS-FAP}{fixed spectrum frequency assignment problem}
\newacronym{EUCLID}{EUCLID}{EUropean Cooperation on the Long term in the Defense}
\newacronym{CELAR}{CELAR}{cenre d'electronique de l'armement}
\newacronym{COST}{COST}{COop\'{e}ration europ\'{e}ene dans le domaine de la recherche Scientifique et Technique}
\newacronym{WLAN}{WLAN}{wireless local area network}
\newacronym{AP}{AP}{access point}
\newacronym{SA}{SA}{simulated annealing}
\newacronym{AI}{AI}{artificial intelligence}
\newacronym{TS}{TS}{tabu search}
\newacronym{MTM}{MTM}{medium term memory}
\newacronym{LTM}{LTM}{long term memory}
\newacronym{STM}{STM}{short term memory}
\newacronym{HMT}{HMT}{heuristic manipulation technique}
\newacronym{GA}{GA}{genetic algorithm}
\newacronym{CGA}{CGA}{canical genetic algorithm}
\newacronym{PRNG}{PRNG}{pseudo random number generator}
\newacronym{QRNG}{QRNG}{quasi random number generator}
\newacronym{ACO}{ACO}{ant colony optimisation}
\newacronym{PSO}{PSO}{particle swarm optimisation}
\newacronym{ABC}{ABC}{artificial bee colony}
\newacronym{SACO}{SACO}{simple ant colony optimisation}
\newacronym{AS}{AS}{ant system}
\newacronym{ACS}{ACS}{ant colony system}
\newacronym{ANTS}{ANTS}{approximate non-deterministic tree search}
\newacronym{BCO}{BCO}{bee colony optimisation}
\newacronym{BSO}{BSO}{bee swarm optimisation}
\newacronym{VBA}{VBA}{virtual bee algorithm}
\newacronym{ARPSO}{ARPSO}{attract repulse particle swarm optimisation}
\newacronym{FEA}{FEA}{frequency exhaustive assignment}
\newacronym{MMAS}{MMAS}{min-max ant system}
\begin{document}
\frontmatter
\makecover
\tableofcontents
\listoffigures
\listofalgorithms
\listoftables
\mainmatter
\part{Background on the problem domain and influential algorithms}
%%% TEXEXPAND: INCLUDED FILE MARKER ./chpt1.tex
\chapter{Introduction}
\section{Introduction}
In the technology age, life is almost unfathomable without the mobile phone. It is hard to believe how the business world managed to function in the pre-mobile phone era\footnote{Pre 1980s where the mobile phone did not yet exist}. 

The invention of the mobile phone fulfilled the need to always be connected and be within reach of the modern world. This need can actually be attributed to feeling part of something and this something is deemed as being part of a network. This is similar to how mobile phones are able to provide connectivity at almost any location within a country.

Behind the connectivity of mobile phones lies an intricate layer of communication technology which has evolved since the invention of the normal landline phone. This technology is referred to at the top level as wireless communication, which includes inventions such as the radio. To enable communication at the level needed by mobile phones, wireless communication had to evolve and go a step further than normal radio communication. Hence the concept of cellular mobile networks was developed.

Without cellular networks mobile phones have no means of providing communication. The purpose of the cellular network is to provide the necessary functions to connect and facilitate communication between two entities (mobile phones) over a wireless network. 

Cellular networks achieve this level of communication through expensive equipment and ``smart'' algorithms. By ``smart'' algorithms, what is actually meant is algorithms that utilise artificial intelligence concepts to perform a certain function in an attempt to either automate a task within the network or improve a certain part of the network. Therefore, the correct term for these types of algorithms is actually artificial intelligence (AI) algorithms.

AI algorithms have a wide spread of functions that they can perform ranging from making informed intelligent decisions to optimising the operation of certain processes. In particular computers are indeed very apt at optimising certain procedures. This is because a computer is able to test and evaluate a huge number of different alterations and combinations of a certain procedure in a short amount of time, thereby allowing it to find the best combination out of those tested.

In this dissertation an algorithm is presented which concentrates on cellular phone networks. This particular algorithm falls into the latter part of the AI algorithms discussed, namely an AI optimisation algorithm. Thus the algorithm presented in this dissertation operates on a cellular phone network to optimise a certain part of the network.

In this section a introduction was presented to the dissertation. The main themes of the dissertation were outlined namely, cellular phone networks and optimisation algorithms. In the next section research plan and chapter breakdown is presented which is followed by this dissertation.
\section{Research Questions and Objective}
As previously discussed, an artificial intelligent algorithm is presented in this dissertation that generates plans for use by cellular networks. The purpose of creating such an algorithm is to determine the applicability of modern swarm-based algorithms with regard to finding better solutions to real-world problems that exist in domains such as cellular communication.

The research approach followed in this dissertation was first and foremost to understand the cellular network domain. More importantly, the focus is on how and what frequencies are used to facilitate communication as well as what affects the quality of the communicational link between two entities in a cellular network. 

The cellular domain is the problem domain, but to develop a solution in the problem domain a study needs to be conducted in the artificial intelligence domain, namely a study of optimisation algorithms. In order for a new optimisation algorithm to be developed, other algorithms that have achieved success in the respective optimisation problem domains in which they have been applied need to be investigated.

Therefore in an attempt to develop and apply a modern viable optimisation-based algorithm, a series of research questions has been identified which need to be answered. The research questions are as follows:
\begin{itemize}
\item \textbf{Question 1} --- What is cellular technology, how it got developed and what improvements have been made since its initial development?
\item \textbf{Question 2} --- What is the architecture behind a modern cellular network, how do the various hardware entities within a network communicate with each other and how is a communicational link established between two users of the network?
\item \textbf{Question 3} --- What exactly is the frequency problem and how does it affect modern wireless communication?
\item \textbf{Question 4} --- What variants of the frequency problem exist and which are most applicable to cellular networks?
\item \textbf{Question 5} --- What are the most popular optimisation algorithms and what characteristics make them unique?
\item \textbf{Question 6} --- With algorithms that achieved success in their respective optimisation problems, what particular technique is used by the algorithms that allowed them to achieve better performance?
\end{itemize}

The PSO algorithm might be short and elegant, but applying it to the FS-FAP required various new techniques in response to the following questions:
\begin{itemize}
\item How can a particle best be represented as a frequency plan?
\item How can one frequency plan move to another?
\item How can particles be prevented from using forbidden frequencies when they fly towards a particular plan?
\end{itemize}

The above questions were only the preliminary questions and were in fact a problem that had to be addressed for successful application of the PSO to the FAP. In chapter~\ref{chpt:psoapplicationFAP} a discussion is presented on how these problems were solved as well as how other problems were solved that were not anticipated.

Throughout the course of this dissertation the aim is to answer each of these identified research questions. In the next section a chapter breakdown of this dissertation is presented.

The aim of this dissertation is first and foremost to answer the identified research questions. Answering these questions will aid in reaching the research objective of this dissertation. The research objective is therefore to develop and determine the viability of an algorithm based on modern swarm optimisation techniques that will operate on the frequency assignment problem in an attempt to provide better frequency plans for use in cellular networks.

\section {Chapter Breakdown}
\subsection{Part I - Background}
The first part of this dissertation is concerned with the domain and problem the algorithm presented in this dissertation addresses, and finally to also understand the intricate details of how the algorithm operates.

Below is an outline of the chapters in the first part of this dissertation.
\subsubsection{Chapter 1}
This chapter provides an introduction to the dissertation as well as a broad overview of the topics in the dissertation will discuss.
\subsubsection{Chapter 2}
This chapter is concerned with providing information on how a modern cellular network functions. Within this chapter a brief history is presented on how cellular network technology was developed. The chapter also provides an overview of the architecture of a cellular network,and each part of the network's intended purpose and function to facilitate wireless communication is discussed.
\subsubsection{Chapter 3}
This chapter presents the problem that the dissertation addresses, namely the frequency assignment problem. The chapter provides a discussion on why the problem exists, the causes of the problem and what it means for a problem to be NP-Complete. Furthermore the variants of the problem and how they differ depending on the wireless domain that is being considered are alos discussed. Finally the chapter also provides a formal definition of the problem which is later utilised by the algorithm developed in this research.
\subsubsection{Chapter 4}
This chapter marks the beginning of a discussion on various optimisation algorithms in this dissertation. The algorithms presented in this chapter were chosen due to their widespread usage as well as success on NP-Complete problems. Each algorithm is discussed in depth providing an outline of the core features that make the algorithm unique as well as each core feature in detail. For each algorithm the chapter also presents an analysis on related work of the particular algorithm being applied to the frequency assignment problem. 
\subsubsection{Chapter 5}
This chapter is concerned with providing algorithms that are new in the research domain of optimisation algorithms. The algorithms presented in chapter 4 are fairly old and have been applied to a wide variety of problems. Algorithms in this chapter are relatively new in the optimisation domain and have not been applied to the same number of problems as the algorithms in chapter 4. In this chapter swarm algorithms are presented and the algorithms have the particular characteristic that they are based generally on processes observed in nature. Each algorithm is discussed in depth with its core characteristics outlined. Furthermore for each algorithm an analysis is given if the algorithm were to be applied to the frequency assignment problem. Finally it is formally stated what algorithm this dissertation is applied to the frequency assignment problem in this research.
\subsection{Part II - Implementation}
\subsubsection{Chapter 6}
This chapter provides a discussion of the algorithm developed to be applied to the frequency assignment problem. Within this chapter an outline is given of the process in developing a specialised particle swarm algorithm for the frequency algorithm. Each specialised technique developed is discussed in depth, along with an explanation of why the technique is needed as well as why it is used by the algorithm.
\subsubsection{Chapter 7}
This chapter is concerned with providing the results after applying the algorithm to a specialised set of benchmark problems for frequency assignment algorithms. The particular selected benchmark problems were discussed in chapter 2.
\subsubsection{Chapter 8}
This chapter concludes this dissertation. In this chapter it is determined whether the research goal was reached as well as whether any future work can be done to improve the presented algorithm.
%%% TEXEXPAND: END FILE ./chpt1.tex
%%% TEXEXPAND: INCLUDED FILE MARKER ./chpt2.tex
\chapter{Cellular Communication Technology}
\label{chpt:celltech}
\section{Introduction}
 Wireless technology is used by modern electronic devices to establish communication over which information is exchanged\cite{Karen2004}. Wireless technology facilitates communication between two devices by transmitting data or voice via a radio frequency\cite{Karen2004}. Examples of devices exchanging information wirelessly are radios for audio entertainment; television remotes to change channels; cellular phones for communication; wireless access points to create wireless LANs\cite{Karen2004}.

The popularity and rapid adoption of wireless technology contributes to the difficulty of planning, managing and operating wireless networks\cite{Karen2004}. As the popularity and use of services that use wireless technology increase, the need for these services to use different radio frequencies to communicate becomes greater\cite{wirelesstelcoMullet}. This need arises due to an effect called \emph{interference}, which occurs when two or more connections between devices use the same radio frequency to facilitate communication\cite{wirelesstelcoMullet}. This effect is discussed in more detail in chapter 3.

A wireless cellular operator is not allowed to operate on just any frequency. A governing body licenses a certain piece of the available wireless spectrum to the operator for use in their network\cite{FAPRAMColouring}. These frequencies that need to be licensed for use are known as \emph{commercial} frequencies and are very scarce as it is immensely expensive to license\cite{FAPRAMColouring}. 

The use of frequencies by services must be carefully considered to avoid interference when devices communicate with each other. This is a problem as the amount of devices that communicate far outstrips the amount of frequencies available for communication\cite{wirelesstelcoMullet}. Thus assigning frequencies to devices for communication is a difficult problem and is referred to as the \gls{FAP}\cite{Karen2004,Eisenblatter}.

Initially manual techniques were used to assign frequencies in an attempt to solve the \gls{FAP}\cite{Karen2004}. As a result, assigning frequencies was either too complex or just too daunting because of the sheer number of devices that needed to be assigned frequencies\cite{Karen2004}. Also, because of the rapid adoption of wireless technology the assignment of frequencies needed to be dynamic and hence automated\cite{Karen2004}.

By understanding how a \gls{gsm} network operates, especially how communication is facilitated, the reader is able to understand the problem this dissertation addresses. Therefore, this chapter will start off with section~\ref{sec:GSMNet} within which a brief history of \gls{gsm} networks are presented. Section~\ref{sec:GSMArch} follows the history discussion and presents an overview on the different architectural components the form a \gls{gsm} network. In section~\ref{sec:gsminterfaces} the different interfaces used by \gls{gsm} network components for communication is presented. Section~\ref{sec:interfacech} presents an overview on the logical channels that frequencies get divided into when used in a \gls{gsm} network. Finally this chapter concludes with a discussion on the handover process in section~\ref{sec:handover}.

\section{GSM Networks}
\label{sec:GSMNet}
The \gls{gsm} is a system for multiservice cellular communication that is capable of providing voice as well as data services\cite{GSMArchitectureProtocolsServices,wirelesstelcoMullet}. Most cellular networks in operation are \gls{gsm} based\cite{Karen2004,wirelesstelcoMullet}. The primary service that \gls{gsm} caters for is voice communication, but other data services such as \gls{SMS}, \gls{MMS} and internet connectivity services, e.g. \gls{GPRS}, \gls{EDGE} and \gls{HSCSD}, are becoming more important\cite{GSMArchitectureProtocolsServices,Eisenblatter}.

\Gls{gsm} is one of the most widely used radio communication technologies, which is why one needs to look at the history behind it in order to understand the domain of radio communication better \cite{GSMArchitectureProtocolsServices}. A brief history of the \gls{gsm} network specification will now be presented in the next section.

\subsection{A Brief History of GSM Networks}
\label{sec:gsmhistory}
In early 1981 a group known as the \emph{Groupe Speciale Mobile} was established to develop a Europe-wide radio communication system using the reserved 900 MHz band\footnote{In 1990 the United Kingdom requested that 1800 MHz band be added to the scope of the Groupe Speciale Mobile standard group. This variant of the \gls{gsm} specification became known as the \gls{DCS1800} \cite{GSM92,Karen2004}.}

At the start of the \gls{gsm} specification in the early 1980s it was initially thought that the system would be analogue based, but this soon changed with the \gls{ISDN} specification nearing completion\cite{GSM92}. As such the \gls{gsm} specification started following many of the same design principles and access protocols that \gls{ISDN} exhibited\cite{GSM92}.

After the completion of the \gls{ISDN} specification, the advantages of switching to digital instead of analogue for communication became clear\cite{GSM92} One of the primary advantages of \gls{ISDN} is that it is capable of transmitting data at higher speeds\cite{GSM92} \gls{gsm} would therefore be based on digital transmission and speech would be represented by a digital stream of 16 kbits/s \cite{GSM92}.

Before the switch to digital transmission was finalised the Groupe Speciale Mobile first wanted to evaluate the spectral efficiency of analogue and digital-based transmission\cite{GSM92}. Spectral efficiency plays an important part in wireless communication since the radio spectrum is a limited resource and whichever transmission technology is used, the utilisation of the spectrum should be maximised\cite{GSM92}. 

Maximum utilisation is an important problem that is discussed in detail in later sections of this chapter. After an evaluation of spectral efficiency it was decided that the \gls{gsm} system would be digitally based using \gls{TDMA} \cite{GSM92,GSMSysEngin}. \gls{TDMA} is discussed in section~\ref{sec:interfacech}.

By the early 1990â€™s \gls{gsm} became an evolving standard and the first \gls{gsm}-based network was demonstrated in 1991\footnote{Near the end of 1991 the \gls{gsm} group was renamed \emph{Speciale Mobile Group} (SMG) to eliminate confusion between the standard and the group}\cite{GSMArchitectureProtocolsServices,Eisenblatter}. The following year a number of \gls{gsm} networks were operating in Europe due to mobile terminals and equipment capable of operating on the networks becoming more widely available to the general public\cite{GSM92,Eisenblatter}. In the same year an operator in Australia became the first non-European operator to implement a \gls{gsm}-based network\cite{Eisenblatter}.

The collective subscriber base of \gls{gsm} networks surpassed the million subscriber mark in 1993\cite{GSM92}. Due to this phenomenal growth in \gls{gsm} network use, numerous extensions were made to the \gls{gsm} specification. 
Some of the extensions that were made are the following\cite{GSM92,GSMArchitectureProtocolsServices}:
\begin{itemize}
\item Half rate speech codec
\item Improved SMS
\item Line identification
\item Call waiting
\item Call holding
\end{itemize}
The specification with these extensions is known as \gls{gsm} Phase 2+. As the world shifted towards more digital and data-intensive services it became difficult to deliver these services over \gls{gsm} networks. This difficulty was due to the restriction that data could only be transmitted at 9.6 kbps \cite{GSM92,Karen2004}. 

This restriction also applies to voice, as voice is encoded into data that is transmitted over the network\cite{Karen2004, GSM92}. Before the extensions were made, voice was encoded using the Full Rate codec\cite{GSMArchitectureProtocolsServices}. The Full rate codec was the first codec used to encode voice in the \gls{gsm} standard and required the full 9.6 kpbs that was available\cite{GSMArchitectureProtocolsServices}. With half rate speech telephony, only half of the 9.6 kpbs is required for the same voice quality to be delivered\cite{GSMArchitectureProtocolsServices}.  

The new specification defined new technologies such as GPRS, EDGE and HSCSD, which were designed with the primary goal of making more bandwidth available for data transmission \cite{GSMArchitectureProtocolsServices,Karen2004}. Data transmission was improved by these technologies by enabling more than one \gls{gsm} slot to be used for a terminal or service at a time\cite{GSMArchitectureProtocolsServices,Karen2004}.

If more than one \gls{gsm} slot is to be used by a terminal or service, transceivers are required to have a higher \gls{SIR} ratio \cite{GSMArchitectureProtocolsServices,GSMSysEngin}. This requirement affects radio interfaces as there is a higher likelihood that interference might occur; hence it makes it more difficult to generate a low interference frequency plan \cite{Eisenblatter,GSMSysEngin}. 

The actual \gls{SIR} at a receiver is dependent on a number of factors that include \cite{GSMArchitectureProtocolsServices,Karen2004}:
\begin{itemize}
\item Frequency used at the transceiver
\item Strength of the signal
\item Weather conditions
\item Shape of the surrounding environment
\item Direction of the transmission
\end{itemize}
Even taking these factors into account, the calculation of the \gls{SIR} at a transceiver is not trivial. This calculation of the \gls{SIR} as well as its impact on mobile radio frequencies is discussed in section~\ref{sec:Interference}.

As the \gls{gsm} standard matured as a cellular technology, industry experts began specification of the next generation of cellular networks, which would in time replace the \gls{gsm} cellular system. 

The \gls{UMTS} is considered the third generation (3G) of cellular networks\cite{tabuglobalplanning3g,Eisenblatter}. \gls{UMTS} was designed from the beginning to operate in parallel with the legacy \gls{gsm} system. The first standard of \gls{UMTS} was issued in the beginning of 2000 and subsequently most modern networks are based on it or are migrating their networks to it\cite{tabuglobalplanning3g,Eisenblatter}.

UMTS is a major improvement over the \gls{gsm} in two areas, namely data transmission bandwidth and frequency planning due to \gls{UMTS} utilising \gls{DS-CDMA} and \gls{WCDMA}\cite{tabuglobalplanning3g,Eisenblatter}. The higher data transmission speed (2 Mb/s) can be attributed to \gls{UMTS} using the \gls{DS-CDMA} scheme\cite{tabuglobalplanning3g,Eisenblatter}. The scheme also allows more users to be served than previous generations of networks\cite{tabuglobalplanning3g,Eisenblatter}. 

DS-CDMA and \gls{WCDMA} sends data over a wide band spectrum of 5 MHz. The wider spectrum allows for more frequencies to be utilised and with more frequencies being available; the \gls{FAP} is easier to solve compared to a \gls{gsm} network\cite{tabuglobalplanning3g,Eisenblatter}\@. A more in depth discussion on how a range of spectrum is divided into frequencies for communication in \gls{gsm} networks is discussed in section~\ref{sec:interfacech}. \gls{DS-CDMA} and \gls{WCDMA} will not be discussed in depth as this discussion focusses on \gls{gsm}\@. The interested reader is directed to \cite{tabuglobalplanning3g} and \cite{wirelesstelcoMullet} for more information.

\Gls{CDMA} is a technology primarily used in broadband systems\cite{GSMArchitectureProtocolsServices}. Users do not gain access to only a small portion of the bandwidth, but rather use the entire band for the duration of a connection\cite{GSMArchitectureProtocolsServices}. Users also do not gain exclusive access to the whole band, but instead share the usage of the bandwidth with other users simultaneously, hence the name \emph{multiple access}\cite{GSMArchitectureProtocolsServices}.

With \gls{CDMA} a user's signal is not transmitted as its original signal. Instead the signal is spectrally spread over a multiple of its original bandwidth using a spreading factor \cite{GSMArchitectureProtocolsServices}. The spreading factor fluctuates between values of 10 and 1 000 \cite{GSMArchitectureProtocolsServices}. Using these spreading factors less interference and fewer disturbances are encountered because the broadband signal is generated from a narrowband signal \cite{GSMArchitectureProtocolsServices}.
UMTS may be a major improvement, but its adoption does not spread very far from busy city centers where there is a large concentration of clients in a small geographical area\cite{GSMArchitectureProtocolsServices}. The reason for this is that, as mentioned previously, \gls{UMTS} caters for larger data usage and therefore more clients can be serviced simultaneously \cite{GSMArchitectureProtocolsServices}.

Most network operators do not implement entirely new backbone architecture for \gls{UMTS}\label{UMTSGSMBackbone} to operate on, but instead utilise the same backbone used for \gls{gsm} and GPRS\@\cite{GSMArchitectureProtocolsServices}. This not only extends the lifetime of previous infrastructure investment by the operator, but also builds upon the redundancy provided by the \gls{gsm} network \cite{GSMArchitectureProtocolsServices}. Thus even with new technological improvements such as \gls{UMTS}, \gls{gsm} as a wireless technology is still used for communication and is therefore still relevant today\cite{GSMArchitectureProtocolsServices}.


The most up-to-date cellular network technology is referred to as the fourth generation of cellular networks (4G)\cite{4GWirelessVid}. The purpose of 4G is to improve upon 3G and bring true broadband speeds that is delivered over the cellular network\cite{4GWirelessVid}. There are currently two competing technologies that aim to provide 4G capabilities to cellular networks which is \gls{LTE} and Mobile \gls{WIMAX}\cite{4GWirelessVid}. Both technologies provide broadband speeds in the range of 14 - 40 MBits/s\cite{4GWirelessVid}. According to the 4G standard both technologies cannot be considered as ``true'' 4G technologies as the standard defines that broadband speeds in excess of 100 Mbits/s must be provided to be considered true \gls{LTE}\cite{4GWirelessVid}.

In this section a brief overview on the history of the \gls{gsm} network was presented. In the next section an explanation of the topology of \gls{gsm} network is given. This will broaden the understanding of \gls{gsm} networks.
\section{Topology of a GSM Network}
\label{sec:GSMArch}
A \gls{gsm} network consists of a variety of different subsystems to realise the goal of establishing a radio communication link between two parties. The hierarchy of systems and their respective connections to each other are illustrated in figure~\ref{fig:GSMArchitecture}. Each subsystem will now be discussed.

\subsubsection{Mobile Station}
A \gls{MS}  as it is defined in the \gls{gsm} specification refers to any mobile device that is capable of making and receiving calls on a \gls{gsm} network.  The \gls{MS} is the main gateway 
for a user to gain access to the \gls{gsm} network \cite{Eisenblatter,GSMArchitectureProtocolsServices}. Typical devices that fall under the category of \gls{MS} are cellular phones, smart phones and \gls{POS} devices. The \gls{MS} has two features that play an important role throughout the \gls{gsm} network, namely:
\begin{description}
  \item[\gls{SIM}] --- Inserted into a mobile device. The \gls{SIM} contains the \gls{IMSI} and is used throughout the network for authentication as well as being a key part in providing encrypted transmissions \cite{Eisenblatter}.
\item[\gls{IMEI}] --- Used to identify mobile station equipment. Primarily used in the denial of service to equipment that has been blacklisted\footnote{Equipment can be blacklisted for a variety of reasons, e.g.\ theft} and tries to gain access to the network \cite{Eisenblatter}.
\end{description}
\begin{figure}[H]
	\begin{centering}
		%
%%% TEXEXPAND: INCLUDED FILE MARKER ./tikz-pics/GSMArchitecture.tex
	\begin{tikzpicture}[scale=1.10]
		%\draw[step=0.25cm,thin,color=gray] (-6,-8) grid (6,8);
		%drawing of handsets
		%left handset
		\draw (-3.85,-6.20) circle (0.05cm);
		\draw (-3.85,-6.75) -- (-3.85,-6.25);
		\draw (-3.9,-8) node [below=0.85cm,right=0.005cm] {} rectangle (-3.15,-6.75);
		\draw (-3.8,-7.4) rectangle (-3.25,-6.8);
		\draw (-3.9,-8.25) node [below=0.85cm,right=0.005cm] {MS};
		\foreach \x in {0.0,0.1,0.2,0.3,0.4}
		{
			\foreach \y in {0.0,0.1,0.2,0.3}
			{
				\draw (-3.78 + \x,-7.6 - \y) rectangle (-3.68 + \x,-7.5 - \y);
			}
		}
		%right handset
		\draw (3.85,-6.20) circle (0.05cm);
		\draw (3.85,-6.75) -- (3.85,-6.25);
		\draw (3.9,-8) node [below=0.85cm,left=0.005cm] {} rectangle (3.15,-6.75);
		\draw (3.8,-7.4) rectangle (3.25,-6.8);
		\draw (3.9,-8.25) node [below=0.85cm,left=0.005cm] {MS};
		\foreach \x in {0.0,0.1,0.2,0.3,0.4}
		{
			\foreach \y in {0.0,0.1,0.2,0.3}
			{
				\draw (3.38 + \x,-7.6 - \y) rectangle (3.28 + \x,-7.5 - \y);
			}
		}
		%Drawing of the BTS's
		\begin{scope}
			\foreach \x in {-5,-2,2,5}
			{
				\path (\x,-4.1) coordinate (TowerCirlce);
				\path (\x - 0.10,-4.215) coordinate (startLeftMast);
				\path (\x + 0.10,-4.215) coordinate (startRightMast);
				\path (\x - 0.45,-5.75) coordinate (endLeftMast);
				\path (\x + 0.45,-5.75) coordinate (endRightMast);
				\path (\x - 0.140,-4.5) coordinate (startTopHorizontalBar);
				\path (\x + 0.140,-4.5) coordinate (endTopHorizontalBar);
				\path (\x - 0.260,-5) coordinate (startMiddelHorizontalBar);
				\path (\x + 0.260,-5) coordinate (endMiddelHorizontalBar);
				\path (\x - 0.370,-5.5) coordinate (startBottomHorizontalBar);
				\path (\x + 0.370,-5.5) coordinate (endBottomHorizontalBar);
						\draw [thick,color=gray] (startLeftMast) -- (endLeftMast) (startRightMast) -- (endRightMast) (startMiddelHorizontalBar) -- (endTopHorizontalBar) -- (startTopHorizontalBar) -- (endMiddelHorizontalBar) -- (startMiddelHorizontalBar) -- (endBottomHorizontalBar) -- (startBottomHorizontalBar) -- (endMiddelHorizontalBar) -- cycle;
					\shade [ball color=gray] (TowerCirlce) circle (0.15) node [above=0.25cm] {BTS};
			}
		\end{scope}
		%Lines connecting Handsets with BTS's
		%Left
		\draw (-5,-5.75) -- (-3.9,-7.5);
		\draw (-2,-5.75) -- (-3.15,-7.5);
		%Right
		\draw (5,-5.75) -- (3.9,-7.5);
		\draw (2,-5.75) -- (3.15,-7.5);
		%Drawing of BCS's
		\begin{scope}
			\node (LeftBCS) at (-3.55,-0.75) [shape=rectangle,draw=blue!40, fill=blue!20,minimum size = 2.25cm] {BCS};
			\draw (LeftBCS.south) -- (-5,-3.35);
			\draw (LeftBCS.south) -- (-2,-3.35);
			\node (RightBCS) at (3.55,-0.75) [shape=rectangle,draw=blue!40, fill=blue!20,minimum size = 2.25cm] {BCS};
			\draw (RightBCS.south) -- (5,-3.35);
			\draw (RightBCS.south) -- (2,-3.35);
			\draw [dashed,thick,color=black] (-5.6,0.5) rectangle (5.6,-5.85) (0,0.25) node [anchor=north] {BSS System};
		\end{scope}
		%Draw MSC
		\node (MiddelMSC) at (0,2.75) [shape=rectangle,draw=black,minimum height=2.5cm, minimum width=1.5cm] {MSC};
		\draw [thick] (MiddelMSC.west) to [bend right=30] (LeftBCS.north);
		\draw [thick] (MiddelMSC.east) to [bend left=30] (RightBCS.north);
		\node (LeftMSC) at (-5,2.75) [shape=rounded rectangle,draw=black,minimum height=2.5cm, minimum width=1.5cm] {Other MSC's};
		\node (OtherNetworks) at (5,2.75) [cloud,cloud ignores aspect,cloud puffs=11,minimum height = 2.5cm,draw=black] {Other Networks};
		\draw (LeftMSC.east) to (MiddelMSC);
		\draw (MiddelMSC) to (OtherNetworks);
		%Databases
		\node (VLRDB) at (4,7.10) [cylinder,shape border rotate=90,aspect=0.45,minimum width=2cm,minimum height=1.35cm,draw] {VLR};
		\node (AUCDB) at (-4,7.10) [cylinder,shape border rotate=90,aspect=0.45,minimum width=2cm,minimum height=1.35cm,draw] {AUC};
		\node (EIRDB) at (-4,5.75) [cylinder,shape border rotate=90,aspect=0.45,minimum width=2cm,minimum height=1.35cm,draw] {EIR};
		\node (HLRDB) at (4,5.75) [cylinder,shape border rotate=90,aspect=0.45,minimum width=2cm,minimum height=1.35cm,draw] {HLR};
		\draw[thick] (EIRDB) to [bend left=20] (MiddelMSC);
		\draw[thick] (VLRDB) to [bend right=20] (MiddelMSC);
		\draw[thick] (AUCDB) to [bend left=25] (MiddelMSC);
		\draw[thick] (HLRDB) to [bend right=25] (MiddelMSC);
		\draw[dashed,thick,color=black] (-6,8) -- (0,8) node [anchor=north] {NSS System} -- (6,8) -- (6,5) -- (2,5) -- (2,1) -- (-2,1) -- (-2,5) -- (-6,5) -- (-6,8) -- cycle;
	\end{tikzpicture}
%%% TEXEXPAND: END FILE ./tikz-pics/GSMArchitecture.tex
		\caption{GSM architecture\cite{GSMArchitectureProtocolsServices}}
		\label{fig:GSMArchitecture}
	\end{centering}
\end{figure}
The \gls{MS} has the capability to change the transmission power it uses from 0.8, 2, 5, 8 MW to a maximum value of 20 MW\cite{GSMSysEngin}. The change in transmission power is automatically set to the lowest level by the \gls{BTS} to ensure reliable communication after evaluating the signal strength as measured by the \gls{MS} \cite{GSMSysEngin,GSMArchitectureProtocolsServices}. The power adjustment also minimises co-channel interference because the transmitted signal is less powerful and therefore less likely to interfere with other signals\cite{GSMSysEngin}. Co-channel interference is discussed in chapter~\ref{chpt:fap}

\subsection{Base Station Subsystem}

According to the \gls{gsm} Phase 2+ specification, this system is viewed by the \gls{MSC} through an Abis radio interface. The \gls{BSS} is responsible for communicating with mobile stations in a particular location area \cite{Eisenblatter}. The \gls{BSS} usually consists of one \gls{BSC} with one or more \glspl{BTS} that it controls \cite{Eisenblatter}.A \gls{BTS} has similar equipment to that of a MS\cite{GSMSysEngin}. Both have transceivers, antennae and the necessary functions to perform radio communication.

The communication link between the \gls{MSC} and \gls{BSC} is the called the A-interface. The interface between the \gls{BSC} and \gls{BTS} is called the Abis interface \cite{Eisenblatter}. The A and Abis interface as well as other interfaces between other \gls{gsm} architecture components are discussed in section~\ref{sec:gsminterfaces}.  

In a \gls{gsm} network a service area is defined as a geographical area where the networks wants to deliver its cellular network service to potential clients \cite{GSMArchitectureProtocolsServices, Karen2004}. The service area is subdivided into \glspl{LA} which are then further divided into smaller radio zones called cells \cite{GSMSecurInTeleNetwork}. When a cellular network is modelled, cells are modelled as hexagonal shapes. Each cell in the modelled network is served by only one \gls{BTS} and is usually regarded to be in the centre of a cell as can be seen in figure~\ref{fig:GSMCell}\cite{GSMArchitectureProtocolsServices}. 
\begin{figure}[H]
	\begin{centering}
		%
%%% TEXEXPAND: INCLUDED FILE MARKER ./tikz-pics/GSMCell.tex
\begin{tikzpicture}
	%===============================Top======================================
	\node [regular polygon, regular polygon sides=6, minimum size=3cm,draw] at (0,1) {};
	\path (0,1.75) coordinate (TowerCirlce);
	\path (0 - 0.10,1.635) coordinate (startLeftMast);
	\path (0 + 0.10,1.635) coordinate (startRightMast);
	\path (0 - 0.45,0.01) coordinate (endLeftMast);
	\path (0 + 0.45,0.01) coordinate (endRightMast);
	\path (0 - 0.140,1.345) coordinate (startTopHorizontalBar);
	\path (0 + 0.140,1.345) coordinate (endTopHorizontalBar);
	\path (0 - 0.260,0.85) coordinate (startMiddelHorizontalBar);
	\path (0 + 0.260,0.85) coordinate (endMiddelHorizontalBar);
	\path (0 - 0.370,0.35) coordinate (startBottomHorizontalBar);
	\path (0 + 0.370,0.35) coordinate (endBottomHorizontalBar);
	\draw [thick,color=gray] (startLeftMast) -- (endLeftMast) (startRightMast) -- (endRightMast) (startMiddelHorizontalBar) -- (endTopHorizontalBar) -- (startTopHorizontalBar) -- (endMiddelHorizontalBar) -- (startMiddelHorizontalBar) -- (endBottomHorizontalBar) -- (startBottomHorizontalBar) -- (endMiddelHorizontalBar) -- cycle;
	\shade [ball color=gray] (TowerCirlce) circle (0.15) node [above=0.10cm] {\tiny{BTS}};
	%%========================================================================
	%%================================Second Line======================================
	\foreach \x in {-2.25,2.25}
	{
		\node [regular polygon, regular polygon sides=6, minimum size=3cm,draw] at (\x,-0.3) {};
		\path (\x,-0.3 + 0.75) coordinate (TowerCirlce);
		\path (\x - 0.10,-0.3 + 0.635) coordinate (startLeftMast);
		\path (\x + 0.10,-0.3 + 0.635) coordinate (startRightMast);
		\path (\x - 0.45,-0.3 - 0.99) coordinate (endLeftMast);
		\path (\x + 0.45,-0.3 - 0.99) coordinate (endRightMast);
		\path (\x - 0.140,-0.3 + 0.345) coordinate (startTopHorizontalBar);
		\path (\x + 0.140,-0.3 + 0.345) coordinate (endTopHorizontalBar);
		\path (\x - 0.260,-0.3 - 0.15) coordinate (startMiddelHorizontalBar);
		\path (\x + 0.260,-0.3 - 0.15) coordinate (endMiddelHorizontalBar);
		\path (\x - 0.370,-0.3 - 0.65) coordinate (startBottomHorizontalBar);
		\path (\x + 0.370,-0.3 - 0.65) coordinate (endBottomHorizontalBar);
		\draw [thick,color=gray] (startLeftMast) -- (endLeftMast) (startRightMast) -- (endRightMast) (startMiddelHorizontalBar) -- (endTopHorizontalBar) -- (startTopHorizontalBar) -- (endMiddelHorizontalBar) -- (startMiddelHorizontalBar) -- (endBottomHorizontalBar) -- (startBottomHorizontalBar) -- (endMiddelHorizontalBar) -- cycle;
		\shade [ball color=gray] (TowerCirlce) circle (0.15) node [above=0.10cm] {\tiny{BTS}};
	}
	%%========================================================================
	%%================================Third Line======================================
	\node [regular polygon, regular polygon sides=6, minimum size=3cm,draw] at (0,-1.6) {};
	\path (0,-1.6 + 0.75) coordinate (TowerCirlce);
	\path (0 - 0.10,-1.6 + 0.635) coordinate (startLeftMast);
	\path (0 + 0.10,-1.6 + 0.635) coordinate (startRightMast);
	\path (0 - 0.45,-1.6 - 0.99) coordinate (endLeftMast);
	\path (0 + 0.45,-1.6 - 0.99) coordinate (endRightMast);
	\path (0 - 0.140,-1.6 + 0.345) coordinate (startTopHorizontalBar);
	\path (0 + 0.140,-1.6 + 0.345) coordinate (endTopHorizontalBar);
	\path (0 - 0.260,-1.6 - 0.15) coordinate (startMiddelHorizontalBar);
	\path (0 + 0.260,-1.6 - 0.15) coordinate (endMiddelHorizontalBar);
	\path (0 - 0.370,-1.6 - 0.65) coordinate (startBottomHorizontalBar);
	\path (0 + 0.370,-1.6 - 0.65) coordinate (endBottomHorizontalBar);
	\draw [thick,color=gray] (startLeftMast) -- (endLeftMast) (startRightMast) -- (endRightMast) (startMiddelHorizontalBar) -- (endTopHorizontalBar) -- (startTopHorizontalBar) -- (endMiddelHorizontalBar) -- (startMiddelHorizontalBar) -- (endBottomHorizontalBar) -- (startBottomHorizontalBar) -- (endMiddelHorizontalBar) -- cycle;
	\shade [ball color=gray] (TowerCirlce) circle (0.15) node [above=0.10cm] {\tiny{BTS}};
	%%========================================================================
	%%================================Fourth Line======================================
	\foreach \x in {-2.25,2.25}
	{
		\node [regular polygon, regular polygon sides=6, minimum size=3cm,draw] at (\x,-2.9) {};
		\path (\x,-2.9 + 0.75) coordinate (TowerCirlce);
		\path (\x - 0.10,-2.9 + 0.635) coordinate (startLeftMast);
		\path (\x + 0.10,-2.9 + 0.635) coordinate (startRightMast);
		\path (\x - 0.45,-2.9 - 0.99) coordinate (endLeftMast);
		\path (\x + 0.45,-2.9 - 0.99) coordinate (endRightMast);
		\path (\x - 0.140,-2.9 + 0.345) coordinate (startTopHorizontalBar);
		\path (\x + 0.140,-2.9 + 0.345) coordinate (endTopHorizontalBar);
		\path (\x - 0.260,-2.9 - 0.15) coordinate (startMiddelHorizontalBar);
		\path (\x + 0.260,-2.9 - 0.15) coordinate (endMiddelHorizontalBar);
		\path (\x - 0.370,-2.9 - 0.65) coordinate (startBottomHorizontalBar);
		\path (\x + 0.370,-2.9 - 0.65) coordinate (endBottomHorizontalBar);
		\draw [thick,color=gray] (startLeftMast) -- (endLeftMast) (startRightMast) -- (endRightMast) (startMiddelHorizontalBar) -- (endTopHorizontalBar) -- (startTopHorizontalBar) -- (endMiddelHorizontalBar) -- (startMiddelHorizontalBar) -- (endBottomHorizontalBar) -- (startBottomHorizontalBar) -- (endMiddelHorizontalBar) -- cycle;
		\shade [ball color=gray] (TowerCirlce) circle (0.15) node [above=0.10cm] {\tiny{BTS}};
	}
	%%========================================================================
	%%================================Fifth Line======================================
	\node [regular polygon, regular polygon sides=6, minimum size=3cm,draw] at (0,-4.2) {};
	\path (0,-4.2 + 0.75) coordinate (TowerCirlce);
	\path (0 - 0.10,-4.2 + 0.635) coordinate (startLeftMast);
	\path (0 + 0.10,-4.2 + 0.635) coordinate (startRightMast);
	\path (0 - 0.45,-4.2 - 0.99) coordinate (endLeftMast);
	\path (0 + 0.45,-4.2 - 0.99) coordinate (endRightMast);
	\path (0 - 0.140,-4.2 + 0.345) coordinate (startTopHorizontalBar);
	\path (0 + 0.140,-4.2 + 0.345) coordinate (endTopHorizontalBar);
	\path (0 - 0.260,-4.2 - 0.15) coordinate (startMiddelHorizontalBar);
	\path (0 + 0.260,-4.2 - 0.15) coordinate (endMiddelHorizontalBar);
	\path (0 - 0.370,-4.2 - 0.65) coordinate (startBottomHorizontalBar);
	\path (0 + 0.370,-4.2 - 0.65) coordinate (endBottomHorizontalBar);
	\draw [thick,color=gray] (startLeftMast) -- (endLeftMast) (startRightMast) -- (endRightMast) (startMiddelHorizontalBar) -- (endTopHorizontalBar) -- (startTopHorizontalBar) -- (endMiddelHorizontalBar) -- (startMiddelHorizontalBar) -- (endBottomHorizontalBar) -- (startBottomHorizontalBar) -- (endMiddelHorizontalBar) -- cycle;
\shade [ball color=gray] (TowerCirlce) circle (0.15) node [above=0.10cm] {\tiny{BTS}};
\end{tikzpicture}
%%% TEXEXPAND: END FILE ./tikz-pics/GSMCell.tex
		\caption{Cells with BTSs}
		\label{fig:GSMCell}
	\end{centering}z
\end{figure}
Even though cells are modelled as being hexagons (see figure~\ref{fig:GSMCell}), the actual coverage area of a cell has no predefined regular shape \cite{GSMArchitectureProtocolsServices}.

For the purpose of this research a \gls{BTS} is considered to be assigned channels which are used for communication. No discussion will be presented on the electro-magnetic wavelength properties of channels as it has no effect on the results presented or problem being investigated.

With the network modelled as a series of interconnecting hexagons it allows one to more easily take constraints into account\cite{Eisenblatter}. For a cell to serve its geographical area, it needs to be allocated frequencies to operate on. Therefore, for each cell $i$ in the modelled network a subset $S_i$ of frequencies from the total frequencies $F$ allocated to the \gls{gsm} network is assigned\cite{GSMArchitectureProtocolsServices}. Neighbouring cells must at all costs avoid having the same subset of frequencies allocated to them, since such a scenario would lead to severe interference on any communication and thus degrade quality \cite{GSMArchitectureProtocolsServices}.

Since the number of cells in a network greatly outnumber the available of subset frequencies available, one is forced to start reusing frequency subsets in cells\cite{GSMArchitectureProtocolsServices}. To ensure that the reused frequency subsets do not interfere with their neighbouring cells, a reuse distance $D$ is defined \cite{GSMArchitectureProtocolsServices}. The reuse distance means that a certain number of cells must be between the cell already assigned the frequency subset $S_i$ and the cell to be assigned a frequency subset \cite{GSMArchitectureProtocolsServices}. The amount of cells is the distance value $D$.

The size of a cell determines the amount of potential traffic that the cell will be required to handle \cite{GSM92,Eisenblatter,GSMArchitectureProtocolsServices}. Therefore, if the size of a cell is chosen to be small, fewer channels will be required to be allocated to that cell as it would not be required to handle as much traffic as a larger cell\cite{GSMArchitectureProtocolsServices}. 

By making the size of cells smaller, the network operator is required to invest more into its network infrastructure. Smaller cells have a direct consequence that more cells would be required to serve the same geographical area, and more cells means that more \glspl{BTS} etc.\ need to be built and maintained, more locations need to be rented \cite{GSMArchitectureProtocolsServices}. Hence, making a cell smaller has a compounding effect on the amount of infrastructure needed to support it.

Fortunately all the extra infrastructure investment by the operator can be greatly scaled down if cells are divided into sectors\label{def:cellsector}. Each sector performs the exact same function as a traditional cell and is therefore regarded to also be a cell, just smaller in size and not omnidirectional \cite{GSMArchitectureProtocolsServices,GSM92,GSMSysEngin}. 

A cell is divided into 3 to 6 service sectors and each sector is allocated an antenna/transceiver \cite{GSMSysEngin}. Figure~\ref{fig:cellsector} illustrates a cell divided into sectors. 

\begin{figure}[H]
	\begin{centering}
	\includegraphics[scale=0.5]{tikz-pics/cellsector.pdf}
	\caption[Cell Sectorization]{Cell sectorisation\cite{GSMSysEngin}.}
	\label{fig:cellsector}
	\end{centering}
\end{figure}

Depending on how many sectors are at a cell, the operating angles of the antennae need to be adjusted accordingly to ensure 360 degree service. If there is only one sector, an omnidirectional antenna is used, otherwise the antennae operating angles are adjusted to $\frac{360\,^{\circ}}{n}$ where ${n}$ is the number of antennae \cite{Eisenblatter}.

By dividing the cell into sectors the amount of co-channel interference that would occur in a cell is greatly reduced \cite{GSMArchitectureProtocolsServices}. It is important to note that the reduction of co-channel interference is only applicable when the angle of the antenna by which transmission occurs is restricted\cite{GSMArchitectureProtocolsServices}.

Suppose, if a cell using an omnidirectional transceiver is assigned 6 channels. If the cell were to be divided into three sectors, where the sectors' antennae are $120^\circ$ apart, the number of interfering co-channels shrinks from 6 to 2 and from 6 to one in the case when the cell is divided into 6 sectors \cite{GSMSysEngin,GSM92,GSMArchitectureProtocolsServices}.

Each sector operates one or more elementary transceivers called \gls{TRX}. The number of \gls{TRX} per sector is determined by the expected peak traffic demand that the cell must be able to handle. Each \gls{TRX} can handle 7 to 8 communication links or calls in parallel except the first \gls{TRX}, which handles fewer calls than normal because it is responsible for transmitting cell organisation and protocol information \cite{Eisenblatter}. \glspl{TRX} are able to handle 7-8 calls in parallel due to the use of \gls{FDM} and \gls{TDM} schemes. 

\glspl{TRX} are assigned channels, which enable them to provide conversion between digital traffic data on the network side and the radio communication between \glspl{MS}and the \gls{gsm} network\cite{ACOvsEA,FAPOrientationModel}. The channels that are used by a cell for communication are discussed in section~\ref{sec:interfacech}.

\subsection{Mobile Switching Centre}

The \gls{MSC} is at the heart of a cellular switching system and forms part of the \gls{NSS}. The \gls{MSC} is responsible for the setting up, routing and supervision of calls between \gls{gsm} subscribers\cite{GSM92,GSMSysEngin}. The \gls{MSC} has interfaces to communicate with \gls{gsm} subscribers (through the \gls{BSS}) on the one hand and with external networks on the other\cite{GSM92}. The \gls{MSC} interfaces with external networks to utilise their superior capability in data transmission as well as for the signalling and communication with other \gls{gsm} network components \cite{GSM92}. 

The most basic functions that an \gls{MSC} is responsible for in a network are the following \cite{wirelesstelcoMullet}:
\begin{itemize}
\item Voice call initialization, routing, control and supervision between subscribers
\item Handover process between two cells
\item Location updating
\item \gls{MS} authentication
\item \gls{SMS} delivery
\item Charging and accounting of services used by subscriber
\item Notification of other network elements
\item Administration input or output processing functions
\end{itemize}

To achieve most of these functions the \gls{MSC} has an integrated \gls{VLR} database that stores call setup information for any \gls{MS} that is currently registered for service with the \gls{MSC} \cite{GSM92,wirelesstelcoMullet}. 

The \glspl{VLR}retrieves this information from the \gls{HLR} that contains all the registered \gls{gsm} subscriber information for the network. This information enables the \gls{MSC} to quickly retrieve the necessary information to set up a call between two clients that want to communicate with each other \cite{GSMSysEngin,GSMSecurInTeleNetwork}.

A requirement for being able to communicate with other network elements such as \gls{PSTN} is the ability to multiplex and demultiplex signals to and from such network elements. This operation is a necessity, since the incoming or outgoing connection bitrate from the source entity might be either too low or too high for the receiving entity.

A typical scenario where this operation proves vital is when a mobile subscriber makes a call to a subscriber on a\gls{PSTN} \@. The connection bit rate needs to be changed at the \gls{MSC} from a wireless connection bitrate to a bitrate suitable for transmission over a\gls{PSTN} \@. In chapter~\ref{chpt:fap} section~\ref{sec:Interference} more information regarding bit rates is presented.

\subsection{Network databases}
The \gls{HLR},  \gls{AUC} and \gls{EIR} are the three `back-end' databases which store and provide information for the rest of the \gls{gsm} network. In this subsection each one of the databases that form part of the `back-end' is discussed briefly and a description is given of the core functions that each database performs in the network.

\paragraph{Home location register}
--- The \gls{HLR} is a database that permanently stores information pertaining to a given set of subscribers. It needs to store a wide range of subscriber parameters because it is the reference source for anything \gls{gsm} subscriber related in the network\cite{GSMSysEngin}. 

Subscriber parameters that are stored in the database include billing information, routing information, identification numbers, authentication parameters and subscribed services\cite{GSMSysEngin}. The following information is also stored, but the information is of a temporary nature and can change at any time: The current \glspl{VLR}and \gls{MSC} the subscriber is registered with and whether the subscriber is roaming \cite{GSMSysEngin}.

\paragraph{Authentication centre}
--- The AUC is the entity in the \gls{gsm} network that performs security functions and thus stores information that enables it to provide secure over-the-air communication\cite{GSM92,GSMSysEngin}. The information that is stored contains authentication information as well as keys that are used in ciphering information\cite{GSM92,GSMSysEngin}.

During an authentication procedure no ciphering key is ever transmitted over the air; instead a challenge is issued to the mobile that needs to be authenticated. This challenge requires the mobile station to provide the correct \gls{SRES} with regard to the random number generated by the \gls{AUC}\cite{GSM92,GSMSysEngin}. The random number and ciphering keys that are used change with each call that is made; thus an attacker would gain nothing by intercepting a key, since it will change with the next call \cite{GSMSysEngin}.

Each mobile that is registered in the \gls{HLR} database needs to be authenticated and each call that is instantiated needs to retrieve keys from the AUC to establish a secure communication link\cite{GSM92,GSMSysEngin}. The AUC is sometimes included with \gls{HLR} to allow for fast communication between the two databases \cite{GSMSysEngin}.

\paragraph{Equipment identity register}
--- The \gls{EIR} is a database that stores the \gls{IMEI} numbers of all registered mobile equipment that has accessed the network\cite{GSMSysEngin}. Only information about the mobile equipment is stored, nothing about the subscriber or call is stored in the databas\cite{GSMSysEngin}.

Typically there is only one \gls{EIR} database per network and interfaces to the \gls{HLR} databases contained in the network\cite{GSMSysEngin}. The \glspl{IMEI} are grouped into three categories: \emph{white list}, \emph{black list} and the \emph{gray list}\cite{GSMSysEngin} The white list contains only the \gls{IMEI} numbers of valid \glspl{MS}; the black list stores the \gls{IMEI} numbers of equipment that has been reported stolen and the gray list stores the \gls{IMEI} numbers of equipment that has some fault (faulty software, wrong make of equipment)\cite{GSMSysEngin}.

\subsection{GSM Network Management Entities}
In a \gls{gsm} network most of the elements that form part of and make the network function are often distributed in a wide geographical area to provide the best network coverage for the customer\cite{GSMSysEngin}. 

For a network to function properly and efficiently network engineers need to be kept up to date on the state of the network and be alerted if \emph{any} problems occur\cite{GSMSysEngin}. For this purpose there are two systems in the \gls{gsm} network architecture that allow for this functionality required by network engineers\cite{GSMSysEngin}. 

One system is called the \gls{OMC} which is responsible for centralised regional and local operational and maintenance activities\cite{GSMSysEngin}. The other system is called the \gls{NMC} and unlike the \gls{OMC} it provides global and centralised management for operations and maintenance of the network supported by the OMCs \cite{GSMSysEngin}.

In the following paragraphs more in depth discussions on the critical functions the \gls{OMC} and \gls{NMC} perform is presented.

\paragraph{Operational and Management Centre}
--- The \gls{OMC} is capable of communicating with \gls{gsm} network components using two protocols, namely SS7 and X.25\cite{GSMSysEngin}. The SS7 protocol is usually used when the \gls{OMC} is communicating within the \gls{gsm} network over short and medium distances\cite{GSMSysEngin}. The X.25 protocol is used for large external data transfers\cite{GSMSysEngin}. All communication where the \gls{OMC} is involved occurs over fixed line networks and/or leased lines. The \gls{OMC} is usually used for day-to-day operation of a network \cite{GSMSysEngin}.

The \gls{OMC} has support for alarm handling\cite{GSMSysEngin}. An alarm in a \gls{gsm} network goes off whenever a predefined expected condition does occur. Engineers are able to define the severity of an alarm, which defines who or what is further alerted and if the alarm needs to be escalated to a higher level \cite{GSMSysEngin}.

The \gls{OMC} is also capable of fault management in the \gls{gsm} network\cite{GSMSysEngin}. It is able to activate, deactivate, remove and restore a service manually or automatically on network devices\cite{GSM92}. Various tests can be run and diagnostic information can be retrieved on the network devices to detect any current or future defects \cite{GSMSysEngin}.

\paragraph{Network Management Centre}
--- The \gls{NMC} is similar to the \gls{OMC} but it is not restricted to only regional \gls{gsm} network components as it is in charge of all the \gls{gsm} network components in the network\cite{GSMSysEngin}. The \gls{NMC} provides traffic management for the global network and also monitors high priority alarms such as overloaded or failed \gls{gsm} network components\cite{GSMSysEngin}. It is usually used in long-term planning of a network, but it has the capability to perform certain \gls{OMC} functions when a \gls{OMC} is not staffed. 

\section{GSM Interfaces}
\label{sec:gsminterfaces}
In the \gls{gsm} network all the network components communicate with each other through predefined interfaces. In this section an overview is given of these interfaces between the components.
\begin{description}
  \item{\textbf{Um interface}} --- This interface is the link between an \gls{MS} device and a \gls{BTS} and is also referred to as the \emph{Air} interface since communication occurs wirelessly. The primary protocol used on this interface is the \gls{LAPDm}, which is an extension of the \gls{ISDN} LAPD protocol to accommodate the mobile nature of \gls{MS} devices as well as for the shorter \gls{TDMA} frames which are used in \gls{gsm} networks\cite{wirelesstelcoMullet,GSMSecurInTeleNetwork}.
\item{\textbf{Abis interface}} --- Between the \gls{BTS} and \gls{BSC} the interface used for communication is known as the Abis interface. The only messages that the \gls{BTS} is interested in are those that have to do with management of radio resources\cite{wirelesstelcoMullet,GSMSecurInTeleNetwork}. All other messages are left alone and merely pass through the \gls{BTS} to the \gls{BSC} transparently.
\item{\textbf{A interface}} --- The interface between the \gls{BSC} and \gls{MSC} is known as the A interface. This interface is used for the transfer of information, which is used by the \gls{MSC} to manage BSSs, control connections and manage the mobility of \gls{MS} in its area of service\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}.
\item{\textbf{Other Interfaces}} --- The \gls{MSC} has interfaces going from itself to databases and other external networks. Each interface connects to a specific database, \gls{MSC} or network and is therefore very specific as to what function it performs\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}. An interface going from one \gls{MSC} to another will convey information regarding handling the administration of handover of an \gls{MS} device leaving one administrative area to another MSC's administrative area. The administrative area of an Msc is the section of \gls{BSS} components the Msc is responsible for. The handover procedure is a very delicate process which is described in section~\ref{sec:handover}.
\end{description}

In this section a brief overview was given of the most critical interfaces used by all the network components of the \gls{gsm} network involved. In the next section the difference between a logical channel and a frequency is described. Additionally an outline and overview of all the logical channels defined in the \gls{gsm} is presented. 
\section{GSM Channels}
\label{sec:interfacech}
\gls{gsm} defines a series of logical channels, which are used for communication over these interfaces. A distinction needs to be made between channels and frequencies. As discussed earlier, a network is licensed in a certain section of the wireless spectrum for use for commercial communication. This piece of spectrum is referred to as bandwidth and is measured in Hz, therefore $W$ Hz, where $W$ denotes the allocated bandwidth\cite{FundamentalsWirelessCommunication}. This bandwidth W is then divided into N smaller chunks of bandwidth called narrowband chunks. Each N narrowband chunk is a channel and has a width of $W/N$ Hz\cite{FundamentalsWirelessCommunication}. 

Using \gls{TDMA} the \gls{gsm} system is able to provide additional transmission capacity by dividing the frequency into eight equal timeslots \cite{wirelesstelcoMullet}. As can be observed from figure~\ref{fig:GSMChannels} each \gls{TDMA} frame has a series of consecutive timeslots. Each timeslot can be used for both uplink and downlink transmission. A \gls{gsm} \emph{channel} is a logical channel and refers to a single timeslot within a \gls{TDMA} frame \cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}.
\begin{figure}[H]
	\begin{centering}
		%
%%% TEXEXPAND: INCLUDED FILE MARKER ./tikz-pics/GSMChannel.tex
\begin{tikzpicture}[]
	\begin{scope}[node distance=0cm]
		\node (startSquare) at (-6.0,0.5) [shape=rectangle,draw=black,minimum height = 0.75cm,minimum width = 0.8cm]{   };
		\node (secondSquare) [right = of startSquare,shape=rectangle,draw=black,minimum height = 0.75cm,minimum width = 0.8cm]{   };
		\node (TS0) [right = of secondSquare, shape=rectangle,draw=black,fill=gray!40,minimum height = 0.75cm,minimum width = 0.8cm]{TS1};
		\node (TS1) [right = of TS0, shape=rectangle,draw=black,fill=gray!40,minimum height = 0.75cm,minimum width = 0.8cm]{TS2};
		\node (TS2) [right = of TS1, shape=rectangle,draw=black,fill=gray!40,minimum height = 0.75cm,minimum width = 0.8cm]{TS3};
		\node (TS3) [right = of TS2, shape=rectangle,draw=black,fill=gray!40,minimum height = 0.75cm,minimum width = 0.8cm]{TS4};
		\node (TS4) [right = of TS3, shape=rectangle,draw=black,fill=gray!40,minimum height = 0.75cm,minimum width = 0.8cm]{TS5};
		\node (TS5) [right = of TS4, shape=rectangle,draw=black,fill=gray!40,minimum height = 0.75cm,minimum width = 0.8cm]{TS6};
		\node (TS6) [right = of TS5, shape=rectangle,draw=black,fill=gray!40,minimum height = 0.75cm,minimum width = 0.8cm]{TS7};
		\node (TS7) [right = of TS6, shape=rectangle,draw=black,fill=gray!40,minimum height = 0.75cm,minimum width = 0.8cm]{TS8};
		\node (secondLastSquare) [right = of TS7, shape=rectangle,draw=black,minimum height = 0.75cm,minimum width = 0.8cm]{   };
		\node (lastSquare) [right = of secondLastSquare, shape=rectangle,draw=black,minimum height = 0.75cm,minimum width = 0.8cm]{   };
	\end{scope}
	\node (startF) at (startSquare.west) [above=1.5cm]{};
	\node (endF) at (lastSquare.east) [above=1.5cm]{};
	\draw [|<->|,thick] (startF) to node [above=0.05cm] {Frequency} (endF);
	\draw[decorate,decoration={brace,amplitude = 0.5cm,raise=0.5cm}] (TS0.west) to node [above=1cm] {TDMA Frame} (TS7.east);
	\node (logicalChannel) [shape=rectangle,draw=black,below = 1.5cm of TS4] {Logical Channel};
	\draw (logicalChannel.north east) to (TS1.south east);
	\draw (logicalChannel.north west) to (TS1.south west);
\end{tikzpicture}
%%% TEXEXPAND: END FILE ./tikz-pics/GSMChannel.tex
		\caption{TDMA frame and logical channels \cite{wirelesstelcoMullet}}
		\label{fig:GSMChannels}
	\end{centering}
\end{figure}
The \gls{gsm} system is therefore able to use the same physical frequency in eight different timeslots without interference as these \emph{logical} channels are used at different times. Therefore using \gls{TDMA} the available channels that can be used for communication in \gls{gsm} are increased eightfold \cite{wirelesstelcoMullet}.

Frequencies are assigned to the uplink and downlink portion of the connection with a duplex separation of 45 Mhz in the frequency band to avoid interference between uplink and downlink. There are two types of channels, traffic channels and control channels. \glspl{TCH} primary purpose is to enable communication of user speech and data and therefore carry no control information \cite{GSMArchitectureProtocolsServices}.

A \gls{TCH} is assigned to an \gls{MS} device when the device indicates that it needs to communicate with another device either with speech or data. When an \gls{MS} has finished with the \gls{TCH} the allocated \gls{TCH} is reclaimed for use by other \gls{MS} devices on the network. This request by the \gls{MS} device occurs using the control channels \cite{GSMArchitectureProtocolsServices}.

Control channels are much more actively used in a \gls{gsm} network since they are the primary means by which control and management of the network occurs \cite{GSMArchitectureProtocolsServices}. These channels are used even when the \gls{MS} has no active connection and is in idle mode. This constant activity on the control channels is to keep the network updated with information such as the position of the \gls{MS} (location updating) and signal strength \cite{GSMArchitectureProtocolsServices,GSMSysEngin,Eisenblatter}. 

The control channels are divided into three main channel groups namely \gls{BCH}, \gls{CCCH} and \gls{DCCH} \cite{GSMArchitectureProtocolsServices}. Each of these channel groups contains other channels that aid in the control and management of the network. Each group along with the associated channels will now be briefly discussed.

The first group, \gls{BCH}, consists of three channels:
\begin{description}
  \item{\textbf{\gls{BCCH}}} --- This channel is broadcast using the very first frequency assigned to a cell. Using this frequency, the channel broadcasts information regarding the network. This information includes radio channel configuration of the current and neighbouring cells, synchronisation information, registration identifiers and most importantly the format of the \gls{CCCH} used by the local \gls{BTS} \cite{GSMArchitectureProtocolsServices}.
  \item{\textbf{\gls{FCCH}}} --- Synchronisation information is broadcast to the \glspl{MS}to enable them to perform frequency correction on the transmission. Typical synchronisation information on this channel, for instance, is the exact frequency the local \gls{BTS} is using for transmission to enable the \glspl{MS}to attune themselves to the same frequency \cite{GSMArchitectureProtocolsServices}.
  \item{\textbf{\gls{SCH}}} --- On this channel, identifying information regarding the \gls{BTS} is transmitted. Also on this channel information regarding synchronisation of frames is sent which aids an \gls{MS} to, for example, structure the time frames of \gls{TDMA} frames.
\end{description}

The \gls{FCCH} and \gls{SCH} are always broadcast with the \gls{BCCH} since these channels are needed for the operation of the radio subsystem \cite{GSMArchitectureProtocolsServices}. The \gls{CCCH} is a point-to-point signalling channel that is used to localise an \gls{MS} through the use of paging\cite{GSMArchitectureProtocolsServices}. 

When a \gls{MS} is paged in a \gls{gsm} network, a \gls{CCCH} message is sent to all the cells in the surrounding area of the last known cell the \gls{MS} was recorded to be at\cite{GSMArchitectureProtocolsServices}. The messsage is sent to surrounding cells in case the \gls{MS} changed location since it was last communication with the network\cite{GSMArchitectureProtocolsServices}. The \gls{MS} recevies the paging through the \gls{CCCH} and responds if it is intened for the particular MS\cite{GSMArchitectureProtocolsServices}. The channel is also used to assign dedicated channels \cite{GSMArchitectureProtocolsServices}. The \gls{CCCH} is made up of the following channels:
\begin{description}
  \item{\textbf{\gls{RACH}}} --- The \gls{RACH} forms the uplink portion of the \gls{CCCH} and is randomly accessed by the \glspl{MS}to request a dedicated channel for a single signalling transaction \cite{GSMArchitectureProtocolsServices}.
  \item{\textbf{\gls{AGCH}}} --- The \gls{AGCH} froms the downlink part of the \gls{CCCH}\@. It is used by the radio subsystem to assign a \gls{SDCCH} or \gls{TCH} to an \gls{MS} \cite{GSMArchitectureProtocolsServices}.
  \item{\textbf{\gls{PCH}}} --- The \gls{PCH} also forms part of the downlink portion of the \gls{CCCH}\@. This channel is used by the radio subsystem to page specific \glspl{MS}, which aids in the process of locating an \gls{MS} \cite{GSMArchitectureProtocolsServices}.
\item{\textbf{\gls{NCH}}} --- This channel is used to inform an \gls{MS} of any incoming group calls or calls that are being broadcast \cite{GSMArchitectureProtocolsServices}.
\end{description}

The last group of signalling channels is referred to as \gls{D/ACCH}. This group of channels has the characteristic that they are a group of bidirectional point to point channels \cite{GSMArchitectureProtocolsServices}.
\begin{description}
  \item{\textbf{Stand-alone dedicated control channel (\gls{SDCCH})}} --- This channel is used for communication between the \gls{BSS} and \gls{MS} even when there is no active connection\cite{GSMArchitectureProtocolsServices}. Hence the `stand-alone' since it means that there need not be a \gls{TCH} assigned for communication to occur between the \gls{BSS} and \gls{MS} \cite{GSMArchitectureProtocolsServices}.
  \item{\textbf{\gls{SACCH}}} --- When a \gls{TCH} or \gls{SDCCH} is assigned, an accompanying \gls{SACCH} is also assigned. The \gls{SACCH} is used to transmit information for optimal radio operation, which can include information on power control of the radio transmitter and synchronisation information\cite{GSMArchitectureProtocolsServices}. Packets must be continuously sent over the \gls{SACCH} as it is used as proof that there is still a physical radio connection \cite{GSMArchitectureProtocolsServices}. When the \gls{MS} has finished using the \gls{SACCH} channel, it transmits a report regard the current results of the radio signal level, which is continuously measured \cite{GSMArchitectureProtocolsServices}.
  \item{\textbf{\gls{FACCH}}} --- When more bandwidth is required for signalling purposes, the signal of the \gls{TCH} is modified using dynamic pre-emptive multiplexing. The additional bandwidth comes at the expense of the user data transport\cite{GSMArchitectureProtocolsServices}. When a channel is created in this manner it is called a \gls{FACCH} \cite{GSMArchitectureProtocolsServices}.
\end{description}

Finally, one last channel is defined namely the cell \gls{CBCH}, which shares the same physical channel that the \gls{SDCCH} uses. On this channel messages of the short message service cell broadcast are broadcast\cite{GSMArchitectureProtocolsServices}.

In this section an overview was given of how \emph{logical} channels are used for communication between an \gls{MS}  and \gls{BSS}/\gls{MSC}\@. These three groups of channels collectively enable the \gls{gsm} network to facilitate wireless communication, a very important function for a telecommunication network. The following section dealts with how the network is able to keep a connection to an \gls{MS} alive and allow the \gls{MS} to make calls while the device is moving around geographically within the network.
\section{Handover}
\label{sec:handover}
The handover process in a \gls{gsm} network is initiated when an \gls{MS} with an active call moves outside the coverage area of a cell, \gls{BSS} or \gls{MSC} \cite{GSMArchitectureProtocolsServices,wirelesstelcoMullet,Eisenblatter}. A handover might also be initiated because of measurements indicating bad channel quality\cite{GSMArchitectureProtocolsServices}. 

Various information needs to be migrated across and shared between the components handling the calls to ensure a smooth handover. Not only the \gls{gsm} architecture components that need to continuously share information but also the \gls{MS}\@. The \gls{MS} is required to continuously observe and measure signal strength of up to 6 neighbouring cells. The \gls{MS} does this by monitoring the \gls{BCCH}\cite{GSMArchitectureProtocolsServices,wirelesstelcoMullet}. This information is of course relayed to the \gls{MSC} and \gls{BTS}. The information plays a critical role in the decision process as to which entity will be the best in taking over the administration of the active call\cite{GSMArchitectureProtocolsServices,wirelesstelcoMullet}.

An \gls{MS} can in some cases receive the same \gls{BCCH} from different cells, which are most likely neighbours \cite{GSMArchitectureProtocolsServices}. This problem of duplicate \gls{BCCH} from different cells can be attributed to the frequency reuse in the cellular network as well as to the smaller sector cells forming clusters and therefore overlapping coverage area \cite{GSMArchitectureProtocolsServices}. As discussed in section~\ref{def:cellsector}, cells are divided into sectors, which lessen the problem of co-channel interference. This division into sectors can cause clustering of cells and overlapping of coverage area.

This creates a problem for the \gls{MS} since it needs to distinguish between the two cell measurements as it does not know which measurement belongs to which cell\cite{GSMArchitectureProtocolsServices}. To distinguish between different cells, the \gls{MS} also tries to determine the identity of each cell it is monitoring. Only cells whose identity can be determined reliably are included in the report sent to the BTS\cite{Eisenblatter,GSMArchitectureProtocolsServices,wirelesstelcoMullet}\footnote{When cell identity cannot be determined this can be due to environmental factors like signal strength or to packets getting lost/dropped}. Using this report the handover algorithm is able to decide how to handle the handover, and which cell needs to take over the call\cite{Eisenblatter,GSMArchitectureProtocolsServices,wirelesstelcoMullet}.

Once the cell has been selected, the actual handover process starts. Which has to take into account that the frequency allocated to the incoming call from the other cell does not interfere with other present active calls in the cell receiving the handover\cite{Eisenblatter,GSMArchitectureProtocolsServices,wirelesstelcoMullet}. A frequency interfering with calls currently active in the cell can cause users to hear other conversations from the interfering call, or experience their call being ``dropped'' i.e.\ disconnected\cite{Eisenblatter}. 

There are three core handover procedures when a handover needs to occur in a \gls{gsm} network: \emph{intra-BSC}, \emph{inter-BSC} and \emph{inter-MSC}, each of which involves different \gls{gsm} network components \cite{wirelesstelcoMullet}.

\begin{description}
\item{\textbf{Intra-BSC}} --- Also known as \emph{intercell handover}, this handover is concerned with the transfer of an active call/connection from an \gls{MS} to another cell which is controlled by the same \gls{BSC} as the current cell\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}. The current \gls{BTS} that manages the active call of the \gls{MS} constructs a report containing measurement information from the MS, as well as measurements the \gls{BTS} has taken on signal strength and error bit ratio of the current connection\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}. The error bit ratio is defined as how often part of the data being sent over a connection needs to be retransmitted because an error occured\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}. An error can be caused by interference, faulty hardware or the signal strenght is fading\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}. 

  The constructed report is forwarded to the managing \gls{BSC}. The report is analysed to determine the necessity of handing over the active call to another \gls{BTS}\@. If a handover is deemed necessary, the \gls{BSC} starts by initialising the \gls{BTS} to prepare it to handle the new connection\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}.

The \gls{BSC} then notifies the \gls{MS} through the old \gls{BTS} of the new \gls{BTS} identity, and properties of the new connection such as \gls{TCH} frequency, power output etc. After receiving the information about the new connection, the \gls{MS} makes the necessary adjustments for it to continue operating and handling the call on the new connection\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}. 

Once all the adjustments have been made the \gls{MS} sends a confirmation to the \gls{BSC} of the successful handover through the new \gls{BTS}\@. The \gls{BSC} instructs the old \gls{BTS} that it must relinquish the use of the \gls{TCH} and its associated \gls{SDCCH} used by the old \gls{MS} call. The \gls{BSC} notifies the \gls{MSC} of the handover as it is used in network operation reports\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}.
\item{\textbf{Inter-BSC}} --- In an inter-\gls{BSC} handover a call of an \gls{MS} that is being managed by a \gls{BTS} is transferred to another \gls{BTS} which has a \emph{different} controlling \gls{BSC}\@. Thus, the call is essentially moved between two \glspl{BSC}, and it is up to the new control \gls{BSC} to select a suitable \gls{BTS} that will actually handle the call of the \gls{MS} being handed over\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}.

  This handover occurs because the \gls{MS} is moving or is about to move into a cell that is not controlled by the current \gls{BSC}\@. The current \gls{BSC} detects this and therefore takes the necessary precautions to ensure that the new \gls{BSC} is able to make suitable provision to assume control of the call within one of its BTSs\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}.

The \gls{BSC} informs the managing \gls{MSC} that a handover to another \gls{BSC} must occur. The request sent to the \gls{MSC} contains the identity of the cell managed by a different BSC\@. The \gls{MSC} determines the managing \gls{BSC} of the cell in question and notifies it that it must select and prepare the cell for handover. The new \gls{BSC} informs the cell to create a new connection, which will be used by the \gls{MS} once the handover is complete\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}.

The new \gls{BSC} informs the \gls{MSC} of the new connection details which the cell will use to handle the handover and maintain the active connection of the \gls{MS}\@\cite{wirelesstelcoMullet}. The \gls{MSC} forwards the connection information to the old \gls{BSC}, which forwards it to the \gls{MS}\@\cite{wirelesstelcoMullet}. The \gls{MS} makes the necessary adjustments for it and then moves on to the new connection. The \gls{MS} informs the new \gls{BSC} that the handover has been completed successfully\cite{wirelesstelcoMullet}. The new \gls{BSC} informs the \gls{MSC}, which then instructs the old \gls{BSC} to relinquish the old connection used by the \gls{MS}\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}.
\item{\textbf{Inter-MSC}} --- With an inter-\gls{MSC} handover, control and management of an active call on an \gls{MS} must be transferred to another \gls{BTS}, which resides in a different area that is managed by a different MSC\@\cite{wirelesstelcoMullet}. The handover process follows the same basic formula as the intra-\gls{BSC} and inter-\gls{BSC} handovers once the handover request is made\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}.
The \gls{BSC} managing the \gls{BTS} to which the \gls{MS} is going to be handed over is to be determined by the MSC\@\cite{wirelesstelcoMullet}. The \gls{BSC} is notified by the new managing \gls{MSC} that certain \glspl{BTS} must bring a new connection online for the incoming \gls{MS}; the network components upstream\footnote{components upstream are the network components which are higher up in the managing structure. In this instance, \gls{BTS} -- \gls{BSC} -- \gls{MSC}\@.} are notified\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}.

The new \gls{MSC} informs the old \gls{MSC} of the new connection details. The old \gls{MSC} transfers the connection information to the \gls{MS} that is going to be a handed over to another \gls{BTS}\@\cite{wirelesstelcoMullet}. The \gls{MS} makes the corresponding adjustments and then starts operating on the new connection. The \gls{MS} informs the \gls{BSC} of the successful handover\cite{wirelesstelcoMullet,GSMArchitectureProtocolsServices}. 

  The \gls{BSC} in turn informs the new \gls{MSC}, which in turn informs the old \gls{MSC} that the handover was successful. The \gls{MSC} then instructs the \gls{BSC} to ensure that the old connection resources are relinquished by the \gls{BTS}.
\end{description}

In this section a discussion was presented on the handover process in \gls{gsm} network. The effect this has on channel selected as well as the different handover procedures was highlighted. 
\section{Summary}
In this chapter a broad discussion was given of modern cellular technology, specifically \gls{gsm} cellular network technology. A brief history on how \gls{gsm} was developed to be the most widely used cellular technology in use today was provided. The \gls{gsm} architecture components followed. In the \gls{gsm} architecture all the network components present in a modern \gls{gsm} network were identified.

Following the discussion of the \gls{gsm} network components, a broad overview was given of the communication interfaces used between the \gls{gsm} network components to communicate with each other. This was followed by a definition of the \gls{gsm} channels which are used on the interfaces to communicate information.

The chapter concluded with the handover process which is used to allow an \gls{MS} device to move freely geographically within the network. 
%%% TEXEXPAND: END FILE ./chpt2.tex
%%% TEXEXPAND: INCLUDED FILE MARKER ./chpt3.tex
\chapter{The Frequency Assignment Problem}
\label{chpt:fap}
\section{Introduction}
The \gls{FAP}\footnote{Also known as \gls{AFP} or \gls{CAP}\cite{ACOvsEA}} is a generalisation of the graph-colouring problem and is consequently an NP-Complete problem\cite{FAPRAMColouring}. The \gls{FAP} is an NP-Complete problem due to fact that only a finite number of frequencies can be assigned to \glspl{TRX}, where the number of transceivers to be assigned frequencies greatly outweighs the number of available frequencies\cite{FAPRAMColouring}. A more thorough definition of what it means for a problem to be NP-Complete is given in section~\ref{sec:NPComplete}.

In wireless communication a huge concern is interference which occurs when frequencies used for communication are close to each other in the frequency spectrum\cite{Karen2004}. Interference and its effects is discussed in detail in section~\ref{sec:Interference}. Essentially for the \gls{FAP} the primary concern is to develop an approximate plan on assigning frequencies in such a way that interference is kept to a minimum. 

Using exact algorithms to find a solution is not practical since the time to find a solution is polynomial. Generally metaheuristic algorithms are used to find optimal solutions to NP-Complete problems\cite{ACOvsEA}. In the chapter~\ref{chpt:heuristic}, a discussion is presented on algorithms that are used to find solutions to NP-Complete problems. 

As discussed in chapter~\ref{chpt:celltech} network operators are licensed a range of frequencies from the available spectrum. A licensed piece of spectrum contains a series of consecutive frequencies as well as gaps. Gap frequencies are barred from being used by any device within the network as they may have already been allocated to another operator for use \cite{FAPInCell}. By barring frequencies, a scenario is avoided where the different networks' equipment interferes with their respective operations\cite{FAPInCell}.

Due to the whole spectrum not being available to network operators and only a subset being available for commercial communication as per the frequencies allocated to them, networks opt to reuse their frequencies\cite{FAPInCell}. The networks do this to maximise the use of their allocated frequencies and to minimise their licensing fees, since if the network needs more frequencies, they need to be licensed\cite{FAPRAMColouring}.

It is not always possible to simply allocate more frequencies to a network even if the network pays the associated fees. The whole commercial spectrum may already have been licensed to various entities. Hence, licensed frequencies are a very valuable and scarce commodity \cite{FAPRAMColouring,FAPInCell}.

The chapter is organised as follows. The first section the follows provides a discussion on NP-Complete problems. In section~\ref{sec:chm} constraint handling mechanisms are presented. Section~\ref{sec:FreqAssignmentTypes} presents an overview of different methods for allocated frequencies. Interference is discussed in depth in section~\ref{sec:Interference}. After the interference discussion a section is presented on the different types of frequencies assignment problems in section~\ref{sec:FAPVariants}. A mathematical formulation of the fixed spectrum frequency assignment problem is presented in section~\ref{sec:FAPMathDef}. Section~\ref{sec:FAPBenchmarks} provides an overview of the different benchmarks used to evaluate frequency assignment problems. After the discussion on the different benchmarks that are available in the domain a section on the where the FAP is encountered in the industrial domain is presented. 

This chapter concluded with a section that summarises the contents presented. In the next section an overview of what it means when a problem is NP-Complete is given.

\section{NP-Complete}
\label{sec:NPComplete}
The term NP stems from the field known as complexity analysis. Algorithms are typically measured for their worst running time using $O(n)$ notation. The field of complexity analysis is more interested in measuring complexity of a problem than the running time of an algorithm\cite{AIModernApproach}.

The field of complexity analysis makes a keen distinction between problems that can be solved by algorithms in polynomial time and problems that cannot be solved in polynomial time using any available algorithm\cite{AIModernApproach}. An algorithm is said to be of polynomial time if the number of steps it needs to perform to solve the problem is given by $O(n^k)$ where $k$ is a nonnegative integer and $n$ refers to the complexity of the input\cite{AIModernApproach}.

A distinction needs to be made between \emph{finding} a possible solution and determining whether a result is a valid solution to an NP problem\cite{AIModernApproach}. Verifying whether some result is indeed a solution to an NP problem is a quick operation\cite{AIModernApproach}. Finding a solution through the use of an algorithm is what polynomial time refers to.

Algorithms that are able to solve problems in polynomial time have worst case running times of $O(n),O(\log n)$ and $O(n^2)$\cite{AIModernApproach}. These classes of problems are easy to solve using modern algorithms available today. Problems that can be solved with these kind of running times are classified as being in the P range of complexity problems\cite{AIModernApproach}.

Another range of problems consists mostly of problems that cannot be solved in polynomial time\cite{AIModernApproach}. Hence, if an algorithm were to try each and every possible solution, it would take an arbitrarily long time, which cannot be determined, which is why these problems also have the characteristic of being non-deterministic\cite{AIModernApproach}. Problems in this range are referred to as being in the NP range of complexity problems\cite{AIModernApproach}.

There is another range of NP problems that are a subset of NP problems, which are referred to as the ``most extreme'' problems within NP\@.  These problems are collectively known as NP-Complete problems and are the most difficult problems to determine feasible solutions for in the NP problem range\cite{AIModernApproach}. The \gls{FAP} is one such problem \cite{AndreasPaper,FixedFAPPSO}.

\section{Constraint Handling mechanisms}
\label{sec:chm}
Not only is the \gls{FAP} an NP-Complete problem but it is also a constraint problem. Constraint problem restrict the search space of possible solutions with boundaries. These boundaries are reffered to as constraints. The \gls{FAP} domain has specific constraints defined for each of the different individual problems. Before the various ways in which frequencies can be allocated is discussed a brief discussion needs to be presented on constraint handling mechanisms.

Constraints define the boundaries of the search space. Solutions found to be violating the constraints are considered to be outside of the search space. Various methods exist how to treat solutions found to be outside of the defined search space. These methods are known to be \emph{constraint handling mechanisms} and are discussed below.

In research done by Engelbrecht\cite{CompuIntelligenceIntro} the following constraint handling mechanisms are defined.
\begin{itemize}
\item{\textbf{Reject infeasible solutions}} --- Solutions that violate the defined constraints are not even considered and rejected.
\item{\textbf{Penalty function methods}} --- Modifies the objective function to add a penalty that is enforced if a solution violates constraints. By adding a penalty the infeasible solutions are discouraged.
\item{\textbf{Convert the constrained problem to an unconstrained problem}} --- By solving the unconstrained problem better solutions can be found although not guaranteed.
\item{\textbf{Preserving feasibility methods}} --- Candidate solutions are initialised in the search space and satisfy all constraints. These solutions are continuously moved or transformed with specialised operators who ensure that the solutions continue to satisfy all the constraints. The operators ensure that all solutions stay within the bounded search space.
\item{\textbf{Pareto ranking methods}} --- Solutions are ranked based on the severity of their constraint violations.
\item{\textbf{Repair methods}} --- Operators are used to transform solutions that violate constraints to solutions that adhere to all the constraints and are thus feasible solutions.
\end{itemize}

Constraint handling methods need to be used when solving constrained problems like the \gls{FAP}. Without these methods, the search for solutions is undirected and solutions that cannot be used are presented as most optimal. Reference to these methods will be made where applicable.

In the next section, two methods are discussed that define how frequencies are allocated.
\section{Frequency Allocation Types}
\label{sec:FreqAssignmentTypes}
In this section the different methods used to allocate frequencies to cells in a cellular network are discussed. Furthermore the method that relates to the specific \gls{FAP} variant in this dissertation is described.

Within the \gls{FAP} domain there are different types of \gls{FAP}, which have emerged over the years as the domain of wireless communications matured and technological requirements changed. These \gls{FAP} variants are discussed in section~\ref{sec:FAPVariants}.

There are a variety of \gls{FAP}s in the wireless communication domain but each individual problem can be classified into one of the following two categories based on the way frequencies are assigned to cells:
\begin{itemize}
  \item \emph{\gls{FFA}} is where frequencies assigned to cells are static; therefore they cannot be changed until a new assignment plan is calculated\cite{PrinciplesMobileCommunication}.
\item \emph{\gls{DFA}} is the process of allocating frequencies to cells as required to meet the current traffic demand imposed on them by clients\cite{PrinciplesMobileCommunication}. 
\end{itemize}

\subsection{Fixed Frequency/Channel Assignment}
\gls{FFA} is the process of permanently assigning frequencies to cells \cite{PrinciplesMobileCommunication}. The frequencies assigned are fixed and cannot be changed immediately while the network is active, since the frequencies assigned to the cell form part of a delicate frequency plan designed to keep interference on communication links to a minimum\cite{PrinciplesMobileCommunication}. 

When the channel used by a particular cell for communication is suddenly changed, the cell might start interfering with neighbouring cells' communication links. This interference is caused because the assigned frequencies of the neighbouring cells are close to each other on the frequency spectrum. Hence, if the cell is sectored (refer to section~\ref{def:cellsector} in chapter two for a discussion on cell sectorisation) it can interfere with a minimum of three and up to a maximum of six neighbouring cells\cite{PrinciplesMobileCommunication}.

When an \gls{FFA} plan is created, cells are assigned frequencies based on the estimated traffic that cell will be expected to handle during peak network usage. \gls{FFA} is ideally suited for macro cellular networks since the nature of the traffic encountered in such networks has the characteristic of being homogeneous, stationary and predictable \cite{PrinciplesMobileCommunication}. Cellular networks can be classified as being in the macro cellular group of wireless networks.

With \gls{FFA}, networks are able to permanently allocate a certain subset of frequencies to cells since the nature of the traffic on their network allows them to predict with reasonable certainty the call blocking probability \cite{PrinciplesMobileCommunication}. A call is blocked on the network when a cell has no available frequencies to use when establishing a communication link \cite{PrinciplesMobileCommunication}.

In situations where the nature of the traffic is neither homogeneous nor stationary, using the \gls{FFA} allocation scheme is not feasible as its use of available frequencies is grossly inefficient \cite{PrinciplesMobileCommunication}.

A problem that occurs with \gls{FFA} when all assigned frequencies are in use is that any new call or call handed over will be blocked\cite{PrinciplesMobileCommunication}. The call will be blocked even if adjacent cells have suitable capacity to handle the call\cite{PrinciplesMobileCommunication}.

\subsection{Dynamic Frequency/Channel Assignment}
\gls{DFA} is a channel allocation scheme where frequencies assigned to cells are not permanent but rather assigned to cells as the need arises\cite{PrinciplesMobileCommunication}. Therefore all the frequencies licensed by a particular network are available to each and every cell to establish a communication link as long as the channel does not violate the co-channel reuse constraint \cite{PrinciplesMobileCommunication}. 

The co-channel reuse constraint must be adhered to otherwise the amount of interference occurring on the communication link will be too much\cite{PrinciplesMobileCommunication}. This constraint forms part of the electromagnetic constraints, which are described in section~\ref{sec:Interference}.

The \gls{DFA} allocation scheme is ideally suited for micro cellular wireless networks. The traffic on these networks have the characteristic of being immensely unpredictable as traffic demand varies constantly\cite{PrinciplesMobileCommunication,MobileWirelessCommunications}.

As the name indicates, micro cellular wireless networks have much smaller cell sizes than macro cellular networks. Thus a cell in a micro cellular network must handle a lot more handover requests than a cell in a macro cellular network, since an \gls{MS} with an active connection is much more likely to move out of the coverage area of a micro cell than a macro cell \cite{PrinciplesMobileCommunication,WirelessCommunications}.

Since a micro cellular network has increased handover requests between cells compared with a macro cellular network, a \gls{DFA} scheme must rapidly allocate frequencies to requesting cells that must handle the handovers\cite{PrinciplesMobileCommunication,WirelessCommunications}.

\gls{DFA} is much more efficient than \gls{FFA} when the amount of mobile traffic on the network is relatively low\cite{PrinciplesMobileCommunication,WirelessCommunications}. On the other hand, when the network is under heavy mobile traffic load, the \gls{FFA} scheme outperforms the \gls{DFA} scheme\cite{WirelessCommunications}. The \gls{DFA} shceme is outperformed because it allocates frequencies to cells in an inefficient arrangement that might affect the amount of interference encountered on the network\cite{MobileWirelessCommunications}.

Finally \gls{DFA} inherently requires a great deal more computational power than \gls{FFA}, since the frequencies need to be selected and allocated with great speed, otherwise the cell requesting a channel will not be able to handle the call and will therefore block the call or drop the call\cite{PrinciplesMobileCommunication,WirelessCommunications}.


This concludes the discussion on the different allocation schemes used in modern cellular networks. In the next section a description is given of what interference is and why it is important for cellular networks. An overview will also be given of when interference occurs.

\section{Interference}
\label{sec:Interference}
Interference can be defined as any unwanted signal that is received along with a signal of interest\cite{WirelessDigitalCommunications}. The unwanted signal is said to \emph{interfere} with the original signal and as a consequence degrades the original signal quality with unwanted information\cite{WirelessDigitalCommunications}.

Interference usually occurs when two or more entities communicate independently on the same channel or on adjacent frequencies\cite{WirelessCommunications,WirelessDigitalCommunications}. Other external factors can also contribute to interference on a communication link, such as machines, which inherently produce some sort of electromagnetic distortion, for instance a car's ignition or a big turbine\cite{WirelessCommunications,WirelessDigitalCommunications}. 
end{figure}
Interference that occurs when two signals operate on the same channel can be seen in figure~\ref{fig:sameinterference} and interference that occurs as a consequence of two signals operating on adjacent frequencies can be seen in figure~\ref{fig:adjacentinterference}.

\begin{figure}[H]
	\begin{centering}
	%
%%% TEXEXPAND: INCLUDED FILE MARKER ./tikz-pics/cochannel.tex
\begin{tikzpicture}[]
	%\draw[step=.5cm,gray,very thin] (-0.5,-0.5) grid(10,5);
	\draw[->](-0.5,0) to node[below=0.25cm]{\tiny{f (Mhz)}} (10,0);
	\draw[->](0,-0.5) to node[left=0.25cm] {\tiny{Power (dB)}} (0,5);
	\draw[pattern=vertical lines,thick] (0,0) parabola bend(3,4) (6,0);
	\draw[pattern=horizontal lines,thick] (0,0) parabola bend(3,2) (6,0);
	\draw[-] (0,2) -- (7,2);
	\draw[-] (0,4) -- (7,4);
	\draw[<->,thick] (6.5,2) to node[right=0.25cm]{\tiny{Wanted frequency}} (6.5,4);
	\draw[->,thick] (6.5,0) to node[right=0.25cm]{\tiny{Interfering Frequency}} (6.5,2);
\end{tikzpicture}
%%% TEXEXPAND: END FILE ./tikz-pics/cochannel.tex
	\caption{Co-channel interference}
	\label{fig:sameinterference}
	\end{centering}
\end{figure}
\begin{figure}[H]
	\begin{centering}
	%
%%% TEXEXPAND: INCLUDED FILE MARKER ./tikz-pics/adjchannel.tex
\begin{tikzpicture}[]
	%\draw[step=.5cm,gray,very thin] (-0.5,-0.5) grid(10,5);
	\draw(-0.5,0) -- (10,0);
	\draw(0,-0.5) -- (0,5);
	\draw[pattern=crosshatch dots,even odd rule] (0,0) parabola bend(2.5,4) (5,0) (4.5,0) parabola bend(7,4) (10,0);
	\draw[-] (2.5,0) -- (2.5,4.5);
	\node (interference) at (4.75,3.25) {\tiny{Interference}};
	\draw[<-] (4.75,0.25) -- (interference);
	\draw[-] (7,0) -- (7,4.5);
	\draw[<->] (2.5,4.25) -- (7,4.25);
\end{tikzpicture}
%%% TEXEXPAND: END FILE ./tikz-pics/adjchannel.tex
	\caption{Adjacent channel interference}
	\label{fig:adjacentinterference}
	\end{centering}
\end{figure}

The impact interference will have on an entity that has established a connection and that operates on the same channel or adjacent channel as another entity decreases as the geographic distance between them increases\cite{InterferenceOrientatedFAP}. Therefore, to minimise the impact interference will have on communication links a \emph{separation} is defined\cite{WirelessCommunications}. More specifically, this separation is known as the channel reuse or frequency reuse distance within wireless networks\cite{WirelessCommunications}.

This separation is defined as the minimum number of cells (which must all use different frequencies) between one cell, which has been allocated a channel, and another cell before a cell is allowed to reuse the same channel that another cell has been allocated\cite{WirelessCommunications,InterferenceOrientatedFAP}. 

The separation can be depicted visually as in figure~\ref{fig:seperationgraph} where $f_a,f_b,f_c,f_d$ are different frequencies that are assigned to the specific cells. The frequency $f_a$ is allowed to be reused since the two cells it is assigned to are separated by three cells (shaded in grey) because the separation for this network was set to three.

\begin{figure}[H]
	\begin{centering}
	%
%%% TEXEXPAND: INCLUDED FILE MARKER ./tikz-pics/SeparationGraph.tex
\begin{tikzpicture}[node distance=0cm]
	\foreach \x in {0,1.5,3,4.5}
	{
		\node [regular polygon,regular polygon sides=6,minimum size=1cm,draw] at (\x,1){};
	}
	\foreach \x in {0.75,2.25,3.75}
	{
		\node [regular polygon,regular polygon sides=6,minimum size=1cm,draw] at (\x,0.57){};
		\node [regular polygon,regular polygon sides=6,minimum size=1cm,draw] at (\x,1.43){};
	}
	\node [regular polygon,regular polygon sides=6,minimum size=1cm,draw,fill=gray!40] at (1.5,1.87){\tiny{$f_b$}};
	\node [regular polygon,regular polygon sides=6,minimum size=1cm,draw,fill=gray!40] at (3,1.87){\tiny{$f_d$}};
	\node [regular polygon,regular polygon sides=6,minimum size=1cm,draw] at (4.5,1.87){};
	\node (cella) [regular polygon,regular polygon sides=6,minimum size=1cm,draw] at (0.75,2.29){\tiny{$f_a$}};
	\node (cellb) [regular polygon,regular polygon sides=6,minimum size=1cm,draw,fill=gray!40] at (2.25,2.29){\tiny{$f_c$}};
	\node (cellc) [regular polygon,regular polygon sides=6,minimum size=1cm,draw] at (3.75,2.29){\tiny{$f_a$}};
	\node (fa) at (cella) [above=1cm]{};
	\node (fc) at (cellc) [above=1cm]{};
	\draw[<->,thick] (fa) to node [above=0.15cm] {\tiny{3 cells}} (fc) ;
	\draw[dashed] (cella.center) -- (fa.north);
	\draw[dashed] (cellc.center) -- (fc.north);
\end{tikzpicture}
%%% TEXEXPAND: END FILE ./tikz-pics/SeparationGraph.tex
	\caption{Frequency Separation}
	\label{fig:seperationgraph}
	\end{centering}
\end{figure}


As discussed earlier, cellular networks are forced to reuse their licensed frequencies multiple times to keep costs to a minimum. Therefore, the design of a cellular network is limited to the defined separation distance between cells as it defines the size of cells that will be in the network\cite{Eisenblatter,InterferenceOrientatedFAP}. Smaller cells can lead to a larger separation distance compared with when cells are larger\cite{WirelessCommunications,WirelessDigitalCommunications}.

Cellular networks use the amount of interference on their networks as a qualitative measure for their \gls{QoS}\cite{WirelessCommunications}. A network with high interference would experience a lot of dropped connections/calls, which occurs when the interference is too high to sustain a connection or call for communication; consequently their \gls{QoS} degrades as interference increases\cite{WirelessCommunications,WirelessDigitalCommunications}.

Even though interference can cause a call or connection to be lost, i.e.\ dropped, there are other situations where a call can be dropped\cite{GSMSysEngin}. A situation where a call can be dropped is when a handover procedure occurs between two cells and one cell receiving the call is at full utilisation of its allocated frequencies\cite{GSMSysEngin,WirelessDigitalCommunications}. Another situation can be due to weather conditions. Weather brings forth natural interference or the caller entering a building which drastically reduces cellular reception\cite{WirelessDigitalCommunications}.

In the literature a variety of methods are used to calculate the amount of interference in a network. The \gls{SIR} ratio is the recommended way of calculating the potential interference at a certain point \cite{Karen2004}. 

The \gls{SIR} equation is actually based on the \gls{SINR} but since cellular networks are interference limited, the noise is not considered in the interference calculation\cite{WirelessCommunications}. Noise can be disregarded since the power of interference is much larger than the power of noise\cite{WirelessDigitalCommunications}.

A formulation of the \gls{SINR} and \gls{SIR} is as follows:

\begin{align}s 
	SINR &= \frac{P_r}{N_0 + P_I}\\
	SIR &= \frac{P_r}{P_I}
\end{align}
Where $P_r$ is the power of the received signal and $P_I$ is the power associated with interference from within a cell (intracell interference) and interference from outside a cell (intercell interference)\cite{WirelessCommunications}.

This calculation can be considered a best guess as it models the environment, weather and other factors which may influence the potential interference at a point with a Gaussian distribution with standard deviation for noise represented by the $N_0$\cite{Karen2004}. 

Using the \gls{SIR} formula cellular networks are able to determine the \gls{BER} users on the network will experience on their connections\cite{WirelessDigitalCommunications}. The \gls{BER} is defined as the probability that a received bit on the connection will be incorrect\cite{MobileWirelessCommunications}. 

As the \gls{BER} increases voice quality on the connection decreases since more bits that are used to describe the voice information are incorrectly received\cite{WirelessDigitalCommunications}. \gls{SIR} and \gls{BER} probability are interlinked. As \gls{SIR} increases, i.e. less interference is encountered on the communication link, the probability that bits will be received incorrectly decreases\cite{WirelessDigitalCommunications}.

Whether precise measurements are taken or the interference is calculated based on the \gls{SIR} formula, the end result of both methods is that all the calculated or measured values are put into a matrix to produce an \emph{interference matrix}\cite{ACOvsEA}.

An interference matrix consists of a number of cell pairs (\emph{i,j}), where \emph{i} is the cell receiving interference and \emph{j} the cell whose allocated channel is providing the interference\cite{Karen2004}. Each cell pair in the matrix has two corresponding values that indicate the level of interference if the \emph{electromagnetic constraints} are violated \cite{ACOvsEA,AndreasPaper}. 

Primarily interference occurs when the electromagnetic constraints are violated. These constraints are defined as:
\begin{description}
\item[Co-channel] --- As discussed earlier, when cell \emph{i} and cell \emph{j} operate on the same channel interference will occur \cite{GSMSysEngin,PrinciplesMobileCommunication}. When this type of interference occurs it is referred to as \emph{co-channel} interference.
\item[Adjacent channel] --- When cell \emph{i} and cell \emph{j} operate on adjacent frequencies, their allocated frequencies differ by one, i.e.\ cell \emph{i} operates on channel \emph{f}, then if cell \emph{j} operates on either channel \emph{f - 1} or \emph{f + 1}, then interference will occur\cite{GSMSysEngin,InterferenceOrientatedFAP}. This type of interference is referred to as \emph{adjacent channel} interference.
\end{description}

The electromagnetic constraints defined above are applicable in any wireless network. With regard to mobile telecommunication networks, such as cellular networks, there are additional constraints that are imposed due to technological requirements, availability, location and size of area with unacceptable interference \cite{Karen2004,Eisenblatter,AndreasPaper}. These constraints are defined as the following:
\begin{description}
\item[Co-site] --- If cell \emph{i} and cell \emph{j} are located at the same site, then their allocated channel ranges must differ by a certain distance in the frequency domain. This distance is known as the reuse distance where cell \emph{i} and cell \emph{j} serve different sectors\cite{FixedFAPPSO,EgyptFAPPSO}. In the benchmarks which are discussed in section~\ref{sec:FAPBenchmarks} this distance is also referred to as the \emph{separation variable}. 
\item[Co-cell] --- Channels used on the same antennae of a cell must differ by a certain number. This is typically set to three but can be any number greater than zero that the network operator deems necessary to avoid unwanted interference\cite{Karen2004,Eisenblatter,AndreasPaper}.
\item[Handover] --- This constraint means that frequencies must differ by a predefined margin, i.e. two or three, when one cell hands over a call to another cell. If this constraint is violated a mobile subscriber will experience a dropped call since the handover between cells fails\cite{Karen2004,Eisenblatter,AndreasPaper}.
\end{description}

Within the licences of wireless networks there are two hard constraints which forbid networks from using certain frequencies. Hard constraints means that under no circumstances are these constraints allowed to be violated.

The first set of hard constraint frequencies is known as \emph{globally blocked frequencies}. Frequencies that are in the set of globally blocked frequencies are usually frequencies that have been licensed to other networks\cite{Karen2004,InterferenceOrientatedFAP}.

The second set of hard constraint frequencies is known as \emph{locally blocked frequencies}. These frequencies are not allowed at certain geographic areas but are free for use at any other area\cite{InterferenceOrientatedFAP}. A typical area where certain frequencies will be forbidden to be used is near a country border\cite{InterferenceOrientatedFAP}. The locally blocked frequencies are most likely in use by another network resident to the bordered country.

In this section a description was given of what interference is and what the consequences are of too much interference in a network. This section further elaborated on the circumstances in which interference can occur in a wireless network. In the next section an overview is given of the various different sub problems in the \gls{FAP} domain.


\section{Frequency Assignment Problem types}
\label{sec:FAPVariants}
In this section each of the problem variants for the \gls{FAP} is discussed, starting with one of the first and oldest problems in the \gls{FAP} domain. This section will conclude with a discussion on the particular variant of \gls{FAP} focussed on in this research.
\subsection{Minimum Order Frequency Assignment Problem}
The \gls{MO-FAP} was the first \gls{FAP} that emerged in the 1970s. The \gls{MO-FAP} is concerned with assigning frequencies to transmitters while interference is minimised as well as minimising the number of different frequencies that are used\cite{Karen2004}. 

In \gls{MO-FAP} channel reuse is prioritised and the usage of a channel has a certain cost associated with it. The reason for this is that when the wireless network industry started, operators were billed according to the number of different frequencies they used. In the beginning of commercial cellular networks frequencies were not cheap since they were sold per unit \cite{MontemanniThesis}. 

Over the years as the law governing the wireless spectrum changed and new technology as well as standards emerged, \gls{MO-FAP} lost its relevancy\cite{Karen2004,MontemanniThesis}. Companies are no longer billed according to the different frequencies they use, but they purchase licences from a regulatory body\cite{Karen2004,MontemanniThesis}. This licence usually stipulates what channel band the network is allowed to use.

In some instances a certain band of frequencies is put up for auction by a regulatory body, on which interested parties can bid to own the specified spectrum\cite{Karen2004,MontemanniThesis}. Due to the shift in how frequencies are allocated to networks, neither the regulatory bodies nor the network operators care about the number of different frequencies are used\cite{Karen2004,MontemanniThesis}.
\subsection{Minimum Span Frequency Assignment Problem}
The \gls{MS-FAP} is a problem that is very relevant today, especially when network operators want to deploy a new network in a region\cite{Karen2004}. The \gls{MS-FAP} is concerned with keeping the interference below a certain level during assignment as well as minimising the span\cite{MSFAP}. The interference threshold used is specified by the network designer as the minimum allowable interference on the network\cite{MSFAP}.

The span is defined as an interval on the frequency domain. This interval is the difference between the maximum and minimum frequencies used during assignment\cite{Karen2004,MSFAP}. With the span value, network operators are able to request certain frequency bands and know their network will be able to operate at suitable interference levels \cite{Karen2004,MSFAP}.

The \gls{MS-FAP} and \gls{MO-FAP} are two very similar problems, the only difference being that \gls{MO-FAP} focuses on minimising different frequencies and \gls{MS-FAP} focuses on minimising the interval of frequencies used during assignment \cite{Karen2004}. The Philadelphia benchmark is usually used to gauge how well the algorithm performs.
\subsection{Minimum Interference Frequency Assignment Problem}
The \gls{MI-FAP} or \gls{FS-FAP} is encountered after the network operator has obtained a frequency band from a regulatory body\cite{Karen2004}.

Unlike the previous problems, in \gls{MI-FAP} any available channel in the allocated band may be used even though it produces interference. The other problems are concerned with the frequencies used, even though they might be violating some constraints that incur a huge amount of interference\cite{MontemanniThesis,MultipleBinaryFAP}. The interference value does not play a large role in their respective objective functions\cite{Eisenblatter,MultipleBinaryFAP}. In \gls{MI-FAP} the objective is to minimise the total amount of interference on the network. It is important to note that this amount of interference might not necessarily be zero \cite{Karen2004,Eisenblatter}.

The \gls{MI-FAP} is the problem currently most encountered in cellular networks, since there are more operating networks than new networks being designed in the cellular industry today\cite{Karen2004}. This particular problem forms the focus of this research. 

Since \gls{MI-FAP} is very close to real-world instance problems, authors tend to use real-world instances or benchmarks to test the quality and efficiency of their algorithms \cite{Eisenblatter,MontemanniThesis}. The quality and efficiency of the solution in this research is benchmarked against the \gls{COST} 259 benchmark ,which is discussed in section~\ref{sec:FAPBenchmarks}.

In the following section a formal mathematical definition for the fixed spectrum \gls{MI-FAP} is set out. The definition is important as it forms the basis for the objective/cost function that the algorithm in this research uses.
 
\section{FS-FAP Mathematical Formulation}
\label{sec:FAPMathDef}
A Mathematical definition of the \gls{FAP} is given in this section. The mathematical definition is used by the algorithm discussed in this dissertation to evaluate the amount of interference that generated frequency plans exhibit.

The \gls{FAP} can be represented as a graph colouring problem and is known to be NP-Complete. Before a mathematical definition can be formally given for the \gls{FAP}, some symbols and their respective definitions need to be introduced.

\begin{align}
	G &= (V,E) \label{E:setG}\\
	V &= \{v_{0},v_{1},\ldots,v_{i}\} | i \in \mathbb{N} \label{E:setV}\\
	E &= \{\{v_0,v_1\},\{v_0,v_2\},\ldots,\{v_i,v_j\}\}|v \in V,\forall ij \in \mathbb{N},i \neq j \label{E:setE}\\
	D &= \{d_{01},d_{02},\ldots,d_{ij}\}| \forall\{i,j\} \in E, \exists d_{ij} \in \mathbb{N}^+ \label{E:setD}\\
	P &= \{\{\bar{p_{00}},\overset{=}{p_{01}}\},\{\bar{p_{10}},\overset{=}{p_{11}}\},\ldots,\bar{p_{i0}},\overset{=}{p_{i1}}\}\}| \forall \{i,j\} \in E,\exists p_{ij} \in \mathbb{N}^+ \label{E:setP}\\
	F &= \{0,1,2,3,\ldots,k\}| \forall k \in \mathbb{N},\forall v \in V \exists f \in F\label{E:setF}\\
	d_{ij} &< |f(i) - f(j)|, \forall ij \in \mathbb{N},i \neq j \label{E:interference}
\end{align}

Let $G$ (see equation~\ref{E:setG}) be a weighted undirected graph, where $V$ (see equation~\ref{E:setV}) is a set of vertices\cite{MontemanniThesis}. Each $v \in V(G)$ represents a transmitter in the \gls{FAP}\cite{MontemanniThesis}. 

The variable $E$ in equation~\ref{E:setE} represents a set of edges\cite{MontemanniThesis}. An edge consists of two vertices $v_i$ and $v_j$ that are joined because there is a constraint on the frequencies that can be assigned between the two vertices or transmitter\cite{MontemanniThesis}s. Each edge has two associated labels $d_{ij}$ and $p_{ij}$ \cite{FAPOrientationModel,TabuMontemanniSmith}. 

The label $d_{ij}$ that is part of the set $D$ (see equation~\ref{E:setD}) denotes the maximum separation that is required between frequencies assigned to two transmitters $v_i$ and $v_j$. $f(i)$ denotes the frequency assigned to $i$. Using equation~\ref{E:interference} the amount of interference that is generated between transmitters $v_i$ and $v_j$ can be determined\cite{FAPOrientationModel,TabuMontemanniSmith}.

The other label, $p_{ij}$, forms part of the set $P$ (see equation~\ref{E:setP}) which is referred to as the interference matrix (discussed in section~\ref{sec:Interference})\cite{Eisenblatter}. Each label $p_{ij}$ contains two values which represent interference:
\begin{itemize}
\item $\bar{p_{i0}}$ represents the value for co-channel interference \cite{FAPOrientationModel,TabuMontemanniSmith}. 
\item $\overset{=}{p_{i1}}$ represents the value for adjacent channel interference\cite{FAPOrientationModel,TabuMontemanniSmith}.
\end{itemize}

Finally the set $F$ (see equation~\ref{E:setF}) denotes a set of consecutive frequencies for every transmitter in $V$\cite{FAPOrientationModel,TabuMontemanniSmith}.

Formally the \gls{FS-FAP} can now be defined \gls{FS-FAP} $= (V,E,D,P,F)$ with a required mapping of $f: V \rightarrow F$\cite{TabuMontemanniSmith}. The objective of the \gls{FS-FAP} is to find an assignment of frequencies to transmitters that minimise the sum of total interference (see equation~\ref{E:costFunction}). 

The interference value for a single transmitter is represented by $c(p_i)$ which is based on equation~\ref{E:interferenceCases}. In equation~\ref{E:interferenceCases} the co-channel interference value is represented by $\bar{p_{i0}}$ and the adjacent-channel interference value is represented by $\overset{=}{p_{i1}}$.

\begin{align} 
 \label{E:interferenceCases}
 c(p_i) &= 
 \begin{cases}
	\bar{p_{i0}} &,\text{if $|f(i) - f(j)| = 0$}\\
	\overset{=}{p_{i1}} &, \text{if $|f(i) - f(j)| \leqslant d_{ij}$}\\
	0 &,\text{if $|f(i) - f(j)| > d_{ij}$}
 \end{cases}\\
 \label{E:costFunction}
 Total Interference &= \sum^{|P|}_{i = 0}c(p_i),p \in P 
\end{align}

In the following section a brief discussion on the different \gls{FAP} benchmarks that exist is provided and the benchmark against which the algorithm developed in this research is evaluated is defined.
\section{FAP Benchmarks}
\label{sec:FAPBenchmarks}
Some of the most used benchmarks in the \gls{FAP} domain are now discussed. The first benchmark was introduced in the 1970s.
\subsection{Philadelphia Benchmarks}
The Philadelphia benchmarks are derived from an instance that was introduced in 1973 by Anderson\cite{AndersonPhiladelphia}. Each instance is a hexagonal grid of cells that overlaps the area of interest. At the centre of each cell there is a transmitter. Past approaches used these hexagonal systems to model modern cellular networks \cite{Karen2004,ExactMIFAP}.

In this benchmark interference is measured by a co-channel reuse distance\cite{Karen2004}. This distance stipulates that the difference between the frequencies  assigned to two cells must be greater than or equal to a certain value $d$. A channel cannot be assigned to a cell if it violates this minimum distance \cite{ExactMIFAP}.

These benchmarks are typically used to test algorithms developed for \gls{MS-FAP}, since there is no concept of cost or penalty for interference incurred by violating constraints.
\subsection{CELAR}
In 1994 \gls{EUCLID} introduced a project called CALMA, which was a combined effort by several European governments that were part of \gls{EUCLID} to investigate algorithms for military applications\cite{Karen2004}. The project was granted to six research groups. Within the project 36 instances were made available by the \emph{Centre d'ELectronique de l'ARmement} (CELAR) for radio link frequency assignment \cite{Karen2004,DynamicFAP}.

All the CELAR instances have the constraint that the difference between frequencies assigned to interfering radio links must be greater than a certain predefined distance in the frequency domain\cite{Karen2004}. This is a soft constraint and may be violated. Another constraint in the CELAR instances is that each pair of parallel links must differ by an exact predefined distance\cite{Karen2004}. This constraint is a hard constraint and may not be violated \cite{DynamicFAP}.

These instances were initially not available to the general public as they were contained to be within the CALMA project\cite{CALMA}. In 2001 the CELAR launched the International ROADEF challenge, where certain instances from the CALMA project were made available for the research teams taking part in the challenge\cite{CALMA}. The instances made available had been modified to take polarisations and controlled relaxations of certain EMC constraints \cite{LowerPolarFAP}.
\subsection{COST 259}
\label{sec:COST259}
The \gls{COST} 259 is a set of real-world \gls{gsm} instances made available by the European Union. The instances are publicly available and can  be downloaded for free at http://fap.zib.de/ (FAP Web 2011). The website also contains the most recent results obtained by researchers using these instances\cite{Karen2004,Eisenblatter}.

The instances are difficult due to the large number of transmitters (900 - 4 000) that need to be assigned frequencies, with a relatively small number of spectrum of frequencies. The most important characteristic of these benchmarks are that they resemble real-world \gls{gsm} network data. Due to these benchmarks' real-world applicability, they were selected as the main benchmarks to evaluate the algorithm presented in this dissertation.

More specifically this research concentrates on a small subset of the instances that are available, namely Siemens1, Siemens2, Siemens3 and Siemens4. In the paper by Montemanni and Smith \cite{TabuMontemanniSmith} the same subset of problems was used and to date their algorithm has produced some of the best results. 

As discussed in section~\ref{sec:chm} constraint handling mechanisms need to be used for problems like the \gls{FAP}. Each of the Siemens benchmarks define a set of globally or locally blocked frequencies which are hard constraints. Due to this constraint one of the mechanisms that will be used in the algorithm to handle solutions violating this constraint is \emph{to reject any solutions that is found to violate this hard constraint}. The characteristics of each instance will now be discussed.


\subsubsection{Siemens1}
The Siemens1 instance resembles a \gls{gsm} network that follows the \gls{gsm}900 standard. This particular network has been allocated a spectrum set of frequencies $F = \{16,17,18,\dots,90\}$ which are allowed to be assigned to cells. 

Not all 74 frequencies are available to be used by the network. The allocated frequency block is split into two blocks. According to the problem instance frequencies ranging from $F= \{36,37,38,\dots,67\}$ are globally blocked. Only frequencies ranging from $F= \{16,17,\dots,35\}$ and $F= \{68,69,70,\dots,90\}$ therefore available for assignment.

This problem instance finally also defines this network as consisting of a total of 506 cells where on average each cell has 1.84 transceivers that need to be assigned a frequency. The co-site separation is stated to be two and the co-cell separation is stated to be three.
\subsubsection{Siemens2}
The Siemens2 problem instance describes a \gls{gsm} network based on \gls{gsm}900 and has 86 sites. The problem specifies that the network consists of 254 cells where each cell has on average 3.85 transceivers that need to be assigned frequencies.

For this problem, the network has been allocated two blocks of frequencies: one block of four frequencies ranging from $F = \{42,43,44,45,46\}$ and a second block of frequencies ranging from $F= \{53,54,55,\dots,124\}$. The frequencies allocated to the network have been split into two blocks because frequencies ranging from $F = \{47,48,49,50,51,52\}$ are globally blocked. Finally the problem specifies that the co-site separation must be set to two and the co-cell separation must be set to three.
\subsubsection{Siemens3}
The Siemens3 problem describes a network based on \gls{gsm}900. This network has been allocated a continuous set of frequencies $F= \{681,682,683, \dots, 735\}$. Thus the network has 55 frequencies, which can be allocated to transceivers in its network.

The problem defines the network as consisting of 366 sites and 894 cells. On average each cell has 1.82 transceivers that need to be allocated a frequency to handle communication.
\subsubsection{Siemens4}
The Siemens4 instance is similar to a \gls{gsm} network that follows the \gls{gsm}900 standard. According to this instance this network has been allocated 39 continuous frequencies starting at 56, thus $F = \{56,57,58,\dots,94\}$. No frequencies are said to be globally or locally blocked in this network.

According to this problem instance this network has 276 sites and consists of 760 cells. Where each cell is said to have on average 3.66 transceivers. The Co-site separation is set to be two and the co-cell separation must be three.

In the next section a general overview is given on the different industries where the \gls{FAP} is encountered. The purpose of this discussion is to get a better understanding about how far reaching the problem is and the different forms the problem is encountered in.
\section{FAP in the Industry}
\label{sec:FAPIndustry}
FAP is a real-world problem that is encountered in industries that make use of wireless technology for wireless communication\cite{Karen2004}. For each industry listed, a brief overview is given of how the problem differs compared with other industries. 

\subsection{Satellite Communication}
The \gls{FAP} in the satellite communication domain occurs in the ground terminals that transmit and receive signals via a satellite\cite{Karen2004}. One would assume that the problem includes the satellite as it handles a variety and order of magnitude more connections than a ground station at any given moment. In fact, the problem is only concerned with the frequencies that the ground terminals use\cite{Karen2004}.

In Satellite communication, a signal is transmitted to one or more satellites via an uplink from a ground terminal\cite{Karen2004}. The signal is received by the recipient satellite and relayed via downlink to those ground terminals which have expressed interest in signals from other ground terminals\cite{Karen2004}.

 A large distance in the frequency domain separates the frequencies used by the ground terminals for uplink and downlink communication. The typical distance is much larger than the bandwidth. When frequencies are assigned to transmitters, downlink transmitters are ignored and only uplink transmitters are considered \cite{Karen2004}. 

A radical difference with regard to the use of frequencies compared with the standard \gls{FAP} in cellular networks is that frequencies are only allowed to be used once\cite{Karen2004}. This is specific to the satellite domain to avoid interference\cite{Karen2004}.

\subsection{Wireless Mesh Networks and Wireless Local Area Networks (WLANs)}
Wireless mesh networks and WLANs are the most recent applications where the \gls{FAP} is encountered. 

Multiple WLANs are increasingly being used to provide backbone support for large fixed line networks, enterprise networks, campuses and metropolitan areas\cite{MultiradioMeshNetworks}. To be able to provide backbone support for these networks, a primary design goal when designing and deploying these networks is capacity\cite{MultiradioMeshNetworks}. A limiting factor for WLAN capacity is interference, which affects multihop hop settings. Thus the overall network interference needs to be minimized to increase the capacity of the network \cite{MultiradioMeshNetworks}. 

Typical approaches allocating frequencies include using \gls{DFA} and \gls{FFA} (discussed in section~\ref{sec:FreqAssignmentTypes}). \gls{DFA} is not very popular because the dynamic switching of frequencies lowers the response time on commodity hardware since there is a delay in milliseconds when switching frequencies. Typical packet transmission times are in microseconds. To guarantee uptime and high responsiveness, \gls{FFA} is the preferred approach \cite{MultiradioMeshNetworks}.

The \gls{FAP} in wireless mesh networks and WLANs differs from the standard problem in that it introduces an extra constraint. Channels assigned to links on a node cannot be more than the available interfaces on that particular node. This constraint is known as the \emph{interface constraint} \cite{MultiradioMeshNetworks}. Another aspect to consider is the placement of access points (APs) in the network, which is similar to the problem cellular networks face with regard to base station placement \cite{Karen2004}.

\subsection{Military Field Communication}
In a military context the \gls{FAP} is a very difficult problem to be solved due to its dynamic nature\cite{CALMA}. During deployment, connections need to be established rapidly between nodes which guarantee that the nodes will stay static at locations. Usually nodes are military field phones or can be any transceiver device \cite{CALMA,DynamicFAP}. 

Due to the nature of the problem the \gls{DFA} scheme is used to allocate frequencies to nodes. The military \gls{FAP} has the property that any of the nodes are mobile and can move at any moment to a new location, potentially interfering with another connection\cite{CALMA,DynamicFAP}. This property differs from the traditional \gls{FAP} where the nodes that are allocated frequencies are stationary\cite{CALMA}. Two frequencies need to be assigned to each connection that is established, one for each direction of communication. These allocated frequencies must also differ by a certain distance in the frequency domain to prohibit alternating directions of communication from interfering\cite{CALMA,DynamicFAP}.

A lot of literature can be found on Military field communication. This is due to two organizations CELAR and \gls{EUCLID} making data available to various research groups and allowing them to develop algorithms for frequency assignment \cite{CALMA,DynamicFAP}. 

\subsection{Television and Radio Broadcasting}
The \gls{FAP} encountered in broadcasting very closely resembles the problem domain found in cellular networks\cite{Karen2004}. The only notable difference is that the required distance by which allocated frequencies must differ in the frequency domain are larger in broadcasting than in cellular networks \cite{Karen2004}.

Since the problem resembles the problem found in cellular networks, there are few articles that specifically discuss frequency assignment in broadcasting as a main topic. Research that specifically discusses \gls{FAP} in broadcasting has been conducted by Idoumghar and Schott \cite{RadioFAP}.
\subsection{Cellular Communication}
Cellular communication (see chapter 2 for a discussion) can be considered the main driving force behind research in the frequency assignment domain. As new standards are developed and used in 3G networks, in general an \gls{FAP} still needs to be solved since these newer technologies still use \gls{gsm} as their backbone architecture, as discussed in section~\ref{UMTSGSMBackbone}. With new networks being deployed or current networks being expanded, standard \gls{gsm} is used as it is cheaper than using the latest 3G technology. Therefore, standard \gls{gsm} is still relevant and in use in modern networks.

There is a wealth of research that concentrates on the \gls{FAP} within cellular networks. This is because cellular networks are used by millions of people around the world and as such this presents an interesting notion to produce better results since viable solutions have the possibility to impact millions of people. Most of the literature concentrates on this domain and one can find a lot of research in the literature presenting viable algorithms that produce real-world solutions \cite{Eisenblatter}. 

Because the \gls{FAP} problem is NP-Complete most presented algorithms are either of the metaheuristic type or more recently of the swarm intelligence type. Both of these algorithmic types are discussed in chapters 4 and 5 respectively.
\section{Summary}
In this chapter a discussion was presented on the problem this dissertation is based upon. The problem was defined as being the \gls{FAP} and is categorised as being part of the set of NP-Complete problems. The NP-Complete nature of the problem is an important concept to understand.

Within the \gls{FAP} domain there are two different techniques when assigning frequencies. The two different techniques were discussed in section~\ref{sec:FreqAssignmentTypes}. 

An important concept that needs to be understood to comprehend why the \gls{FAP} exists is the concept of interference. This was discussed in depth in section~\ref{sec:Interference}.

The \gls{FAP} is not just one problem but consists of various sub problems that have different goals for the resulting frequency plan. Some problems are concerned with the number of frequencies used, others are more concerned with the amount of interference that is generated on the network.

The various \gls{FAP} sub problems were outlined and discussed in section~\ref{sec:FAPVariants}.

A formal mathematical definition of the \gls{MI-FAP} was also presented. Finally, this chapter concluded with a discussion on the on the different industries where the FAP is encountered and how the problem is handled.
%%% TEXEXPAND: END FILE ./chpt3.tex
%%% TEXEXPAND: INCLUDED FILE MARKER ./chpt4.tex
\chapter{Metaheuristic Algorithms}
\label{chpt:heuristic}
\section{Introduction}
Metaheuristics is a subdomain of the \gls{AI} domain\cite{AIModernApproach}. It evolved out of a need for more efficient search techniques with regard to hard problems. 

Metaheuristics forms part of a collective body of algorithms that use heuristics to search a particular domain's search space for the most optimal solution\cite{AIModernApproach,NatureInspiredMetaHeuristic}. Some problems explicitly define constraints to which the produced solution must adhere to. Problems that define such constraints are referred to as constraint optimisation problems\cite{FundamentalSwarm}. Problems where there are either no constraints or just a boundary constraint  defined are referred to as unconstraint problems\cite{FundamentalSwarm}.

Constraints can be either hard or soft. A hard constraint is defined as a certain condition an algorithm or potential solution is not allowed to violate\cite{AIModernApproach,NatureInspiredMetaHeuristic,Karen2004,Eisenblatter}. A soft constraint is allowed to be violated but there is some sort of penalty or cost involved which is imposed onto the potential solution, which lowers its desirability\cite{AIModernApproach,NatureInspiredMetaHeuristic,Karen2004,Eisenblatter}. 

An optimal solution would therefore be any solution that violates no hard constraints and violates no or a minimum number of soft constraints\cite{AIModernApproach,NatureInspiredMetaHeuristic,Karen2004,Eisenblatter}. Algorithms that are classified as being part of the collective body of algorithms known as metaheuristic algorithms are Tabu Search\cite{TabuVechicleRoutingWithTimeWindows,TabuCSP}, Simulated Annealing \cite{SASingleMultiObj,CurveFittingSA} and Genetic Algorithm\cite{GATSP, GeostatisticalGA}.

The above-mentioned algorithms are not the only algorithms to form part of this subdomain, but they are the algorithms that have received the most attention in the literature and produce good results\cite{SweepMeta}.

The main focus of this chapter is on each of the above algorithms. Before each of the algorithms is discussed, a brief overview is given of the various characteristics that metaheuristic algorithms exhibit. 

\gls{AI} search algorithms operate in search spaces, where they occupy various states while they are searching for a solution or goal state in a search space. Before these algorithms can be properly introduced, the concept of search spaces and states needs to be introduced.

\section{Search Spaces and States}
A search space is defined as a set of candidate goal states which may or may not be a solution to an problem\cite{AIModernApproach}. The candidate states are defined by the problem definition\cite{AIModernApproach}. The possible states can be given by a successor function which generates new states adhering to the problem defined constraints if any\cite{AIModernApproach}. 

The search space can also be explicitly defined with constraints to which a solution must adhere to\cite{AIModernApproach}. When constraints are defined it is up to the algorithm how it moves from one state to another in the search space\cite{AIModernApproach}. Each state the algorithm moves to is then checked whether it adheres to the constraints\cite{AIModernApproach}.

A state is a position in the search space\cite{AIModernApproach}. This position represents a configuration that describes a possible solution to the defined problem\cite{AIModernApproach}. When a algorithm is said to be moving to a new state, the algorithm moves to a new position in the search space\cite{AIModernApproach}. This new position represents a different solution than the previous position that was occupied\cite{AIModernApproach}.

When dealing with an optimisation problem there can be more than one solution\cite{AIModernApproach}. Which is why with optimisation problems not only does an algorithm have to find a solution, but also the most optimal solution among the candidate solutions\cite{AIModernApproach}. This subset of solutions in the search space is referred to as the \emph{solution} space.

Both concepts of search spaces and states have now been defined. All search algorithms operate in search spaces and occupy states. The domain of search contains a wide variety of algortihms. In the next section Metaheuristics Algorithms are discussed as this body of algorithms are used to solved optimisation problems.

\section{Metaheuristics Algorithms}
NP-Complete\footnote{A discussion of NP-Complete problems is appears in section \ref{sec:NPComplete}} problems have been proven to not be solvable in polynomial time by traditional uninformed search algorithms such as Breath First Search and Depth-First Search\cite{AIModernApproach}. 

Uninformed algorithms are not able to distinguish whether a particular goal state is more ``correct'' than any other goal state\cite{AIModernApproach}.

Uninformed search algorithms search spaces are represented by a tree structure\cite{AIModernApproach}. A search is performed in the search space by starting at a root node, the algorithm expands successive nodes based on a strategy\cite{AIModernApproach}. Bread-first search continiously expands all successive nodes and Depth-First search expands the deepest node first\cite{AIModernApproach}.

The path taken to a final  goal state node represents a solution\cite{AIModernApproach}. In a worst-case scenario, an uninformed search will expand every single node in its search space, thus each and every single possible solution is evaluated\cite{AIModernApproach}.

It is not always viable to test every possible solution in a given problem search space, especially in NP-Complete problems, since their search spaces are huge or infinite. This is why traditional algorithms are not able to produce optimal solutions in polynomial time\cite{AIModernApproach}.

Metaheuristic algorithms are considered to be \emph{general-purpose} algorithms and can thus be applied to a wide variety of optimisation problems with only small modifications that need to made to the algorithm model\cite{MetaGraph}.

Metaheuristic algorithms do not dictate all aspects of the search procedure but define guidelines and aspects which directs the search\cite{HandbookofMH}. Therefore a metaheuristic can be defined as follows: \emph{the algorithm selects candidate solutions from a neighbourhood with respect to one or more current solutions of which the candidates are either rejected or accepted}\cite{HandbookofMH}.

As can be gathered from the name, a metaheuristic algorithm uses some sort of heuristic. A heuristic is a decision rule. Algorithms use heuristics to make decisions by applying the heuristic to the data the algorithm is currently working on\cite{AIModernApproach,NatureInspiredMetaHeuristic}.

When an algorithm utilises a heuristic its forms part of a group known as informred search algorithms. As the name implies the algorithm is more ``informed'' using the heuristic the algorithm gains additional information about its search space. With this additional information the algorithm is able to performa a better search for a possible solution\cite{AIModernApproach}.

Heuristics are strategies that direct the search based on the information available, to move towards areas where there is a higher probability of obtaining high quality candidate solutions \cite{AIModernApproach}. A heuristic is able to dictate what an algorithm must do for its next iteration by evaluating the current internal state of the algorithm, i.e. whether it should move to a different point in the search space, generate new data, or select the current data as the most optimal solution\cite{AIModernApproach,NatureInspiredMetaHeuristic}. 

In general ``meta'' means \emph{beyond} or \emph{higher level}\cite{AIModernApproach,NatureInspiredMetaHeuristic}. A metaheuristic therefore refers to a heuristic that is more complex with regard to the decisions it is able to make compared with a standard heuristic\cite{AIModernApproach,NatureInspiredMetaHeuristic}. With a standard heuristic only the current state is considered\cite{AIModernApproach}. A metaheuristic takes additional information into account when considering a current state\cite{NatureInspiredMetaHeuristic}. This additional information can be previous states, or states that are considering to be close in the search space\cite{AIModernApproach, NatureInspiredMetaHeuristic}.

Metaheuristic-based search algorithms are not guaranteed to find the most optimal solutions in the search space; instead these algorithms are used to find near-optimal solutions. Thus most algorithmic development in the metaheuristic domain focuses on developing new techniques that will increase the probability that a good solution will be obtained in difficult combinatorial problems \cite{MetaAgricultural}.

Similarly, metaheuristics are not guaranteed to find suitable solutions or perform well in each problem domain it is applied to. The quality of the solution and performance of the metaheuristic is very much dependent upon on the expertise of the algorithm designer \cite{AutoComplexMeta}. Besides the algoritm designer modifying the algorithm; metaheuristic algorithms that are inherently population-based, hybrid and/or distributed, use the concept of social and self-organisation to better exploit the solution space\cite{Self-AdaptiveMeta}.

In this section the characteristics of metaheuristics that set these algorithms apart from the conventional algorithms used on difficult problems was introduced. In the next section of this chapter the tabu search algorithm is discussed.
\section{Tabu Search}
\label{sec:tabusearch}
\subsection{Introduction}
\label{sec:TSIntroduction}
\gls{TS} was first proposed by Glover\cite{Glover89} as a new searching technique to help algorithms avoid getting trapped in local optima in combinatorial and optimisation problems \cite{TabuRCAProblem}. Since Glover introduced the algorithm in the 1980s, tabu search has been applied to a wide range of problems such as the vehicle routing problem\cite{TabuVechicleRoutingWithTimeWindows}, \gls{FAP}\cite{TabuMontemanniSmith}, capacitated-lot sizing problem\cite{TabuCarryOver}, Nurse Scheduling\cite{TabuNurse} and the Resource Constrained Assignment Problem\cite{TabuRCAProblem}. 

Even though the problems mentioned differ by a large margin, the algorithm has been successful in most optimisation problems it has been applied to. If one observes the results obtained in research \cite{TabuMontemanniSmith,tabuglobalplanning3g}, it can be inferred that tabu search has on average obtained the best results compared with previous attempts with other algorithms. 

\gls{TS} resembles in its most basic form the hill-climbing search algorithm\cite{TabuBiddingStrats}. The hill-climbing search algorithm starts from an initial solution and then iteratively moves from the current solution to a neighbouring solution\cite{AIModernApproach}. Each neighbour is rated based on its attractiveness as a possible optimal solution that the algorithm is being applied to\cite{AIModernApproach}. 

The hill-climbing algorithm moves to the neighbour with the highest rating without considering whether the neighbour might lead the algorithm astray, to a position where the neighbours are in fact \emph{worse} than previously encountered possible solutions\cite{AIModernApproach}. 

The \gls{TS} algorithm addresses this shortcoming by introducing the concept of memory\cite{TabuBiddingStrats}. The memory of the algorithm is actually a history of previous solutions that the algorithm has moved to in its search for the search space for a solution\cite{TabuBiddingStrats}. 

General search algorithms like hill-climbing, random-restart\footnote{Random-restart is a search algorithm where once a certain trend of repeated moves is noticed, the algorithm restarts by generating a new initial solution to start from and then continues its search process from that generated solution\cite{AIModernApproach}.} or scatter search tend to get trapped in local optima \cite{AIModernApproach}. The local optima might be a very attractive solution and thus general search algorithms will not move to better solutions since, according to the algorithm's built-in strategy, it has found the best solution. 

In actual fact the solution that was found is the best solution in the \emph{local} search space, but not in the \emph{global} search space\cite{CompuIntelligenceIntro,AIModernApproach}. Therefore an important characteristic of algorithms being applied to optimisation problems is breaking out of local optima\cite{CompuIntelligenceIntro,AIModernApproach}.

The next section discussed some of the characteristics that make the \gls{TS} algorithm unique.

\subsection{Important Tabu Search Characteristics}
\label{sec:TScharacteristics}
Various characteristics are important to the \gls{TS} algorithm. The first characteristic is exactly how the \gls{TS} algorithm iteratively improves upon the initial start solution.

\subsubsection{Initial Solution Generation}
The core feature of the \gls{TS} algorithm is to sequentially improve an initial solution \cite{TSHazardous}. An initial possible solution is a point in the search space where the \gls{TS} algorithm will \emph{start} exploring in search of a more optimal solution \cite{AIModernApproach,TSHazardous}.

An important consideration one has to make is how initial solutions are generated for the \gls{TS} algorithm to start on\cite{AIModernApproach,TSHazardous}.

Random initial solutions might seem to be a good starting point, but by introducing randomisation it becomes hard to control the quality of the end solution\cite{TSHazardous}. Hence the generation of starting solutions must be controlled to limit the infeasibility of potential solutions \cite{TSHazardous}. 

Control of the randomly generation solutions can be achieved by simply constraining the random solution generator to only generate initial starting points in a bounded subset of the entire search space. For example: instead of letting the random initial starting point be any number between positive infinity and negative infinity, the random number generator is constrained to only generate numbers between 5 and -5.

\subsubsection{Neighbourhood Search}
The following discussion on neighbourhood search is not meant to be an exhaustive survey on the different methods and how they differ under different problems. Instead the discussion is ment as a general overview to get an idea of neighborhood generation in the \gls{TS} algorithm context. 

The following neighbourhood discussion will be based on the assumption that the underlying problem the \gls{TS} is applied to, has a search space with defined boundaries that is suitable for neighborhood generation.

TS uses a neighbourhood local search process to explore the solution space. There is no set process of how neighbourhood candidate solutions are selected as it is problem dependant. The overall quality of the solution produced by \gls{TS} is also dependent on the neighbourhood search strategy used \cite{TSHazardous}. 

The neighbourhood search phase is the first operation performed after the algorithm has been initialised, which is to say the algorithm has generated an initial starting solution from which the exploration process can start.

The neighbourhood search phase is the primary means for the \gls{TS} algorithm to search the solution space for an optimal solution. It is within this phase that new possible solutions must be presented for the \gls{TS} heuristic to allow the algorithm to decide to which solution it must move next.

The new possible solutions that are generated are called neighbouring solutions; hence the \gls{TS} algorithm always moves to a neighbouring solution. When the \gls{TS} algorithm moves to a neighbouring solution, the current solution is replaced by the neighbouring solution. Therefore, in the next iteration, neighbours for the new solution need to be generated.

Generation of new neighbours can range from a simple increment option to a complex operation that incorporates additional intelligence by means of a more heuristic approach to generate new neighbours.

The \gls{TS} algorithm is not limited to just one neighbourhood search strategy. In the research by Gopalakrishnan et al.\cite{TabuCarryOver} five neighbourhood move strategies are developed and are used interchangeably; in some cases a strategy is used three times in a row due to stagnation in the search space. 

Stagnation occurs when the algorithm does not move to a better solution; instead it opts to stay on the current solution, as no neighbouring solution is better than the current one. 

Other neighbourhood strategies developed is that by N. A. Wassan \cite{ReactiveTabuVHR}. Wassan used a neighbourhood selection strategy that exchanges route nodes from initial vehicle routes for the vehicle routing problem. This route exchange enables the \gls{TS} algorithm to search much more broadly due to the constant supply of different solutions. 

Since initial solutions are constantly modified, it enables the \gls{TS} procedure to be a very fined-grained process, because often a small change in a potential solution can have a big impact on the overall proposed solution by the \gls{TS} algorithm.

In the research done by Zhang et al.\cite{TSHazardous} a neighbourhood selection scheme called \emph{dynamic penalty} is developed. When the algorithm moves onto an infeasible solution a penalty is imposed. By dynamically changing the penalty that is imposed the ``feasibility'' of solutions produced is influenced. 

Therefore, if and when the algorithm continually produces infeasible solutions, the penalty imposed is increased to guide the algorithm to produce more feasible solutions. Finally, when the algorithm becomes trapped at local optima, the penalty is reduced, which allows the algorithm to consider moving onto infeasible solutions thus escaping local optima.

TS is an iterative algorithm, executing a set of operations sequentially until a stopping criterion is met\cite{EvoParallelTabu,TabuVechicleRoutingWithTimeWindows}. At each iteration the algorithm has to determine feasibility of the immediate neighbourhood candidate solutions \cite{EvoParallelTabu,TabuVechicleRoutingWithTimeWindows}. 

Therefore each candidate must be evaluated by some function, which may be a costly operation in terms of computational cycles as well as in terms of time\cite{EvoParallelTabu,TabuVechicleRoutingWithTimeWindows}. This constant evaluation can drastically reduce the overall performance of the algorithm, since it is spending more time calculating feasibility than actually searching the solution space \cite{EvoParallelTabu,TabuVechicleRoutingWithTimeWindows}. 

\subsubsection{Memory Structures of Tabu Search}
The hill-climbing and random-restart algorithms are able to break out of local minima, but there is nothing stopping these algorithms from avoiding the local optima with their second or n-pass in the search space. \gls{TS} addresses the shortcoming of these algorithms by incorporating an important concept: the notion of memory.

In its most basic form \gls{TS} keeps a local memory of all its recent best moves, and puts them into a \emph{tabu list} that has a predefined size. In the literature the Tabu list is also referred to as the \emph{tabu tenure} \cite{TSHazardous,TabuCarryOver}. The algorithm is not allowed to move to any solution that is in the tabu list unless a solution that is \emph{tabu} is better than any current moves available in the immediate search neighbourhood \cite{TabuCarryOver,ReactiveTabuVHR}. The process of overriding a solution's tabu status in the tabu tenure is called the \emph{aspiration criterion} \cite{TSHazardous,TabuCarryOver}. With the use of the tabu tenure and the aspiration criterion, the algorithm is able to avoid cycling, local optima as well as searching in a too narrow region \cite{TabuSingleMachineScheduling,CircuitTabu}.

Research done by Ashish Sureka and Peter R. Wurman makes an important distinction with regard to the memory scheme that is used in the \gls{TS} algorithm. Two memory schemes are discussed: \emph{explicit memory} and \emph{attribute-based memory} \cite{TabuBiddingStrats,TabuFormGames}. Of the two memory schemes the explicit memory scheme is the most used in the literature \cite{TabuVechicleRoutingWithTimeWindows}.

With explicit memory the algorithm stores a complete solution in the tabu tenure; hence the algorithm is prohibited from moving to that position in the search for as long as the solution is in the Tabu tenure\cite{TabuBiddingStrats,TabuFormGames}. With attribute-based memory the algorithm stores the \emph{operation} used to move from the previous solution to the current solution\cite{TabuBiddingStrats,TabuFormGames}. Therefore with attribute-based memory the tabu tenure intended function is changed from prohibiting certain solutions already encountered to rather prohibiting making changes to the current solution that would lead to solutions already present in the tabu tenure \cite{TabuBiddingStrats,TabuFormGames}.

In research conducted by Clarkson et.\ al\cite{MultiObjTabu}, the authors add two additional memory structures called \gls{MTM} and \gls{LTM} besides the standard \gls{STM}, referred to as the tabu List \cite{MultiObjTabu}. Each additional structure remembers a different set of solutions for use by the diversification and intensification phases in the algorithm.

STM is similar to the traditional tabu list: to store the most recent solutions produced by the algorithm. \gls{MTM} is designed to remember optimal or near-optimal solutions. These solutions are therefore used later in the intensification phase. Finally, the \gls{LTM} structure stores all the solutions that the algorithm has already explored and is thus used in the diversification phase of the algorithm \cite{MultiObjTabu}.

\subsubsection{Search Phases}
\label{TSSearchPhases}
As \gls{TS} searches through the search space, it goes through two cycles of search phases called \emph{diversification} and \emph{intensification} \cite{TabuParameterization,TabuCrewSchedulingProblem,NonlinearGlobalTabu,SelfControllingReactiveTabu}.

The diversification phase in the \gls{TS} algorithm is the phase where the algorithm is directed to areas in the search space that has not yet been explored. The algorithm applies diversification as mechanisms monitoring the memory; note that solutions being produced are being repeated \cite{ReactiveTabuVHR,SelfControllingReactiveTabu}. 

Research by Fescioglu-Unver and Kokar \cite{SelfControllingReactiveTabu} provides a strategy that consists of two components namely the \emph{observer} and the \emph{diversifier}. The goal of the observer is to continually monitor the best solution obtained by the algorithm as to whether it violates the \emph{stagnation period}. The stagnation period is defined as the number of iterations where the current best obtained solution has not changed and the algorithm has not moved to a new solution\cite{SelfControllingReactiveTabu}. 

As soon as the current solution exceeds the stagnation period the observer component activates and transfers the necessary information needed by the diversifier component. The diversifier component dynamically changes the size of the tabu tenure based on the information the observer gathered. The diversifier mainly targets older moves to diversify, but for short bursts of time it decreases the tabu list size to a very small value in an attempt to combine new and old moves \cite{SelfControllingReactiveTabu}.

The specific mechanism used to define a new position where the algorithm can continue to search, should ideally select areas in the search space that have not been explored yet\cite{NonlinearGlobalTabu,SelfControllingReactiveTabu}. Therefore, the diversification phase makes extensive use of the knowledge present in the long-term memory structures as an indication of what areas of the search space have been previously explored and which areas have not \cite{NonlinearGlobalTabu,SelfControllingReactiveTabu}.

Intensification is the first phase of the \gls{TS} algorithm, since it is responsible for building up a history in memory on which the diversification phase can act. Fescioglu-Unver and Kokar also present an intensification strategy based on control theory in their research \cite{SelfControllingReactiveTabu}. The authors identify repetition length as a critical value for their intensification strategy to be based upon. The repetition length is a control measure that defines how many times the algorithm can occupy the same solution within a span of iterations.

In the following section, an overview is presented of the flow the \gls{TS} algorithm along with pseudo code describing the \gls{TS} algorithm.
\subsection{Flow of the algorithm}
In this section the general flow of the \gls{TS} algorithm is described using algorithm~\ref{alg:TS} as a reference point.
\begin{algorithm}[H]
\caption{Basic Tabu Search Algorithm\cite{TabuRCAProblem,TabuMontemanniSmith}}
\label{alg:TS}
	\begin{algorithmic}[1]
		\State Initialize parameters
    \State $\hat{x_0} \leftarrow$ Initialize starting solution
		\While{stopping criteria not met}
    \State $\hat{y_i} \leftarrow$ Determine $\hat{x_i}$ neighbourhood solutions 
    \State Evaluate neighbouring solutions with fitness function $f(\hat{y_i})$
    \State $\hat{z_i} \leftarrow$Select best neighbour from $\hat{y_i}$
    \If{Move to $\hat{z_i}$ is Tabu}
    \If{$\hat{z_i}$ meets Aspiration Criterion}
    \State $\hat{x_i} \leftarrow \hat{z_i}$
				\EndIf
			\Else
      \State Add $\hat{x_i}$ to Tabu List
      \State $\hat{x_i} \leftarrow \hat{z_i}$
      \If{$\hat{x_i}$ repeated $\ge$ max repeats}
					\State diversify()
				\Else
					\State intensify()
				\EndIf
			\EndIf
		\EndWhile
    \State Return $\hat{x_i}$ as best found solution
	\end{algorithmic}
\end{algorithm}

Before the algorithm can actually start searching, it first needs to initialise various parameters. These parameters include, but are not limited to, the tabu list size, the aspiration criterion and the starting solution. The initialisation can be observed to occur from lines 1 - 2.

Once all the various parameters that are needed by the algorithm have been initialised, the algorithm is ready to enter the actual search phase, which ranges from lines 3 -- 21. 

The search phase starts off by first generating possible solutions that neighbour the current solution $x_i$ as can be observed in line 4. Generating neighbouring solutions are a critical process in the \gls{TS} algorithm as tehy are the means by which the algorithm is able to move from one possible solution to the next in the search space.

After all the solutions that neighbour the current possible solution have been generated, the algorithm needs to decide which of the possible neighbours is the most rewarding. The algorithm therefore determines the fitness of each neighbour $y_i$ by applying a fitness function $f(y_i)$. 

Once all the neighbours have been evaluated, the algorithm selects the best neighbour that not only has the best fitness out of all the generated neighbours, but also has a better fitness than the current solution held by the algorithm. The best neighbour selection can be seen to occur in line 6.

The algorithm has now determined a possible neighbour $z_i$ to move towards. Before moving on to the next iteration, it first needs to perform a series of checks that will aid it in the search process.

The first check that needs to be performed is whether the neighbour $z_i$ is in the tabu list and this occurs in line 7. 

If the neighbour $z_i$ is in the tabu list, then another check is performed where the aspiration criterion is calculated as can be seen in lines 8 -- 10. The aspiration criterion determines whether the algorithm can make neighbour $z_i$ its current solution once more even though it is tabu. 

If the aspiration criterion has been met, the algorithm makes neighbour $z_i$ its current solution $x_i$. 

In the algorithm, if a neighbour $z_i$ is found not to be in the tabu list, the algorithm then adds the currently held solution $x_i$ to the tabu list. The current solution is added to prohibit future movements to the same solution in an attempt to avoid cycling of solutions. After $x_i$ has been added to the tabu list, the algorithm makes $z_i$ the current solution $x_i$. This process can be observed from lines 12 -- 14.

Before the algorithm continues to the next iteration, it performs one last final check. The purpose of this check is to determine whether the algorithm is repeating solutions. As can be observed from lines 15 -- 19, the algorithm calculates whether the new selected solution has been repeated for a certain number of iterations. 

If the solution has indeed been repeated for a predetermined number of iterations, the algorithm activates its diversification strategy or intensifies its search.

The section that follows presents an overview of the \gls{TS} being applied to the \gls{FAP}.
\subsection{Tabu Search on the \gls{FAP}}
In a study conducted by Robert Montemanni and Derek Smith \cite{TabuMontemanniSmith} the \gls{TS} algorithm is used on the \gls{FS-FAP}. The authors had to make some alterations to the algorithm to suit their needs as well as to make the algorithm more efficient in exploring in the \gls{FAP} solution space.

The \gls{TS} algorithm used by the authors is the multistart \gls{TS} algorithm, which randomly starts on different initial solutions \cite{TabuMontemanniSmith}.

The authors developed a technique called \gls{HMT}. \gls{HMT} first monitors an underlying heuristic being used on the problem by the algorithm\cite{TabuMontemanniSmith}. It then identifies certain characteristics that good solutions exhibit. In the \gls{FAP}, it is transmitters that are assigned different frequencies which results in an overall lower interference value\cite{TabuMontemanniSmith}.

The HMT then uses the identified characteristics to add \emph{additional} constraints to the problem\cite{TabuMontemanniSmith}. By adding constraints, the search space is reduced. However, by reducing the search space, other near-optimal solutions which might be far better are excluded\cite{TabuMontemanniSmith}. It is for this reason that that Montemanni and Smith opted not to add the constraints permanently.

Montemanni and Smith applied their \gls{TS} algorithm together with HMT to the \gls{COST} 259 family of benchmarks, specifically the Siemens1, Siemens2, Siemens3 and Siemens4 problems. The results are presented in table~\ref{TSCOST259}. The values presented are scalar and indicate the total interference of the frequency plan. The lower the interference value is, the better the frequency plan.
\begin{table}[H]
\centering
	\begin{tabular}{| c | c | c |}
		\hline
		Problem instance & \gls{TS} with \gls{HMT} & Best \gls{COST} 259 \\ \hline
		Siemens1 & 2.7692 & 2.200 \\ \hline
		Siemens2 & 14.9360 & 14.280 \\ \hline
		Siemens3 & 6.6496 & 5.19 \\ \hline
		Siemens4 & 110.9725 & 81.89 \\ \hline
	\end{tabular}
\caption{Results of applying \gls{TS} with \gls{HMT} on \gls{COST} 259}
\label{TSCOST259}
\end{table}
As can be observed from the results obtained by the authors, the \gls{TS} algorithm with HMT produces results that rank very favourably against other algorithms also applied to the \gls{COST} 259.

When critically reasoning about the \gls{TS} algorithm with regard to applying it to the \gls{FAP}, the following disadvantages in theory can be identified:
\paragraph{Search based on a single solution}
--- The \gls{TS} algorithm at any moment in time only searches in the vicinity of \emph{one} current solution for possible neighbours that might be the current solution for the next iteration. \gls{FAP}s have huge search spaces due to their NP-Complete nature. Therefore, only searching for possible rewarding neighbours from only potential solutions seems to be terribly inefficient. A better strategy would be to use the notion of population-based algorithms and have multiple solutions from which more rewarding neighbours are searched.
\paragraph{Neighbourhood generation}
--- The \gls{TS} algorithm defines no set process for generating a neighbouring solution given a starting solution. Generating neighbours from a solution is a critical process in the \gls{TS} algorithm, for it is the only means by which the algorithm considers other solutions, i.e. it is the mechanism by which the algorithm searches. Generating a new neighbour can be as simple as changing only one value from the current solution or it can be very complex and incorporate other algorithms together with mathematics formulae. Regardless of the complexity of the neighbour generation that is used, care must be taken to ensure that the algorithm is able to produce a wide diversity of neighbours and is also able to intensify on the most optimal solution.
\paragraph{Tabu lifetime}
--- The \gls{TS} algorithm only operates on a single solution at a time and at most only considers one potential neighbour as its next possible current solution. Therefore a difficult choice needs to be made as to how long a solution stays tabu. In the \gls{FAP} a solution might be entered into the tabu list early in the search process of the algorithm. A large majority of the neighbours of this solution are vastly superior solutions compared with any of the current solutions produced by the algorithm. Due to the solution with these neighbours being in the tabu list, these neighbours will not be reconsidered until much later when the solution is removed from the list. A possible option to allow the \gls{TS} to reconsider the tabu solutions is to increase the aspiration criterion. Increasing the aspiration criterion does have its risks. A high aspiration criterion and the algorithm might be too eager to select just any solution even though it is Tabu. A low aspiration criterion and the algorithm will be too strict in selecting a tabu solution.

In the next section the simulated annealing algorithm is discussed.
\section{Simulated Annealing}
\label{sec:simulatedannealing}

\subsection{Introduction}
\label{sec:SAIntroduction}
\gls{SA} is a metaheuristic search technique proposed in the 1980s by Kirkpatrick to solve combinatorial optimisation problems. The technique is based on a natural process which is known in metallurgy as annealing \cite{SASingleMultiObj,TempCyclingSA}. Kirkpatrick was the first to use \gls{SA} to solve optimisations problems but the basic algorithm structure was defined by Metropolis et al.\ in 1953 \cite{CurveFittingSA,VeryFastSAImageEnchancement}.

Annealing is the natural process of crystallisation when a solid is heated to a high temperature and then systematically cooled to a lower temperature to reach a crystallised form \cite{NewSAs,ConstantTempSA}. The crystallised form of the solid is known to be the global minimum of the solid's internal energy state. 

When the solid is rapidly cooled from a high temperature, the molecules have no time to reach a thermodynamic equilibrium stage \cite{MobileRobotSA,ConstantTempSA}. Therefore the molecules of the solid have high energy and the resultant structure has no real crystalline form; thus the solid energy is at a local minimum\cite{CurveFittingSA,NewSAs,MobileRobotSA}. When the solid is slowly cooled in a controlled manner, the molecules are able to reach a thermal equilibrium at each temperature \cite{ChaosSA,CurveFittingSA,NewSAs}.

In the algorithm the energy state is the \emph{cost function} that needs to be minimised, and the molecules are the \emph{variables}, which represent the solutions, and thus their state needs to be optimised to reach the desired energy state.

The \gls{SA} algorithm is able to purposely move to a worse solution in the search space\cite{EcoEquilSA}. In the research when an algorithm moves to a worse solution it is classified as an \emph{uphill} move\cite{AIModernApproach}. Similarly, when a move is made by the algorithm which results in a better solution the move is classified as an \emph{downhill} move\cite{AIModernApproach}.

The following equation is the standard probability function that is used to determine when an uphill move is performed by the algorithm. This function is known in the literature as the \emph{metropolis criterion}. 
\begin{equation}
\label{eq:saprobability}
	M_{AC} =
	\begin{cases}
	1, &\text{if $f(y) \leq f(x)$}\\
	e^{-\frac{\Delta E}{T_k}} , &\text{otherwise}\\
	\end{cases}
\end{equation}
The function $f$ is the objective function or a function that determines the state of a given position in solution space\cite{EcoEquilSA}. The parameter $T_k$ is the temperature of the algorithm at iteration $k$ \cite{EcoEquilSA}. Finally, $\Delta E$ is the change in ``energy'' between two solutions $x$ and $y$ \cite{EcoEquilSA}.

The main purpose of the \gls{SA} algorithm (like most optimisation algorithms) is to minimise or maximise the cost function \cite{SASingleMultiObj}. This cost function evaluates a solution desirability compared with other solutions in the immediate \emph{neighbourhood} of the algorithm's current position \cite{TheoPraticalSA}. 

The immediate neighbourhood of solutions is generated based on a heuristic implemented by the algorithm designer\cite{AIModernApproach}. This heuristic, as with the \gls{TS} algorithm, can be simple or complex.

A neighbouring solution is only selected as the new best state if its desirability ranks higher than the current solution. When the algorithm moves to a better solution from the previous solution, the move is referred in the literature as a \emph{downhill} move \cite{CurveFittingSA}.

The best state is not always selected; in some cases the algorithm is also able to move to solutions that are worse than the current solution. A worse solution is only selected based on a probability which is controlled by the \emph{annealing temperature} of the algorithm \cite{TheoPraticalSA}. 

At a high annealing temperature the probability that the algorithm will select a bad solution is very good. As the annealing temperature decreases so does the probability that a bad solution will be selected \cite{CurveFittingSA}. When the algorithm moves to a worse solution, the move is referred to in the literature as an \emph{uphill} move \cite{CurveFittingSA}. Uphill moves allow the algorithm to break out of local minima and can lead the algorithm down a different path, which may ultimately result in obtaining the global optimum \cite{SASingleMultiObj}. 

As with the \gls{TS} algorithm, the standard \gls{SA} algorithm does not define a set neighbourhood generation mechanism; instead it is up to the algorithm designer to implement a suitable generation mechanism that will allow the algorithm to adequately explore the search space\cite{VariousCoolingSA}. 

The following section presents a discussion on various characteristics of the \gls{SA} algortihm.
\subsection{Important Simulated Annealing Characteristics}
There are four characteristics of the \gls{SA} algorithm that make the algorithm unique. One of the most important is the cooling schedule. 

%\subsubsection{Markov Chain}
%The \gls{SA} Algorithm is typically modelled by using Markov chains due to each Markov chain represents a set of trials that the algorithm has executed at the same temperature. 

%A Markov chain\footnote{Also known as Markov process} defines a chain of states or processes that satisfy the \emph{Markov assumption}. Which is defined as, that any state only depends on a set amount of previous states that have been encountered previously\cite{AIModernApproach}.
%%
%It has been proven with the use of Markov Chain theory that \gls{SA} will find the global minimum in the solution space \cite{ClusterSA}. This proof is only valid when the following properties for the underlying Markov chain hold \cite{VeryFastSAImageEnchancement}:
%\begin{itemize}
%\item It must be irreducible
%\item It mustn't be periodic
%\item The detailed balance condition must hold
%\end{itemize}
%According to the proof presented in \emph{Image enhancement using very fast simulated reannealing}\cite{ClusterSA}, if the \gls{SA} algorithm designer can uphold the above properties, the algorithm is able to find the global optimum. Even though the algorithm will eventually find the global optimum, the algorithm is known to take a very long time to do so.
\subsubsection{Cooling Schedule}
The cooling schedule/annealing Schedule is the most defining characteristic of the \gls{SA} algorithm. It is the procedure where the natural annealing process is mimicked. The temperature of the \gls{SA} algorithm is a control parameter that defines how much the algorithm moves around in the search space.

After each iteration, whether the algorithm has selected a new best solution or not, the temperature is reduced by a certain amount. This amount is determined by the \emph{cooling schedule}.

In general, when the \gls{SA} algorithm temperature has a very high value most solutions that are produced from the neighbourhood are accepted \cite{ClusterSA}. Thus the algorithm moves freely in the search space with little constraint. As the temperature decreases, the probability that the algorithm will select a bad or just any solution decreases\cite{ClusterSA}. When the temperature is very low, the \gls{SA} algorithm is similar to a greedy algorithm in the sense that it only accepts downhill movements\cite{ClusterSA}.

The cooling schedule provides the \gls{SA} algorithm with the critical ability to control the rate the algorithm transitions from the diversification phase (high temperature) to the intensification phase (low temperature)\cite{ClusterSA}. By controlling this rate, one is able to direct the algorithm to explore more early on to locate the more promosing areas for possible solutions. These promoosing areas can then be used by the algorithm in its intensification phase to find more promosing solutions.

In the literature there are three annealing schedules in common use, namely \emph{the logarithmic schedule}, the \emph{geometric schedule} and the \emph{Cauchy schedule}\cite{VeryFastSAImageEnchancement,SASingleMultiObj}. 

The standard and most commonly used schedule is known as the logarithmic schedule and is based on Boltzmann annealing \cite{VeryFastSAImageEnchancement}. The main disadvantage of this schedule is that is slow due to its logarithmic nature \cite{VeryFastSAImageEnchancement}. It also requires moves to be generated from a Gaussian distribution for it to be able to reach the global minimum\cite{SASingleMultiObj}. The logarithmic annealing function has the following form:
\begin{equation}
\label{eq:logcooling}
	T_k = \frac{T_0}{ln(k)},\text{where k is the iteration value and } k \neq 0\\
\end{equation}
Where $T_k$ is the temperature at iteration $k$.

The Cauchy schedule is faster than the logarithmic schedule. Similar to the logarithmic, this schedule also has a movement requirement. Moves must be generated from a Cauchy distribution for the algorithm to be able to reach the global minimum \cite{SASingleMultiObj,VeryFastSAImageEnchancement}. The Cauchy schedule is also referred to as fast annealing\cite{VeryFastSAImageEnchancement}. The schedule has the following form:
\begin{equation}
\label{eq:cauchycooling}
	T_k = \frac{T_0}{k} ~, k \neq 0
\end{equation}

Finally, the fastest annealing schedule is known as the geometric or exponential annealing schedule \cite{SASingleMultiObj}. The schedule has no move generation requirement to reach the global minimum, since there is no regorous proof in the literature \cite{SASingleMultiObj}. By using the geometric schedule the \gls{SA} temperatures are rescaled which is called \emph{re-annealing}\cite{VeryFastSAImageEnchancement}.

The geometric schedule has the following form:
\begin{equation}
\label{eq:geocooling}
	T(k)=T_0e^{-C_k},\text{where C is a constant}
\end{equation}

\subsubsection{Initial Temperature}
The initial temperature is a very important parameter to define in the \gls{SA} algorithm, since it defines a point from which the cooling schedule will start\cite{VariousCoolingSA}. Therefore, depending on what the initial value of the temperature, is the final result that the algorithm will produce can be influenced\cite{SALongestCommon,AutoConfigSA}.

When the initial temperature is set to a very high value, the algorithm takes a long time to reach a result since the search space is being explored more\cite{SALongestCommon,VariousCoolingSA}. More exploration is favourable for \gls{SA} as it lets the algorithm be less susceptible to local minimum. 

If the initial temperature is set to a very low temperature, the algorithm might converge too quickly and thus produce a result which may be the local minimum\cite{SALongestCommon,VariousCoolingSA,AutoConfigSA}.

The initial temperature together with the cooling factor allows the algorithm designer to define the time window for the algorithm to escape local minima, as well as the rate of convergence to an optimum solution\cite{SALongestCommon,VariousCoolingSA}.

A low initial temperature together with a low cooling factor makes the time window for the algorithm to leave a local optimum very small\cite{SALongestCommon}. With a high initial temperature and cooling factor value that is almost 1, the time window for the algorithm to leave the local optimum is much larger \cite{SALongestCommon}. 

When the algorithm is near a global optimum, a low initial temperature and low cooling factor will allow the algorithm to reach the optimum faster in the search space\cite{SALongestCommon}. In contrast, if a high temperature and a very low cooling factor are used, the algorithm will take longer to reach the optimum even though it is near the global optimum\cite{SALongestCommon}.

\subsubsection{Move Generation}
Most of the research done on the \gls{SA} algorithm focuses on the annealing schedule and not so much on the move/solution/neighbourhood generation. Typically an initial solution is generated and then small changes are made to the solution to represent a new solution. The solution is said to be perturbed to the next solution.

Move generation is the phase where neighbouring solutions to the current solution are generated. It is the ideal section for an algorithm designer to embed domain-specific knowledge which will allow the algorithm to generate better possible solutions.

In research done by Tseung and Lin \cite{CurveFittingSA} an initial solution is not modified, but a move generation technique known as \emph{pattern} search is used. Pattern search has two forms of movement, namely the exploratory move and the patten move. The exploratory move continually changes the certain variables of a solution \cite{CurveFittingSA}. This is done so that the technique can rapidly find and identify a ``downhill'' move. The pattern move uses the information gathered by the exploratory move to move towards the minimum of the function \cite{CurveFittingSA}.
\subsubsection{Algorithm Efficiency}
The algorithm is also efficient with regard to CPU cycles when compared with the genetic algorithm. \gls{SA} only has to evaluate a certain number of moves each iteration, instead of a whole population of individuals each iteration. The genetic algorithm is discussed in section~\ref{sec:geneticalgorithm}.

Unlike \gls{TS}, the basic \gls{SA} algorithm does not keep any memory and is therefore memory efficient, but in contrast suffers the risk that the solution may cycle. The more iterations spent at a temperature, the longer the algorithm spends at a certain temperature and therefore the higher the probability that solutions may cycle.

In next section the flow of the \gls{SA} algorithm is discussed and pseudo code for the \gls{SA} algortihm is presented.

\subsection{Flow of the Algorithm}
In an attempt to better understand how the \gls{SA} algorithm operates, a general discussion on the flow of the algorithm will now be given using algorithm~\ref{alg:SA} as a reference point.
\begin{algorithm}[H]
\caption{Basic Simulated Annealing Algorithm\cite{VeryFastSAImageEnchancement,ChaosSA}}
\label{alg:SA}
	\begin{algorithmic}[1]
		\State Initialize parameters
		\State Set starting temperature $T(0)$
    \State $\hat{x_0} \leftarrow$ Generate initial starting solution
		\While{Stopping criterion not met}
    \State $\hat{y_i} \leftarrow$ Generate neighbouring solutions to $\hat{x_i}$
    \State Evaluate $\hat{y_i}$ neighbours with fitness function $f(\hat{y_i})$
    \State Calculate probability $\hat{p_i}$ of $\hat{y_i}$ neighbours with equation~\ref{eq:saprobability}
    \State $\hat{x_i} \leftarrow$ Select $\hat{y_i}$ neighbour based on probability $p_i$
			\State Reduce temperature $T(i)$ based on cooling schedule
		\EndWhile
    \State Return best solution $\hat{x_i}$
	\end{algorithmic}
\end{algorithm}

From lines 1 -- 3, the \gls{SA} algorithm is initialised. The most important step here is setting the starting temperature for the annealing process to start. As mentioned in the introduction, the temperature of the annealing process plays a critical role in the potential solution selection process. After the algorithm has been initialised the search phase of the algorithm starts which ranges from lines 4 -- 10. Like the \gls{TS} algorithm, the \gls{SA} algorithm starts the search phase by generating a number of neighbours to the current solution held by the algorithm as can be observed in line 5.

Before selecting a neighbour the algorithm first needs to evaluate the generated neighbours. It evaluates each neighbour by applying a fitness function $f(y_i)$ in order to determine its fitness.
Once the fitness of all the generated neighbours has been determined, the algorithm uses equation~\ref{eq:saprobability} to calculate the probability of selecting a particular neighbour for all the generated neighbours as well. The probability calculation can be observed to occur in line 7. The algorithm then selects the neighbour with the highest probability to be the current solution, as observed in line 9. 

Before the algorithm advances to the next iteration the temperature needs to be lowered. As discussed, the temperature is lowered according to a particular cooling schedule. In the algorithm the process of lowering the temperature occurs in line 10. 

This concludes the discussion on the flow of the SA algorithm. In the section that follows a discussion is given on when \gls{SA} is applied to the \gls{FAP}.
\subsection{Simulated Annealing on the \gls{FAP}}
The \gls{SA} algorithm, as with the \gls{TS} algorithm, has achieved good results in other optimisation problems, as mentioned in section \ref{sec:SAIntroduction}. Due to its success on other NP-Complete optimisation problems, the \gls{SA} algorithm has also been applied to the \gls{FAP}.

In literature by Carlo Mannino and Gianpaolo Oriolo\cite{SolvingSuperIntervalGraphs} the \gls{SA} algorithm is applied to the \gls{FAP}. The resulting \gls{SA} algorithm was benchmarked on the \gls{COST} 259 Siemens benchmark instances. The results obtained by the authors are presented in table~\ref{tab:SA}. 

\begin{table}[H]
\centering
	\begin{tabular}{| c | c | c | c |}
	\hline
	Problem instance & \gls{SA} & \gls{COST} 259 (old) & Best \gls{COST} 259 \\ \hline
	Siemens1 & 22.96 & 23.00 & 2.200\\ \hline
	Siemens2 & 14.72 & 14.75 & 14.280\\ \hline
	Siemens3 & 52.43 & 52.55 & 5.19\\ \hline
	Siemens4 & 80.96 & 80.80 & 81.89\\ \hline
	\end{tabular}
\caption{SA on \gls{COST} 259 Benchmark}
\label{tab:SA}
\end{table}

Values represent the total interference generated by the frequency assignment. Note that the values represented in the SA column, are the values as presented in the reasearch by the authors. Also, note that the column \gls{COST} 259 (old) represents the best obtained results to the instances as it was when the authors presented their research.
An overview of the \gls{SA} algorithm along with its unique characteristics have now been given. Utilising the knowledge that was gained from understanding how the \gls{SA} algorithm operates a critical evaluation can be presented. In the following paragraphs, a theoretical critical evaluation is presented that lists the various characteristics which would be problematic if the \gls{SA} algorithm would be applied to the \gls{FAP}.

\paragraph{Cooling Schedule}
--- Depending on the cooling schedule selected, the algorithm might converge too quickly. As discussed previously the cooling schedule reduces the temperature. The temperature plays a large part in the determination of whether a particular solution will be moved to or not in an iteration. Thus early on the algorithm will explore a lot more (diversification) and later on will exploit more (intensification). In the \gls{FAP}, the algorithm must not only be able to explore and exploit, but also be able to return to an exploration phase if need be.
As the temperature becomes colder the \gls{SA} algorithm exploits more and therefore will not easily move to a worse off solution. In the \gls{FAP}, it might be desirable to rather move a worse off solution later on, as the particular current solution is a local minimum and yields bad neighbours as potential next solutions. With the cooling schedule this is simply not possible, unless the temperature and schedule are reset. Resetting the temperature and schedule is not ideal, since the algorithm keeps no history and might risk making the same faults as before the reset.
\paragraph{Neighbourhood generation}
--- The \gls{SA} algorithm, as with the \gls{TS} algorithm, has no set process that defines how neighbours should be generated. As discussed, neighbourhood generation is the primary means by which the \gls{SA} algorithm moves about the search space in search of an optimal solution. Therefore applying the \gls{SA} algorithm would require a custom neighbourhood generation scheme. A desireble neighbourhood generation scheme would be one that keeps track of where the algorithm has been previously. By keeping history, the algorithm will be able to avoid previously explored areas in the search space.
\paragraph{Single solution based search}
--- The \gls{SA} algorithm is similar to the \gls{TS} algorithm in the sense that it only searches from one solution per iteration. It searches by generating neighbours around the current solution of the algorithm. The \gls{FAP} search space is huge; hence it would be more efficient to have multiple current solutions from which neighbours are generated. This enables the algorithm to explore the search space much more efficiently at the expense of more computational resources.

\section{Genetic Algorithm}
\label{sec:geneticalgorithm}
\subsection{Introduction}
The genetic algorithm (GA) is a stochastic search method that is based on the natural process of genetic evolution and the Darwinian concept of ``survival of the fittest'' \cite{DistributedHierarchicalGA,AcceleratingGA,AdaptiveSAGA,FamilyGA}. The \gls{GA} was first proposed by Fraser, but it was not till the research presented by Holland that \gls{GA}'s became popular\cite{CompuIntelligenceIntro}. Holland initially applied the algorithm to adaptive systems but has been widely used in the optimisation field of study due to its success on multidimensional problems\cite{ParallelGASA,DistributedHierarchicalGA,FamilyGA}. The \gls{GA} developed by Holland is referred to in the literature as the Canonical \gls{GA} (CGA)\cite{CompuIntelligenceIntro}.

The wide use of the \gls{GA} can also be attributed to its generic algorithm structure as well as the ease of implementation \cite{FamilyGA,AdaptiveSAGA}. The \gls{GA} defines generic operators that select, create and mutate individuals for the next population of the next generation\cite{CompuIntelligenceIntro}. It should be noted that initially the mutation operator was not a required to be part of the \gls{GA}. Only after successive implementations of the \gls{GA} showcased the explorative power that the mutation operator brings tot he search capability of the \gls{GA} was the mutation operator considered to be important\cite{CompuIntelligenceIntro}. 


The \gls{GA} search procedure involves searching the solution space through artificial evolution and natural selection\cite{FamilyGA,MultiPopGA,HybridIntelliGA}. An individual or point in the search space is known as a \emph{chromosome} \cite{HumanPassiveGA}. An initial set of chromosomes (referred to in the research as the \emph{population}) is randomly generated to form the starting population\cite{FamilyGA,HybridIntelliGA,AcceleratingGA,MultiPopGA}. 

A chromosome consists of a sequence of smaller parts called \emph{genes}\cite{CompuIntelligenceIntro}. The sequence upon which these genes appear in the chromosome determines the characteristics of an individual\cite{CompuIntelligenceIntro}. In the \gls{GA} a single gene represents a single variable of a solution\cite{FamilyGA,AcceleratingGA}. A whole chromosome therefore represents a solution\cite{FamilyGA,AcceleratingGA}. Exactly how best to represent a chromosome as a solution is problem dependent\cite{CompuIntelligenceIntro}.

According to the evolution theory proposed by Darwin individuals of a population with the best chromosome have the best chance to survive and to reproduce\cite{CompuIntelligenceIntro}. These individuals are reffered to as the fittest individuals of the population. In a \gls{GA} population each individual is ``rated'' to determine how good the solution its chromosome represents \cite{CompuIntelligenceIntro}. The rating of a chromosome is referred to as its fitness value and is also problem dependent\cite{CompuIntelligenceIntro}.

Determining the fitness value of a chromosome is achieved by means of a \emph{fitness function}. The fitness function is a mathematical function which maps the chromosome representation to a scalar value\cite{CompuIntelligenceIntro}. An optimisation problem has a objective function which calculates how good a solution is, therefore in the \gls{GA} the fitness function represents the objective function\cite{CompuIntelligenceIntro}.

When the fitness of individuals in a population have been determined the \gls{GA} probablisticly selects individuals for the next generation\cite{CompuIntelligenceIntro}. The selection probability is referred to as the \emph{selective pressure}\cite{CompuIntelligenceIntro}. The individuals that are selected by the operator enter the reproduction phase of the \gls{GA} where offspring are created\cite{CompuIntelligenceIntro}.

Offspring are created by combining parts of one or more chromosomes to form a new chromosome this procedure is called the \emph{crossover}\cite{CompuIntelligenceIntro}. The chromomsomes used in the production of the offspring are referred to as the parent chromosomes\cite{CompuIntelligenceIntro}.

With regard to how offspring and parents are handled, there are two forms of the \gls{GA} \cite{FamilyGA}. One form is called the \emph{generational} \gls{GA}  and the other form is known as the \emph{steady-state} \gls{GA} \cite{GeostatisticalGA,FamilyGA}.

With the generational \gls{GA} the offspring are not immediately used in the next generation; instead they are kept in a pool until the pool reaches a required size \cite{FamilyGA}. The offspring are then used to replace the parents entirely in the next generation \cite{FamilyGA}. In the steady-state \gls{GA} once offspring has been created a selection operator is applied once more. The operator selects individuals from the old population and from the offspring to form the new population for the next generation \cite{GeostatisticalGA,FamilyGA}.

The \gls{GA} search process moves around in the search space using probabilistic rules rather than deterministic rules \cite{FamilyGA}. The probabilistic transition rules aid the algorithm to avoid local optima regions in the search space \cite{HybridIntelliGA}. Note that by even using the probabilistic transition rules there is no guarantee that the \gls{GA} will completely avoid local optima\cite{CompuIntelligenceIntro}.

The \gls{GA} makes no assumptions about the search space and primarily works on the information provided by the chromosomes and the representation of solutions used\cite{CompuIntelligenceIntro,ConstrainedGA,HybridIntelliGA}. Unlike the \gls{SA} and \gls{TS} algorithms, the \gls{GA} if properly initialized, starts with a number of search points that cover a wide area of the search space. Depending on the operators used, diversity can be quickly lost and the population can become homogeneous very quickly\cite{DistributedHierarchicalGA,FamilyGA,HybridIntelliGA}\label{GASearchPoints}.
 
The different operators used by the GA along with their probalities are not specific. Each operator and probability can be changed the suit the problem domain the GA is being applied to. Therefore the particular probability and operators the GA uses is problem dependant.

As discussed earlier the defined operators consists of a selection operator, crossover operator and mutation operator\cite{SelfAdaptiveGA,MultiPopGA}. In the section that follows each operator is discussed.

\subsection{Important Genetic Algorithm Characteristics}
The various operators used by the \gls{GA} makes the procedure unique and is one of its defining characteristics. The first is the characteristic to be discussed is the selection operator.

\subsubsection{Selection Operator}
The selection operator is the first operator to be applied to the population after each generation. The operator determines which individuals will be used to create offspring \cite{CoactiveFuzzyGA,CombinedBranchBoundGA,ConstrainedGA}.

The individuals are selected based on the selective pressure and are moved to the ``mating pool''. Individuals that are selected by selection operator are used by the crossover and mutation operators (in the reproduction phase), to generate offspring from the mating pool\cite{AdaptiveSAGA,AcceleratingGA}.

By favouring high fitness individuals above low fitness individuals the operator is said to have a high selective pressure\cite{CompuIntelligenceIntro}. Care must be taken if the operator uses a high selective pressure. Since high fitness individuals are preferred, diversity among the individuals in the population will deteriorate and thus result in premature convergence\cite{ConstrainedGA, CompuIntelligenceIntro}.

If the search space is known to have only one optimum, then a high selection pressure is feasible\cite{ConstrainedGA}. The selection operator directs the search into a gradient-based direction that converges on a single optimum solution \cite{ConstrainedGA}. 

In contrast, with a search space that is known to have multiple optima a low selection pressure is more benificial to the \gls{GA}\cite{ConstrainedGA}. Low selection pressure allows the population of the \gls{GA} to explore the search space more\cite{ConstrainedGA}.

The means by which the selection operator selects individuals is referred to as the selection scheme. The most widely adopted selection scheme is known as the \emph{roulette wheel} selection scheme \cite{ConstrainedGA,GeostatisticalGA,HybridBaldwinGA,CoactiveFuzzyGA}. With this scheme an individual is selected based on a probability defined by the fitness of the individual divided by the collective fitness of the population \cite{GeostatisticalGA}.

Depending on how complicated the objective function is and how large the population is, the selection phase may be the most computationally expensive as well as time consuming \cite{AcceleratingGA}. The selection process as described below  can also be applied by the crossover operator. This process was opted to be split from the crossover operator as to provide a better overview of how the algorithm works

After the offspring has been generated, a selection operator is applied again\cite{CompuIntelligenceIntro}. The purpose of this selection operator is to determine the population of the next generation\cite{CompuIntelligenceIntro}. Within this selection process replacement policies can \emph{optionally} be applied\cite{CompuIntelligenceIntro}. 

These replacement policies define which individuals of the current population should be replaced by the newly generated offspring\cite{CompuIntelligenceIntro}. For instance, the policy can define that the entire current population should be replaced by the offspring\cite{CompuIntelligenceIntro}. Using this policy is not ideal as some generated offspring could have much worse fitness than their parents but due to the replacement the solutions represented by the good parents are lost\cite{CompuIntelligenceIntro}. 

Other replacement policies include replacing the worst individual in the current population with offspring on the premise that the offspring has a better fitness\cite{CompuIntelligenceIntro}. By replacing older chromosomes with better performing chromosomes in the population replacement strategy, the \gls{GA} achieves an hill-climbing ability. The reader that is interested in more information on different selection operators is directed to the suvery by Engelbrecht\cite{CompuIntelligenceIntro}.
\subsubsection{Crossover Operator}
\label{sec:crossover}
The crossover operator is the first operator applied to the population in the reproduction phase. The crossover operates exclusively on the chromosomes in the mating pool. Crossover works by interchanging genes from one or more parent chromosomes. The parent chromosomes are selected with a probability from the mating pool to produce a single chromosome known as the offspring \cite{FamilyGA,HumanPassiveGA,CoactiveFuzzyGA}. 

The probability is known as the \emph{crossover probability} and is problem dependent\cite{CompuIntelligenceIntro}. By defining a high crossver probability the good genes that form the current population are retained in the next population\cite{CompuIntelligenceIntro}. With good genes being retained more historical information is passed onto the next generation's population\cite{FamilyGA}.

There are a variety of ways in which genes are interchanged between chromosomes in the crossover operation i.e. fixed point crossover, two point crossover, uniform crossover and gaussian crossover\cite{CompuIntelligenceIntro}. All of these crossovers operate on the premise that a byte representation is used for the chromosomes. 

With the byte representation, each chromosome is a byte. Each byte is made up of sequence of bits. As discussed previously each chromosome is made out of genes and therefore each bit is a gene\cite{CompuIntelligenceIntro}.

Fixed point crossover operates on binary parents whereby a point is selected in one parent and then all other bits are replaced by the other parents' bits \cite{HumanPassiveGA}. Two point crossover generates two random indices which dictate a certain segment in the one parent to be interchanged with the other parent \cite{ConstrainedGA}. Where a segment consists of a subset of genes from the chromosome. 

The uniform crossover is the most basic of all crossovers since it randomly selects bits from one parent to be replaced by another parent's bits\cite{ParallelGASA,GeostatisticalGA}. Finally, the Gaussian crossover also uses the byte representation. The Gaussian crossover interchanges bits between parents based on a Gaussian distribution \cite{ParallelGASA,GeostatisticalGA}. Depending on the state of the algorithm, crossover operators can also be interchanged or even paired if the algorithm needs better search performance for large or small solution spaces \cite{HetergeneousGA,ParallelGASA}.

Caution should be exercised by the crossover operator when selecting chromosomes for reproduction. It is possible for the operator to select the same chromosome twice to be the parent of a single offspring\cite{CompuIntelligenceIntro}. The operator is also at risk of selecting the same chromosome multiple times for reproduction\cite{CompuIntelligenceIntro}. The opertator must therefore incorporate a test to detect unenecessary repeated usage of a chromosome\cite{CompuIntelligenceIntro}. Finally, it is important to note that there exist strategies for both Gaussian crossover and mutation based operators for use with continuous-valued representations\cite{FundamentalSwarm}.

\subsubsection{Mutation Operator}
The mutation operator is a probabilistic operator and is applied to individials in the offspring population with a probability referred to as the mutation rate\cite{CompuIntelligenceIntro}. The purpose of the mutation operator is to increase the diversity of the genes of a individual chromosomes\cite{CompuIntelligenceIntro}. By introducing new genes into an individual the diversity of the populations characteristics are increased\cite{CoactiveFuzzyGA,AcceleratingGA,ConstrainedGA}.

The mutation operator has no previous information on the chromosome it is mutating; thus it is entirely possible that the mutation may modify the chromosome for the worse \cite{AcceleratingGA}. A worse solution might lead the algorithm out of local optima or lead it down a new path to find the global optima, but this is not always the case \cite{AdaptiveSAGA,FamilyGA,ConstrainedGA}. It is for this reason that it is recommended that the mutation rate be set to a low value to ensure good solutions are not distored too much\cite{CompuIntelligenceIntro}.

In a survey done by Engelbrecht\cite{CompuIntelligenceIntro} another mutation operator is discussed. Instead of mutating a small part of randomly selected chromosomes, this operator generates new offspring to be inserted back into the population. The operator randomly generates a new chromosome and then uses any of the previously discussed crossover operators (see page~\pageref{sec:crossover}).

The mutation operator is not always a basic random replacement of genes operation. In research done by Il-kwon Jeong and Ju-jang Lee\cite{AdaptiveSAGA}, a mutation operator is presented that uses the \gls{SA} algorithm to determine the genes that need to be replaced. The \gls{SA} mutation operator generates a new chromosome from which genes are used to replace in the chromosome being mutated \cite{AdaptiveSAGA}. Addition mutation operators are discussed in Engelbrecht\cite{CompuIntelligenceIntro}.
\subsubsection{Initial Population Generation}
Initial population generation is the very first activity that the \gls{GA} performs. Out of this population potential mating candidates are selected based on their fitness, which indicates desirability. The initial population is generated by means of randomisation \cite{SelfAdaptiveGA}. Since the algorithm searches multiple points simultaneously in the search space, it is desirable that the initial population have a wide diversity with regard to the problem search space\cite{CombinedBranchBoundGA,DistributedHierarchicalGA}. By controlling the initial population generation we can control, to a small degree, the amount of exploration the algorithm does initially\cite{CombinedBranchBoundGA}. Therefore care must be taken in the selection of the particular randomisation scheme that will be used to generate chromosomes for individuals.

In a survey done by Andrea Reese\cite{RandomNumberGA}, two randomisation schemes were defined, namely  \glspl{PRNG} and \glspl{QRNG}. \glspl{PRNG} were found to be heavily problem dependent, improving the search efficiency in some instances and in other instances having no considerable impact. QRNGs, on the other hand, were shown to significantly improve the final solution produced by the \gls{GA} as well as lower the number of generations for the solution to be obtained \cite{RandomNumberGA}.

\subsubsection{Algorithm Efficiency}
The \gls{GA} is a powerful, yet simple algorithm and tends to find good solutions given enough time, it does have its disadvantages. One of the major disadvantages occurs when the \gls{GA} is applied to problems that have very large solution spaces. In these problems, the population size is a very sensitive parameter\cite{AdaptiveSAGA,HetergeneousGA,SelfAdaptiveDataMiningGA,PatternDetectionGA}. If the population is too small the algorithm will not have enough diversity to search and will tend to converge prematurely. 

A large population is preferred in large search spaces in order to get good chromosome diversity among individuals. Hence, the population size must be fine-tuned to achieve optimal performance in large search spaces \cite{AdaptiveSAGA,CompuIntelligenceIntro}. Note an increase in population does not guarantee good chromomsome diversity among the population. As discussed in initial populaiton generation it is also dependant on the random generation scheme used as well. 


In the next section the pseudo code for the \gls{GA} algorithm is presented and the flow of the \gls{GA} algorithm is discussed
\subsection{Flow of the Algorithm}
The core concepts of the genetic algorithm were introduced in the previous section. To better understand the algorithm, a general overview of the algorithm will be presented in this section using algorithm~\ref{alg:GA} as a reference point.
\begin{algorithm}[H]
\caption{Basic Genetic Algorithm Algorithm\cite{FamilyGA,AdaptiveSAGA,DistributedHierarchicalGA,SelfAdaptiveGA}}
\label{alg:GA}
	\begin{algorithmic}[1]
		\State $pop_n\leftarrow$Initialize population
		\While{Stopping criteria is not met}
    \State Evaluate individuals of population with fitness function $f(\hat{x_i})$
    \State $\hat{y_k} \leftarrow$ Select parent individuals from population using selection operator
		\Repeat
    \For{Each chromosome $\hat{g_i}$ in $\hat{y_{k-1}}$}
    \State $\hat{c_i} \leftarrow$ calculate crossover porbability for $\hat{g_i}$
    \If{$\hat{c_i} \geq$ Crossover threshold}
    \State $\hat{g_i} \leftarrow$ Apply crossover operator to $\hat{g_i}$
				\EndIf
        \State $\hat{o_i} \leftarrow \hat{g_i}$
        \State $\hat{m_i}\leftarrow$ Calculate Mutation probability for $\hat{o_i}$
        \If{$\hat{m_i} \geq$ Mutation threshold}
        \State Apply mutation operator to $\hat{o_i}$
				\EndIf
        \State Add offspring chromosome $\hat{o_i}$ to $new_{pop}$
			\EndFor
		\Until{$size(new_{pop}) = size(pop_n)$}
		\State $pop_n \leftarrow$ select new population from $pop_n$ and $new_{pop}$
		\EndWhile
    \State $\hat{x_i} \leftarrow$ Determine best chromosome in $pop_n$
    \State Return best solution $\hat{x_i}$
	\end{algorithmic}
\end{algorithm}
The \gls{GA} algorithm is a population-based algorithm and therefore needs to initialise its population. Each individual of the population represents a potential solution. Population initialisation occurs in line 1 of algorithm~\ref{alg:GA} on page~\pageref{alg:GA}. 

The amount of individuals in a population to be generated is predefined and is known as the population size. In algorithm~\ref{alg:GA} on page~\pageref{alg:GA} the population size is represented by the subscript $n$ in $pop_n$, where $n > 0$.

Before the algorithm can start \emph{evolving} its population, it first needs to determine each individual in the population's fitness. The fitness of an individual is calculated using a fitness function $f(\hat{x_i})$.

After each individual within the initial population has been evaluated, the algorithm is able to start its searching process, which starts at line 3 and ends at line 17 of algorithm~\ref{alg:GA} on page~\pageref{alg:GA}.

Since each individual has a fitness value after being evaluated, the selection operator is applied. The selection operator used on line 4 determine which individuals will form part of the parents used to generate offspring for the next population.

Once the selection operator has selected the parent individuals needed for the next population, the algorithm is ready to enter the reproduction phase, which ranges from lines 5 -- 17 of algorithm~\ref{alg:GA} on page~\pageref{alg:GA}.

In the reproduction phase the crossover and mutation operators are applied probabilisticly. For the crossover operator a crossover probability is calculated on line 7. Depending if the calculated probability satisfies the crossover probability the crossover operator is applied on line 9. Depending on the crossover used, offspring are generated using one or more individuals as parents. The resulting offspring from the crossover operation is assigned to $\hat{g_i}$.

On line 11 the value of $\hat{g_i}$ is assigned to the variable $\hat{o_i}$ which represents the offspring. From lines 7 -- 11 it can be observed that a particular individual does not have to take part in a crossover operation to be carried over to the new population. Thus knowledge gained from the current population is persisted based on the crossover propbability.

The second step of the reproduction phase is where the mutation operator is applied. For each of the offspring a mutation probability is calculated. If the calculated probability for a particular offspring are high enough, the algorithm enters the mutation phase. In the mutation phase an individual is selected and the mutation operator is applied. Application of the mutation operator can be seen to occur in lines 13 -- 15 of algorithm~\ref{alg:GA} on page~\pageref{alg:GA}.

Regardless of whether the offspring has been mutated or not, the resulting offspring are added to the new population. The reproduction phase continually loops, until the new population equals the size of the initial starting population. Once the amount of individuals in the new population has reached the population size $n$, the algorithm moves on to its next iteration.

After the algorithm has completed the reproduction phase the algorithm selects the new population to be used in the next generation. The new population is selected from the current population and the created offspring.

The algorithm continually generates a new population for each generation until a predetermined stopping criterion has been met. Once the criterion has been met, the algorithm selects the individual with the best fitness in the current population as its most optimal solution. The following section discusses literature where the \gls{GA} has been applied to the \gls{FAP}.

\subsection{Genetic Algorithm on the \gls{FAP}}
Continuing the trend of the \gls{SA} and \gls{TS} algorithms, the \gls{GA} has also been applied to a wide variety of problems. These problems include: solving nonconvex nonlinear programming problems\cite{GANonConvex}, data mining \cite{SelfAdaptiveDataMiningGA} and auto configuring metaheuristic algorithms for complex combinatorial problems \cite{AutoComplexMeta}.

Colombo and Allen\cite{ProblemDecompMIFAP} have developed a \gls{GA} to be applied on the \gls{FAP}. The authors decomposed the \gls{FAP} into smaller subproblems. On average the solution quality is improved by using the technique but at the expense of more complex and taxing evaluations that have to be performed\cite{ProblemDecompMIFAP}. 

In table~\ref{tab:GA} the results obtained by authors on the \gls{COST} 259 benchmarks are compared. The listed values are scalars representing the total interference generated by the frequency plan.
\begin{table}[H]
\centering
	\begin{tabular}{| c | c | c |}
	\hline
	Problem instance & \gls{GA} & Best \gls{COST} 259 \\ \hline
	Siemens 1 & 2.60 & 2.20 \\ \hline
	Siemens 2 & 16.34 & 14.280 \\ \hline
	Siemens 3 & 6.37 & 5.19 \\ \hline
	Siemens 4 & 84.08 & 81.89 \\ \hline
	\end{tabular}
\caption{GA on \gls{COST} 259 Benchmark}
\label{tab:GA}
\end{table}

As per the results in table~\ref{tab:GA} the \gls{GA} produces good results coming close to the best obtained results in the benchmark. By critically reasoning about the \gls{GA} if it were applied to the \gls{FAP} in theory, the following disadvantages can be identified:

\paragraph{Diversity}
--- The \gls{GA} continually operates on a set population that is randomly initialised at the beginning of the algorithm. It therefore only has this set of generated genes in the initialised population to therefore evolve successive populations.
If one disregards mutation, the \gls{GA} is a process by which the optimal combinations of the starting genes are found. Thus, the \gls{GA} purifies the starting population genes in an attempt to find those individual genes, which if combined into a single individual, will produce an optimal individual, i.e. solution. Therefore the \gls{GA} is very reliant on the quality of the random generator used. The probability of the algorithm finding a particular desirable gene that is exhibited by the starting population is directly related to the random number generator used to initialise the population. 
\paragraph{Crossover}
--- The crossover operation in the \gls{GA} is the only means by which successive populations are generated and can therefore be regarded as the primary means by which the algorithm performs its search. As the crossover is defined in the standard algorithm, certain parts of both parents are copied and combined to form a new individual. With regard to the \gls{FAP}, if each individual represents a frequency plan, the crossover operation would copy certain cells from the two parent plans. This is not desirable, since a single channel within a cell can generate major interference which overshadows the rest of the channels that generate low interference in the cell. Thus, for the \gls{GA} to generate high quality solutions on the \gls{FAP}, the algorithm would be better off utilising a crossover operation which works on individual channels assigned rather than cells. Crossover operation is also a memory and computationally expensive operation since individuals need to be constantly created and values need to be copied to these new individuals from the respective parents.
\paragraph{Mutation}
--- Mutation is a means by which more diversity is introduced into the chromosomes of the invididuals.  As discussed, the mutation operator introduces new genes to existing chromosome which can lead to an excellent solution being distorted and becoming one of the worst solutions. With regard to the \gls{FAP}, the low probability of mutation is not desirable, as the \gls{FAP} search space is huge and therefore requires constant diversity to be introduced to accurately explore it. A possible good mutation would be one that is slightly more intelligent than the standard mutation operator, which just randomly modifies a selected individual. An intelligent mutation would be one that takes into account the recent history of the individual as well as the history of the population and, based on the collective knowledge alters or \emph{mutates} a particular individual. Each chromosome would therefore be required to keep history of changes made to itself, to allow the mutation operator to take it into account. Another means of applying the mutation operator is to set the mutation rate proprtional to an individuals fitness. By modifying the mutation rate in this manner, mutating good individuals can be avoided.
\section {Summary}
In this chapter a description was given of metaheuristic algorithms. What it means for an algorithm to be classified as being of a metaheuristic nature was explained as well as the characteristics these algorithms exhibit were identified.

Three metaheuristic algorithms were discussed in this chapter. For every algorithm discussed an explanation was given of how the algorithm works as well as the various characteristics that make the algorithm unique.

For each algorithm, a brief overview of studies using the particular algorithm was given as well as some of the disadvantages or challenges that would be faced when applying the particular algorithm to the \gls{FAP}.

The first algorithm discussed was the tabu search algorithm and the second was the simulated annealing algorithm. The chapter concluded with the genetic algorithm. 

In the table~\ref{tab:summary1}, the algorithms discussed in this chapter and their performance on the \gls{COST} 259 set of benchmarks have been summarised.
\begin{table}[H]
\label{tbl:summaryMetaTable}
\begin{center}
	\begin{tabular}{| c | c | c | c | c |}
	\hline
	Problem instance & \gls{TS} & \gls{SA} & \gls{GA} & \gls{COST} 259 \\ \hline
	Siemens1 & 2.7692 & 23.00 & 2.60 & 2.20 \\ \hline
	Siemens2 & 14.9360 & 14.75 & 16.34 & 14.280 \\ \hline
	Siemens3 & 6.6496 & 52.55 & 6.37 & 5.19 \\ \hline
	Siemens4 & 110.9725 & 80.80 & 84.08 & 81.89 \\ \hline
	\end{tabular}
\caption{Summary of algorithm performance on the \gls{COST} 259 benchmark}
\label{tab:summary1}
\end{center}
\end{table}

In the next chapter the class of algorithm that is relatively new to optimisation research, namely the swarm intelligence class of algorithms, is discussed.
%%% TEXEXPAND: END FILE ./chpt4.tex
%%% TEXEXPAND: INCLUDED FILE MARKER ./chpt5.tex
\chapter[Swarm Intelligence]{Metaheuristic Algorithms: Swarm Intelligence}
\label{chpt:swarm}
\section{Introduction}
The research field of artificial intelligence stands a lot to gain by the study of the inner workings of nature itself; this is why there is a branch of artificial intelligence that incorporates some of nature's processes, like evolution, which can be seen being applied in practice in the \gls{GA} (see section \ref{sec:geneticalgorithm}).

 There are other approaches in artificial intelligence which also have their routes in nature, for instance animal learning or the study of how dogs learn\cite{DLearning}. These approaches only look at a â€œsingle agentâ€ thought process when agent percepts (senses) are mapped to actions in an agents particular environment \cite{DLearning}. 
 
 A percept can be said to be a process that is specifically designed to take data from the surrounding environment, process it and present it as information upon which decisions can be made\cite{DLearning,AIModernApproach}. For instance, eyes are percepts, which take visual data presented by the environment\cite{DLearning,AIModernApproach}. The visual data is processed by the brain into information to enable decisions to be made on navigating the environment\cite{DLearning,AIModernApproach}.

The research field of swarm intelligence is an approach more concerned with the underlying processes and behaviour patterns when multiple agents (insects, animals) come together and perform a task as one collective entity\cite{DLearning,AIModernApproach}.  The study of animals and insects and how they socially interact within their local environments in groups has already contributed to artificial intelligence as a whole in the form of Swarm Intelligence\cite{ChaoticSwarmIntel,BeeJobShop}.  In the field of Swarm Intelligence, animals and insects are represented by agents which are simple stimulus-response agents and can only perceive changes in their local environments. A group of agents is referred to as a \emph{swarm}.

Swarm intelligence works on a key aspect observed in nature, the notion of emergent behaviour\cite{SwarmArt,FundamentalSwarm}. Emergent behaviour is when an individual in the swarm achieves success due to the it obtaining more knowledge through exploration about its local environment\cite{SwarmArt,FundamentalSwarm}.

In swarm intelligence, when an agent exhibits emergent behaviour, the outcome of the behaviour needs to be shared with the whole swarm in order for the swarm to adapt and use the newly gained knowledge\cite{CompuIntelligenceIntro,FundamentalSwarm}.

In a swarm, the agents communicate with each other about knowledge gained as a consequence of the changes in their local environments\cite{SwarmArt,ChaoticSwarmIntel}. Changes can be caused by emergent behaviour by the agent itself, other agents or the environment\cite{CompuIntelligenceIntro,FundamentalSwarm}. Communication among agents facilitates \emph{knowledge sharing}\cite{SwarmArt,FundamentalSwarm}. 

Social interaction among agents is certainly not the only means of interacting, but with regard to biological inspired systems it is the most prominent\cite{CompuIntelligenceIntro}.

Using this social interaction between the agents of the swarm can influence their own local environment to move towards more promosing space in the search space \cite{ChaoticSwarmIntel,CompuIntelligenceIntro}. Thus each agents of a swarm contributes to the swarm as a whole to locate and produce better solutions \cite{BeeJobShop}. Due to the social interaction between agents the swarm is also referred to as a \emph{social swarm}\cite{ChaoticSwarmIntel,FundamentalSwarm} 

As discussed the behaviour propagates from one agent to another through social interaction, which brings forth information exchange\cite{SwarmArt}. Social interaction is but one component of self-organisation. Other components that form part of self-organisation are \cite{SIPowerInNums}:
\begin{itemize}
\item Positive and negative feedback\cite{SIPowerInNums}
\item Increased fluctuations of random events\cite{SIPowerInNums}
\end{itemize}

The means by which agents facilitate indirect communication with each other is known as \emph{stigmergy}. Stimergy as well as the different forms of stigmergy are discussed in ~\ref{sec:stigmergy}.

Swarm intelligence algorithms are also meta-heuristic algorithms, with the distinction being made that swarm intelligence algorithms use multiple agents as a collective entity of knowledge to search the problem space\cite{SwarmArt,ChaoticSwarmIntel,BeeJobShop,CompuIntelligenceIntro,FundamentalSwarm}.

The initial algorithms developed with regard to swarm intelligence, were based on the coordination and behaviour exhibited by schools of fish and flocks of birds. The newer generation of algorithms include\cite{SwarmArt,ChaoticSwarmIntel,BeeJobShop}:
\begin{itemize}
\item \gls{ACO}\cite{SwarmArt}.
\item \gls{ABC}\cite{BeeJobShop}.
\item \gls{PSO}\cite{ChaoticSwarmIntel}. 
\item bacterial foraging optimisation\cite{CompuIntelligenceIntro}.
\item Firefly optimisation\cite{CompuIntelligenceIntro}.
\item Fish school optimisation\cite{CompuIntelligenceIntro}.
\end{itemize}


Swarm intelligence based algorithms are able to achieve good results since they have simple individuals searching in their own local environments for more optimal solutions\cite{CompuIntelligenceIntro,FundamentalSwarm}. A direct consequence of multiple individuals in a swarm searching is that the algorithms are able to explore multple locations within the defined search space\cite{CompuIntelligenceIntro,FundamentalSwarm}. Traditional single agent based metaheuristic algorithms like \gls{TS} (section~\ref{sec:tabusearch}) and \gls{SA} (section~\ref{sec:simulatedannealing}) only have in essence one ``individual'' searching for a solution\cite{CompuIntelligenceIntro,FundamentalSwarm}. 

With algorithms like \gls{TS} and \gls{SA}, the information is not shared since there is only one individual search\cite{CompuIntelligenceIntro,FundamentalSwarm,SASingleMultiObj,TSHazardous}. The information is kept to influence future decisions\cite{AIModernApproach,TabuMontemanniSmith,TabuVechicleRoutingWithTimeWindows,CurveFittingSA,EcoEquilSA}. Swarm intelligence algorithms also store information for use by the various individuals that make up the swarm to make more informed decisions as the search space is explored\cite{CompuIntelligenceIntro,FundamentalSwarm}.

NP-Complete optimisation problems are but one of the fields where swarm intelligence algorithms have been adapted to. Other fields where swarm intelligence has been applied include neural network training\cite{CompuIntelligenceIntro}, vehicle routing\cite{ACOSurvey}, clustering\cite{AntSwarmClustering}, search engines and electrical power systems\cite{SAElectricPower}. Swarm intelligence thus seems more suited towards problems with combinatorial complexity\cite{SIOPDenby}.

The chapter is organised as follows. Before the algorithms are discussed an overview of stigmergy is presented in section~\ref{sec:stigmergy}. Starting with section~\ref{sec:ACO} the first swarm intelligence algorithm is discussed namely, Ant Colony Optimisation. Artificial bee colony is discussed in section~\ref{sec:BEE}. Section~\ref{sec:PSO} is a discussion about the Particle Swarm Optimisation algorithm. This chapter concludes with section~\ref{sec:SISummary} that summurises the chapter.

\section{Stigmergy}
\label{sec:stigmergy}
Stigmergy is defined as the method used by animals and insects to facilitate indirect communication\cite{CompuIntelligenceIntro,AntIntroTrends}. Through the use of stimergy animals or insects are able to socially interact with their own species to convey information to each other\cite{AntsAndStigmergy,FundamentalSwarm}.

Interaction occurs through signals that the individuals receive which might require them to perform a specific action\cite{AntsAndStigmergy,CompuIntelligenceIntro,AntIntroTrends}.

Two forms of stigmergy can be observed in nature. One form, \emph{sematectonic stigmergy}\label{def:sematectonic}, is a direct and physical form of interaction since it relies on altering the environment\cite{CompuIntelligenceIntro}. 

Examples of this type of stigmergy are nest building and brood sorting by ants\cite{CompuIntelligenceIntro}. Schools of fish also use this type of stigmergy to communicate direction and speed by visually observing their closest partner in the school. Besides using visual information, birds use sound to communicate with and alert each other\cite{SwarmArt}.

The other form, \emph{sign-based stigmergy}, is an indirect form of interaction, where communication occurs through some sort of signal mechanism\cite{CompuIntelligenceIntro}. Ants use sign-based stigmergy to communicate with each other. More on how ants communicate with this type of stigmergy is discussed in section~\ref{sec:ACOverview}.

Other species that use sign-based stigmergy are bees\cite{stigmergicoptimization}. When a bee determines that an entity poses a threat to the hive, it might decide to sting the entity. The sting of a bee not only injects a toxin into the entity, but also releases a pheromone\cite{stigmergicoptimization}. This pheromone alerts nearby other bees from the hive of the presence of an entity that is a potential danger to the hive\cite{stigmergicoptimization}. 

The other bees of the hive pick up this pheromone that is released by the initial bee's stinger and attack the entity by also stinging it\cite{stigmergicoptimization}. As more bees sting the entity, more bee stingers emit the danger pheromone identifying the entity\cite{stigmergicoptimization}. Hence the pheromone is reinforced and becomes stronger, which persuades more bees into action\cite{stigmergicoptimization}.

Stigmergy is a powerful mechanism that is able to alter the behaviour of a collective entity efficiently, as can be gathered from the above-mentioned examples of stigmergy in nature\cite{AntsAndStigmergy,CompuIntelligenceIntro,AntIntroTrends}. Stigmergy is therefore a core concept upon which swarm intelligence algorithms are based as these communication techniques are exploited to aid the algorithm in finding better solutions\cite{AntsAndStigmergy,CompuIntelligenceIntro,AntIntroTrends}.

In the forthcoming sections three swarm intelligence algorithms are discussed. Each section is divided into four subsections. 

First, an overview of the algorithm is given, where basic concepts about the algorithm are introduced as well as a general outline given of the search process the algorithm uses. 
The second subsection will give an in-depth discussion of some of the core characteristics that make the algorithm unique. 
The third subsection will provide a step-by-step discussion of the algorithm using pseudocode as a reference.

Finally, for each algorithm studies using the algorithm on the \gls{FAP} are mentioned and the various considerations that need to be made to apply the algorithm to the \gls{FAP} are identified.

\section{Ant Colony Optimisation (ACO)}
\label{sec:ACO}
\subsection{Introduction}
\label{sec:ACOverview}
ACO is a class of algorithms incorporating different behavioural aspects that ants exhibit when they perform certain activities, i.e. gather food, build nests and construct cemeteries\cite{AntsAndStigmergy,CompuIntelligenceIntro}. The first \gls{ACO} algorithms that were developed were based on the foraging behaviour that was exhibited by ants when finding the most optimal path towards a food source. Deneubourg noticed the foraging behaviour when he performed the bridge experiment \cite{AntsAndStigmergy,CompuIntelligenceIntro}.

The bridge experiment outlined by Deneubourg placed a food source a certain distance away from the nest\cite{AntsAndStigmergy,CompuIntelligenceIntro}. Two bridges of equal length were established towards the food resource. The ants initially selected a path randomly with no clear distinction of the more dominant path to take to retrieve food from the food source\cite{AntsAndStigmergy,CompuIntelligenceIntro}. After a finite amount of time, one of the paths to the food source became the preferred route for the ants even though both paths were of equal length. The preference of the one bridge by the ants is.

Deneubourg concluded that ants utilise pheromones to communicate to the rest of the foraging ants the shortest path towards a food source.\cite{FundamentalSwarm} By using pheromones to communicate with other ants it can be concluded that ants use sign-based stigmergy (discussed in section~\ref{sec:stigmergy}) when they retrieve food\cite{AntIntroTrends,AntsAndStigmergy,CompuIntelligenceIntro}. As the ant moves along a particular path, it marks the path with a chemical signal that alerts other ants to the desirability of the path \cite{CompuIntelligenceIntro}. The chemical signal that ants use to indicate optimal paths is called \emph{pheromones}\cite{AntsAndStigmergy,CompuIntelligenceIntro}.

The bridge experiment was extended to have two bridges that differ in length. The extended bridge experiment is presented in figure~\ref{fig:antBridgeExperiment} and is known as the shortest path bridge experiement\cite{FundamentalSwarm}. In the experiment the ants started to prefer the shortest bridge \cite{FundamentalSwarm}. The conclusion was made that the ants prefered the shorter bridge because ants return to the nest quicker and therefore the path is reinforced with pheromones faster than on the longer path\cite{FundamentalSwarm}.

\begin{figure}[H]
	\centering
	\setlength \fboxsep{0pt}
	\setlength \fboxrule{0.5pt}
	\fbox{\includegraphics[width=4.0in,height=2.0in]{./pictures/antBridgeExperiment.png}}
	\caption{The shortest path bridge experiment \cite{AntsAndStigmergy}}
	\label{fig:antBridgeExperiment}
\end{figure}

Pheromones used by the ants in \gls{ACO} go through two phases. The first phase is where pheromones a despoited on a particular path by an ant whether their exists previous pheromones or not. The second phase is where pheromones evapurate. Pheromones are not permenant and deteriorate over time\cite{FundamentalSwarm}. By letting pheromones evapurate, ants can ``forget'' previous desicions made by die colony\cite{FundamentalSwarm}. It can be concluded that the more pheromones evapurate the less influence the ants will have on their path selection, therefore promoting exploration\cite{FundamentalSwarm}.

The concept of pheromones and how the \gls{ACO} proceeds in updating the pheromones is a critical concept of \gls{ACO}. Hence, an in-depth discussion on pheromones is provided in subsection \ref{sec:ACOcharacter}.

The \gls{ACO} class of algorithms have a \emph{core requirement} about the problem they are applied to\cite{FundamentalSwarm}. The problem must be able to be modelled as a graph. The reason behind this requirement is that each individial ant in the \gls{ACO} algorithm constructs a path through the graph\cite{FundamentalSwarm}. The path constructed represents a solution.

A path through a graph is made up of a series of links between nodes\cite{AIModernApproach,DataStructuresJava}. A link between two nodes represents a movement from one node to the other\cite{AIModernApproach,DataStructuresJava}. Therefore, a path can be considered as the traversal of the interlinked nodes, from a starting node to some final node\cite{AIModernApproach,DataStructuresJava}. A path differs from another path by the order in which the nodes are interlinked between a start and end node\cite{AIModernApproach,DataStructuresJava}.

 The \gls{ACO} class of algorithms has been applied to a wide range of problems that include single machine scheduling\cite{ACOSingleMachine},weapon target assignment\cite{WeaponTargetACO}, flow shop scheduling\cite{ACOFlowShop} and image thresholding\cite{ACOImageThreshold}. Variants of the standard algorithm have been developed, but all of the algorithms still follow the core structure of the \gls{ACO} algorithm\cite{CompuIntelligenceIntro,FundamentalSwarm}.
The first algorithm developed based on the foraging behaviour of ants is known as the \gls{SACO} and was proposed by Dorigo in 1992 \cite{CompuIntelligenceIntro}. The algorithm provided the basis for how pheromones are used and updated. The \gls{SACO} is an algorithmic implementation of the double bridge experiment.

The first algorithm to improve upon the \gls{SACO} is the \gls{AS} \cite{CompuIntelligenceIntro,AntIntroTrends}. The \gls{AS} included heuristic information into the probability that an ants chooses to move towards a node. The \gls{AS} also added memory to the \gls{AS} by using a tabu list and also incorporated pheromone evapuration. The improvements made enabled the \gls{AS} to better explore the search space and produce better results\cite{CompuIntelligenceIntro,AntIntroTrends}. 

The \gls{AS} algorithm has achieved relatively good success in the problems it has been applied to, but it does have some disadvantages\cite{ImpACOComplex,ACOSurvey}. One of the primary disadvantages of \gls{AS} is that it tends to prematuve converge on local optima \cite{FundamentalSwarm,ImpACOComplex}. The premature convergence can be attributed to due to the ants exploiting the high concentration of pheromones on good solution paths too quickly\cite{FundamentalSwarm}. With the ants focusing only on the good solutions less exploration occurs in the search space leading to local optima being produced as the best solution\cite{FundamentalSwarm}.

Subsequently, various algorithms have been developed that improve on the \gls{AS} algorithm. These improved algorithms include the \gls{ACS}, \gls{MMAS}, Ant-Q, fast ant system, AntTabu, \gls{AS}-rank and i\gls{ANTS}\cite{CompuIntelligenceIntro,AntIntroTrends}. The discussion in this section is focused on providing an introduction to the general \gls{ACO} algorithm concepts and not to discuss various improvements made by variants of the core algorithm. In the forth coming sections reference is made to these algorithms and their respective improvements.

The \gls{AS} algorithm is the base algorithm upon which all other \gls{ACO} class algorithms are based upon. Therefore in the forth coming sections when a reference is made to the \gls{ACO} algorithm, it is directed at the base \gls{AS} algorithm.

In this section the concepts  upon which the core of \gls{ACO} is based upon were briefly introduced. In the next section a discussion is given on each of the concepts.
\subsection{ACO Characteristics}
\label{sec:ACOcharacter}
In this section characteristics that are important and unique to the \gls{ACO} class of algorithms is discussed. The discussion is focused upon three core characteristics namely pheromone trials, pheromone evaporation, pheromone updates and state transition rules.
\subsubsection{Pheromone Trail}
\label{sec:pheromonetrail}
The pheromone technique used by ants forms part of the core methodology used by the \gls{ACO} algorithm \cite{AntQAP}. As an ant moves it lays down pheromones to mark the path it is walking.

With the use of pheromones ants are able to communicate the best and shortest link between nodes\cite{AntQAP,AntsAndStigmergy,CompuIntelligenceIntro}. The more ants following a preferred link the more pheromones would be deposited on that specific link. This increases the strength of the pheromones \cite{ImpACOComplex}. The increase in strength of the pheromones on a link would thus let ants more clearly distinguish between links they should and should not take \cite{ImpACOComplex}. Therefore, a pheromone provides positive feedback to the colony\cite{AntQAP,AntsAndStigmergy,CompuIntelligenceIntro}.

Initially, all the ants will choose a random link to a node\cite{AntQAP,AntsAndStigmergy,CompuIntelligenceIntro}. After all the ants have completed their paths, each path is evaluated using a cost function defined by the problem domain\cite{CompuIntelligenceIntro}. The amount of pheromone marking the links contained in a path in the standard \gls{ACO} is related to the cost function\cite{AntQAP,AntsAndStigmergy,CompuIntelligenceIntro}. Therefore, a low cost function value will have a high pheromone dosage and a high cost function value will have a low dosage\cite{CompuIntelligenceIntro}. 

By incorporating the cost of a particular path into the amount of pheromone deposited the colony is able to influcence future decisions\cite{CompuIntelligenceIntro}. In terms of minimisation a path with a low cost will have a high pheromone value making the links of path more likely to be selected by future ants\cite{CompuIntelligenceIntro}.

In the iterations following the initial one, the ants will at each node decide based on a probability whether it should to a particular neighbouring node. The higher the pheromone intensity is at a neighbouring node, the higher the probability that the ant will choose to move towards that node\cite{AntQAP,AntsAndStigmergy,CompuIntelligenceIntro}. The probability with which ants choose links to neighbouring nodes are defined and discussed in the next section.

Due to ants choosing links to node based on a probability, it is still possible for the ant to choose a random link towards an other node. Thus the \gls{ACO} algorithms are considered stochastic search procedures due to the ants ability to choose links randomly when exploring the search space \cite{ACOSurvey,ImpACOComplex}.

The pheromone trail was initially developed with only one colony in mind \cite{CompuIntelligenceIntro}. In research done by Tiwari et al.\cite{ACOLargeProblem} pheromones in multiple colonies are considered. The basic principle of how pheromones are used by the ants stays the same, but the meaning of the pheromone changes if an ant of another colony encounters the pheromone trail\cite{AntQAP,AntsAndStigmergy,CompuIntelligenceIntro}. The ant will not follow or even consider the pheromone trail since any pheromone encountered from other colonies repulses the ant\cite{ACOLargeProblem}. Thus pheromones only provide positive feedback if the ant is from the same colony, otherwise the pheromone gives negative feedback, in a way warning the ant to stay away\cite{ACOLargeProblem}. This repulsion strategy promotes exploration among the multiple colonies\cite{ACOLargeProblem}. The probability with which a link towards a particular node is chosen by an ant forms part of the \emph{state transition rules}.

\subsubsection{Pheromone Evaporation}
\label{sec:pheromoneevapuation}
Initially when the pheromone concept was first implemented the ants of the colony rapidly converged on a solution\cite{CompuIntelligenceIntro}. The search space was not adequately explored and the produced solution was of local optima\cite{AntsAndStigmergy}. To combat this premature convergence and force the ants to explore the search space more, the concept of \emph{pheromone evaporation} was introduced\cite{AntIntroTrends,AntSurvey}. 

Real pheromones used by ants to mark a particular link to a node is not permanent and over time the strength of the pheromone deteriorates until it eventually disappears\cite{CompuIntelligenceIntro}. Pheromone deteriorating is known in the literature as pheromone evaporation\cite{CompuIntelligenceIntro}. The pheromone will not completely evaporate as long there are ants traversing the defined link reinforcing the pheromone. The evaporation of pheromones is modelled in the \gls{ACO} by equation \ref{eq:pheromoneevapuration}\cite{AntIntroTrends,AntSurvey}:
\begin{equation}
\label{eq:pheromoneevapuration}
	\tau_{ij}(t) = (1-p)\tau_{ij}(t), p\in [0,1]
\end{equation}
The constant $p$ defines the rate at which the pheromone evaporates. If $p=1$ the pheromone completely evaporates every iteration. With no pheromone on a link towards a node the ants take no knowledge gained from the previous iteration into account and therefore select a link randomly \cite{CompuIntelligenceIntro,AntsAndStigmergy}. Thus, the amount of exploration done by the algorithm can be controlled by the constant $p$ \cite{CompuIntelligenceIntro,AntsAndStigmergy}.

Equation \ref{eq:pheromoneevapuration} was first introduced in the \gls{AS} \cite{CompuIntelligenceIntro,AntSurvey}. Most subsequent algorithms that are a form of the \gls{ACO} class of algorithms also use the concept of pheromone evaporation, but they either use the standard equation or develop their own variant \cite{CompuIntelligenceIntro,AntsAndStigmergy}.

A more aggressive form of pheromone evaporation  is added to the \gls{AS} discussed in the research done by Gambardella et. al\cite{AntQAP}. The more aggressive form works beside the already present pheromone evaporation, but this form seeks to add an additional search phase called \emph{diversification}\cite{AntQAP}. The aim of the diversification phase is to lead the algorithm into another direction of the search space\cite{AntQAP}. This is done in an attempt to avoid local minima and stagnation\cite{AntQAP}.

In the ant system developed by Gambardella et. al. the algorithm continually monitors the current best solution and keeps a history of recent best solutions\cite{AntQAP}. If the algorithm starts to notice that solutions are cycling or that the current best solution has not changed for a certain number of iterations, the algorithm activates the diversification phase\cite{AntQAP}. In this phase the algorithm is forced to re-search the search space to create new solutions, as it cannot rely on previous historical information provided by the pheromone trails\cite{AntQAP}.

\subsubsection{State Transition Rules}
\label{sec:STR}
The intention for this section is not to give an exhaustive survey of different transition rules in the literature. Therefore, only the first transition rule that was developed is discussed, since most of the other rules can be considered derivatives of the first. 

 As discussed previously, the ants select which link to follow towards a node based on a probability. This probability is also known as the \emph{transition probability} and is formulated by equation~\ref{eq:ASprobability}.
\begin{equation}
\label{eq:ASprobability}
p^k_{ij}(t) =
\begin{cases}
	\frac{\tau^{\alpha}_{ij}(t)\eta^{\beta}_{ij}}{\sum_{u \in N^k_i(t)} {\tau^{\alpha}_{iu}(t)\eta^{\beta}_{iu}(t)}}, &\text{if $j \in N^k_i(t)$}\\
	0, &\text{if $j \notin N^k_i(t)$}\\
\end{cases}
\end{equation}
The transition probability is used by individual ants of the \gls{AS} algorithm \cite{AntQAP,FundamentalSwarm}. An ant $k$ uses this equation to decide with what probability it will move from node $i$ to node $j$ \cite{CompuIntelligenceIntro,ACOLargeProblem}. $\tau_{ij}$ is the amount of pheromone on the link between nodes $i$ and $j$ \cite{AntsAndStigmergy,ACOLargeProblem}. Heuristic information is incorporated into the equation through the symbol $\eta_{ij}$, which is the desirability of the link from node $i$ to node $j$ as evaluated by a heuristic function \cite{AntsAndStigmergy,ACOLargeProblem}. 

Each ant starting at a source node moves from one node to another based on the defined transition probaility until the ant reaches the final node.

Through the use of parameters $\alpha$ to represent pheromone intensity and $\beta$ to represent heuristic information the algorithm is able to achieve a good balance between exploration and exploitation when $\alpha=\beta$ \cite{ACOLargeProblem,AntQAP}. When $\alpha = 0$ no pheromone is taken into account; hence, any history that the algorithm has on the link between node $i$ and node $j$ is neglected and the algorithm degrades to a stochastic greedy search procedure. If $\beta = 0$ then the algorithm does not take into account the amount of desirability of the link between node $i$ and node $j$ as dictated by the problem-specific heuristic function.

The set $j \in N^k_i(t)$ contains all the valid neighbourhood moves ant $k$ is allowed to make when moving from node $i$ to node $j$. A tabu list is kept by each ant to trim the set of moves already performed previously, and thus cycling is prevented.

The interested reader that requires more information about state transition rules is directed to the survey by Engelbrecht\cite{FundamentalSwarm}.
\subsubsection{Pheromone Update}
Pheromones start to evaporate over time, and so the link marked by a pheromone trail becomes less attractive to the ants. Therefore, a path that represents a good solution needs its pheromone trail to be continuously reinforced. Certian rules govern when and by how much pheromones are reinforced.

 Most of the variants that have been developed differ in what pheromone update rules they employ. In the literature pheromone update rules are classified into two groups \cite{CompuIntelligenceIntro}. One group is called the global update rule. The other group is called the iteration-based or local update rule\cite{CompuIntelligenceIntro}. 

The first local pheromone update rule was first introduced in the \gls{AS} algorithm \cite{CompuIntelligenceIntro,AntSurvey,AntsAndStigmergy}. The ants would retrace their path after each iteration, depositing pheromones on each link that makes the complete path. The following equation is used to update the pheromone:
\begin{align}
\label{eq:pheromonedeposit}
 \tau_{ij}(t+1) &= \tau_{ij}(t) + \Delta\tau_{ij}(t),\\ 
 \text{where }\Delta\tau_{ij} &= \sum^{n_k}_{k=1}\Delta\tau^k_{ij}(t) \notag
\end{align}
In equation~\ref{eq:pheromonedeposit} $\tau_{ij}(t+1)$ represents the amount of pheromone that will be on the link for the next time step $(t+1)$. $\tau_{ij}$ represents the amount of pheromone currently on the link $(i,j)$. $\Delta\tau_{ij}$ is the actual amount of pheromone that needs to be added to the current pheromone $\tau_{ij}$.

Pheromone update rules that are in the global update group only allow the pheromone trail of the path representing the best found solution since the first iteration to be updated \cite{CompuIntelligenceIntro}. Thus the global rule favours intensification where the algorithm exploits the global knowledge gained by the ants to find a better solution. By updating a pheromone the concentration of the particular pheromone is reinforced.

\gls{ACS} was the first to use both the global update rule and local update rule together\cite{CompuIntelligenceIntro}. By using both types of rules the algorithm is able to efficiently exploit the history provided by the pheromones\cite{CompuIntelligenceIntro}. The global update rule used by the \gls{ACS} is formulated in the following equation\cite{CompuIntelligenceIntro}:
\begin{align}
\label{eq:pheromoneupdate}
	\tau_{ij}(t + 1) &= (1 - p_1)\tau_{ij}(t) + p_1\Delta\tau_{ij}(t),\\
	\text{where }\Delta\tau_{ij} &= \notag
	\begin{cases}
		\frac{1}{f(x^+(t))} &\text{if $(i,j) \in x+(t)$}\\
		0 &\text{otherwise}
	\end{cases}
\end{align}
The parameter $f(x^+(t))$ represents the best/shortest path found so far by the algorithm\cite{CompuIntelligenceIntro}. $p_1$ is the variable that controls the rate of evaporation. $\Delta\tau_{ij}(t)$ is the amount of pheromone at the current time step $t$ for the link $ij$.

By using the global update rule the algorithm is able to direct the search more, which is to say the algorithm exploits the search space more. Exploitation is achieved since the best path is continually used in the update of the pheromone as can be observed in equation~\ref{eq:pheromoneupdate}\cite{CompuIntelligenceIntro,FundamentalSwarm}.

As can been seen in the following equation, the \gls{ACS} uses a slight variant of the local update rule first used in \gls{AS}\cite{CompuIntelligenceIntro}:
\begin{equation}
	\tau_{ij}(t) = (1 - p_2)\tau_{ij} + p_2\tau_0
\end{equation}
In the above equation $\tau_0$ is a small constant and $p_2 \in [0,1]$ is the constant that defines the rate of evaporation\cite{CompuIntelligenceIntro}. With the local update rule, the algorithm is able to explore more. The path constructed by the individual ant is used to update the pheromone and no information from the best path found in the colony is incorporated, as with equation~\ref{eq:pheromoneupdate}\cite{CompuIntelligenceIntro,FundamentalSwarm}.

The \gls{MMAS} algorithm as discussed also improves on the \gls{AS}. The global update rule used by \gls{AS} has a disadvantage in the sense that the search might concentrate too quickly on a particular good solution (the global best path)\cite{FundamentalSwarm}. \gls{MMAS} address this disadvantage by using the global update rule on an iteration basis\cite{FundamentalSwarm}.

When considering only on an per iteration basis, the best path found by the algorithm can differ from one iteration to the next\cite{FundamentalSwarm}. Therefore the \gls{MMAS} a different path will be updating with the global update rule each iteration\cite{FundamentalSwarm}. Using this approach the algorithm is allowed to explore the search space more\cite{FundamentalSwarm}.

Another short coming of the \gls{AS} is that pheromone concentrations can become extremely high leading to less exploration by the algorithm\cite{FundamentalSwarm}. The \gls{MMAS} algorithm addresses this short coming by enforcing an maximum and minimum amount of pheromone that can exist on a path\cite{FundamentalSwarm}. By defining a maximum the algorithm is prevents the algorithm from settling on one particular solution i.e, stagnation\cite{FundamentalSwarm}. On the other hand, defining a minimum on all possible links between nodes ensures that links will be continiously considered for possible inclusion into a solution\cite{FundamentalSwarm}. In addition to providing boundaries for the pheromones \gls{MMAS} also uses a smoothing strategy to even out the difference between high and low pheromones\cite{FundamentalSwarm}.

\subsection{Flow of the Algorithm}
In this section the process the \gls{AS} algorithm uses to explore the search space is described using algorithm~\ref{alg:ACO} as a reference point.
\begin{algorithm}[H]
\caption{Ant System Algorithm~\cite{CompuIntelligenceIntro}}
\label{alg:ACO}
	\begin{algorithmic}[1]
	\State$\text{Initialize $\tau_{ij}$ with small starting values}$
	\State$t \leftarrow 0$
	\State$\text{Place $n_k$ ants on starting node}$
	\While{stopping condition not reached}
		\For{each ant $k \leftarrow 0$ to  number of ants $n_k$}
			\State$p^k(t) \leftarrow \text{Initialize path } p^k \text{for time step } t$
			\Repeat
				\State$\text{Select next node based on probability equation~\ref{eq:ASprobability}}$
				\State$\text{Add link (i,j) to path } p^k(t)$
			\Until{Final node reached}
			\algstore{AS}
	\end{algorithmic}
\addtocounter{algorithm}{-1}
\end{algorithm}

\begin{algorithm}[H]
\caption{Ant System Algorithm (continued)}
\label{alg:ACO1}
	\begin{algorithmic}
		\algrestore{AS}
			\State$x^k(t) \leftarrow \text{Remove loops from path }p^k(t)$
			\State$\text{Calculate length of path $f(p^k(t)$})$
		\EndFor
		\For{each link $(i,j)$ in graph}
			\State$\tau_{ij} = \text{Reduce pheromone of link $(i,j)$ with equation~\ref{eq:pheromoneevapuration}}$
		\EndFor
		\For{each ant $k = 0$ to  number of ants $n_k$}
			\For{each link $(i,j)$ in $p^k(t)$}
				\State$\triangle \tau_{ij} = \frac{1}{f(p^k(t))}$
				\State$\text{Update the pheromone $\tau_{ij}$ with equation~\ref{eq:pheromoneupdate}}$
			\EndFor
		\EndFor
		\State$t \leftarrow t + 1$
	\EndWhile\\
	\Return $\text{path $x^k(t)$ with the smallest $f(x^k(t))$ as the solution}$
	\end{algorithmic}
\end{algorithm}

The \gls{ACO} algorithm initialises by creating a set population of ants and placing them on random starting nodes as well as initialising the pheromones to starting values as can be observed from algorithm~\ref{alg:ACO}, lines 1 -- 3. The main purpose of the ant is to explore the search space and to ultimately produce a solution that might be optimal. The ant explores the search space by performing a series of moves from one node to another. Each move is a link that is added to the path. This process can be seen in lines 5 -- 10.

The ant selects which node to move to next based on a probability. The probability is calculated taking into account the amount of pheromone that is on the current link representing the movement from the current node to the next node\cite{CompuIntelligenceIntro,FundamentalSwarm}. This decision process can be seen to occur in line 8.

As the ant moves it records each link between the nodes it traverses until it reaches the final node. All the links the ant has traversed represent a path taken through the search space\cite{CompuIntelligenceIntro,FundamentalSwarm}. Thus, as the ant is moving it is actively building an optimal solution.

Before the ant deposits pheromone on the links it traversed to construct its solution, the pheromones first need to be decayed. This is why in lines 14 -- 16, the algorithm traverses all links that contain pheromones and reduces the amount of pheromones by applying equation~\ref{eq:pheromoneevapuration}.

Once an ant has constructed a path and the pheromone evaporation has occurred, the ant is ready to inform the rest of the ants of what movements it made to construct its solution. The ant needs to share this movement information in order for the rest of the colony to know which movements worked well and which did not. The ant therefore needs to signal the other ants, which is accomplished with pheromones. Therefore, in the next phase of the algorithm, pheromones are deposited on all the links that make up the path the particular ant constructed. In the algorithm pheromones are deposited on lines 17 -- 22 in algorithm~\ref{alg:ACO1}.

After all the ants have deposited pheromones on all the links represented by each individual ant's constructed solution, the algorithm is ready to continue to its next iteration. This process occurs until some defined stopping criterion occurs.

\subsection{ACO on the \gls{FAP}}
ACO has been applied to a wide number of problems and has produced good results. As discussed in chapter~\ref{chpt:fap}, the \gls{FAP} can be modelled as a graph and therefore the \gls{ACO} has also been applied to it.

When using the \gls{ACO} algorithm on the \gls{FAP} the ants need to construct a path that represents a frequency plan and has low interference. With the \gls{ACO}, a node is a cell that has a unique set of channels assigned to it. Thus the same cell may exist in the search space, but will have a different set of channels assigned to it, and will therefore represent an entirely different node to the \gls{ACO}.

As an ant moves in the frequency planning domain, it is actually moving between two cells that are said to interfere. The interference between two cells occurs as a consequence of the channels that have been assigned to them. 

As an ant completes a movement from one cell to another, i.e. it assigns channels to the cell, it measures the interference that occurs due to the assignment.  The measured interference information is incorporated into the pheromone, which the ant will deposit on the link between the two cells.

An optimal frequency plan would therefore be a path through all the interfering cells marked with a high dosage of pheromone. As discussed in the previous sections, the pheromone indicates the desirability of a particular path. In the \gls{FAP}, a desirable path would be one where interference is low; thus a path with a high dosage of pheromones would be the frequency plan with the lowest interference found by the algorithm.

When analysing the basic \gls{ACO} algorithm~\ref{alg:ACO} one can identify the following possible disadvantages if the algorithm were applied to the \gls{FAP}:
\paragraph{Memory Usage}
--- The algorithm requires a fair amount of memory. The memory is used to keep track of each permutation of a particular cell and its allocated frequencies until the pheromone that links to the cell has decayed enough to be discarded. As an ant moves from one cell to another, it might not select the previous cell (due to probability) to move to, but rather generates an entirely new cell to move towards. This newly generated cell would then be linked to the previous cell, and therefore the algorithm needs to keep track of the pheromone on that link until it has completely been decayed away. The algorithm needs to keep track of these pheromones on the links even if the new link to the generated cell is not even close to optimal and has very high interference.
\paragraph{Building a solution}
--- The \gls{ACO} \emph{builds} an optimal solution. Therefore, early decisions made by the ants still influence the plan later for better or for worse. A good decision might seem to be good early on, but later the algorithm might be better off with a slightly worse decision. In the \gls{FAP}, a cell can have multiple interfering cells, but a particular ant only knows about one link between two cells and not about the other interfering cells. Thus an ant will find the optimal path on the first interfering link between two cells, in other words it will optimise the channels allocated to these cells so that interference is low. The first interfering link is now optimised, and subsequent ants will reinforce this channel allocation since the interference is low. When the ants later reach the other cells that also interfere with the first cell that has been optimised, they will have difficulty changing the assignments that have already been made, since the pheromone representing that assignment is too strong to disregard.

The above disadvantages have only been identified by critically evaluating the algorithm as a possible point of interest to produce an optimal solution for the \gls{FAP} for this dissertation. Even with these disadvantages the \gls{ACO} has achieved success in producing high quality optimal solutions for the \gls{FAP}.

In research conducted by Luna et al.\cite{ACOvsEA} an \gls{ACO} algorithm was applied to a custom cellular network instance. This network instance had 711 sectors with 2 612 transceivers, which needed to be assigned frequencies. For their particular network, only 18 channels were available for assignment. The channels started at 134 and ended at 151\cite{ACOvsEA}.

The authors presented two versions of the algorithm. The first version used no heuristic information (henceforth referred to as \gls{ACO}*) and the other version used heuristic information to update the pheromone laid done by the artificial ants\cite{ACOvsEA}.

With regard to the heuristic updating of the pheromone trails, the authors opted to increase the pheromone by some magnitude\cite{ACOvsEA}. This magnitude was handtuned to be 100. The heuristic only increases a certain path's pheromone if the frequencies assigned to the transceivers represented by this path differ enough so as to not cause significant interference\cite{ACOvsEA}. Thus, the heuristic aims to amplify good choices made previously by the algorithm for the next iteration of the algorithm.

In table~\ref{tab:ACO} the results abtained by Lune et. al \cite{ACOvsEA} are presented. By evaluating the results obtained, one can clearly see that the \gls{ACO} version that incorporates heuristic information to reinforce pheromone trails outperforms the version that does not \cite{ACOvsEA}. The values depicted in the table represent the amount of interference that will result if the plan is used in the network\cite{ACOvsEA}.
\begin{table}[H]
\centering
	\begin{tabular}{| c | c | c |}
	\hline
	Time limit & \gls{ACO}* & \gls{ACO} \\ \hline
	120s & 104719.72 & 91140.04 \\ \hline
	600s & 103752.12 & 89703.44 \\ \hline
	1 800s & 103781.86 & 88345.94 \\ \hline
	\end{tabular}
\caption{ACO and \gls{ACO}* on custom GSM \gls{FAP} benchmark\cite{ACOvsEA}}
\label{tab:ACO}
\end{table}
\newpage
\section{Artificial Bee Colony (ABC) Algorithm}
\label{sec:BEE}

\subsection{Introduction}
The \gls{ABC} algorithm is the most recently presented algorithm in the literature discussed in this chapter\cite{ABCCompareStudy,ABCLeafConstrained,ABCNumericalOptimization}. The algorithm was first proposed by Karaboga in 2005 who wanted to mimic the foraging behaviour exhibited by bees \cite{ABCCompareStudy,ABCLeafConstrained,ABCNumericalOptimization}. Like ants, bees need to gather food to support the colony. To understand how the \gls{ABC} algorithm tries to mimic the foraging behaviour of bees, this behaviour of real bees needs to be described first\cite{ABCCompareStudy}. 

In a bee colony there are numerous bees, each with a specific role that dictates what actions a bee can perform. There are bees that protect the queen, maintain the colony, scout for resources and gather food, i.e the worker bees. The most important bees for foraging are those that scout and gather food\cite{ABCCompareStudy}. 

The scout bees are sent out and as their role implies, are responsible for exploring the surroundings of the hive to find suitable food sources\cite{ABCCompareStudy}. If a scout bee has found a food source it needs to return to the colony to share the information with the worker bees\cite{ABCCompareStudy}. When the bee enters the colony it needs to communicate to the other bees by using some form of stigmergy (see section~\ref{sec:stigmergy})\cite{ABCCompareStudy}.

The scout bee accomplishes this communication by performing a dance known as the \emph{waggle dance} in the colony for all the bees to see\cite{ABCCompareStudy}. This is not a dance as in the traditional sense, since through certain movements the bee is able to communicate a variety of characteristics about the food source including\cite{ABCCompareStudy}:
\begin{itemize}
\item How far the food source is from the colony
\item Quality of the food source
\item Path towards the food source
\end{itemize}

It can be concluded that foraging bees use \emph{sematectonic} stigmergy (discussed in section~\ref{sec:stigmergy}). This is deduced from the dance which is a physical form of communication.

The dance is observed by \emph{onlooker} worker bees \cite{ABCCompareStudy,ABCImageEnhancement}. These onlooker bees are initially \emph{unemployed} in the colony \cite{ABCCompareStudy,ABCImageEnhancement}. Once the information of the scout has been transferred to the onlooker bees, the onlooker bees become \emph{employed} bees\cite{ABCCompareStudy,ABCImageEnhancement}. They become employed bees when they operate on a particular food source to gather food\cite{ABCCompareStudy,ABCImageEnhancement}. Thus it is the job of the worker bees to \emph{exploit} the information provided by the \emph{exploration} done by the scout bees \cite{ABCCompareStudy,ABCNumericalOptimization}. 

Worker bees gather food from the designated food source, until the food source reaches a certain quantity with regard to nectar content \cite{ABCCompareStudy,ABCNumericalOptimization}. Each time the bee returns to the colony it evaluates the current food source versus other food sources discovered \cite{ABCCompareStudy,ABCNumericalOptimization}. If a better food source is found, the bee abandons the previous source and starts gathering food from the new source \cite{ABCCompareStudy,ABCNumericalOptimization}. On the other hand, if the food source has been exhausted, meaning there is no more nectar content to gather, the bee returns to the colony and becomes ``unemployed'' \cite{ABCCompareStudy,ABCNumericalOptimization}.

In the \gls{ABC} algorithm, possible solutions are considered to be food sources\cite{ABCCompareStudy,ABCNumericalOptimization}. Each food source has an employed bee associated with it. Onlooker bees either wait for new food sources to be communicated to them or become employed bees by moving to another, more attractive food source \cite{ABCCompareStudy,ABCNumericalOptimization}. 

A food source might be more attractive to a bee because its defined nectar content is more than that of the current food source the bee is operating on\cite{ABCCompareStudy,ABCNumericalOptimization}. The nectar content of a food source can be considered to be the fitness, which is determined using the fitness function of the specific problem domain\cite{ABCCompareStudy,ABCNumericalOptimization}.

As with real honey bees, a \emph{waggle dance} is performed to all the onlooker bees by employed bees that provide information on the nectar amount (fitness value) that they represent \cite{ABCReconfigDistro,ABCCompareStudy,ABCImageEnhancement}. The onlooker bees choose food sources depending on the nectar amount \cite{ABCReconfigDistro,ABCCompareStudy,ABCImageEnhancement}; therefore as the nectar amount of a food source increases, the probability that more onlooker bees will choose the source increases \cite{ABCReconfigDistro,ABCCompareStudy,ABCImageEnhancement}. How and what affects the probability is discussed in the next subsection.

Bees can transition to different roles depending on their situation \cite{ABCCompareStudy,ABCNumericalOptimization}. An onlooker bee becomes employed when assigned to a food source and an employed bee can become a scout if its initial food source becomes exhausted \cite{ABCImageEnhancement,ABCCompareStudy,ABCReconfigDistro}. Note that not all employed bees of a food source become scouts; only the first employed bee of a food source transitions to a scout \cite{ABCImageEnhancement,ABCCompareStudy,ABCReconfigDistro}. Scout bees are sent to randomly generated food sources \cite{ABCImageEnhancement,ABCCompareStudy,ABCReconfigDistro}. 

The more onlooker bees a food source attracts, the more the neighbourhood will be explored since the onlooker bees move to the food source and choose an immediate neighbouring food source to be employed upon \cite{ABCCompareStudy,ABCNumericalOptimization}. Thus, this can be considered exploitation and the algorithm is therefore performing a local search\cite{ABCCompareStudy,ABCReconfigDistro,ABCNumericalOptimization}. Finally, the number of onlooker bees a food source has also indicates its desirability. A very good solution will have the majority of onlooker bees choosing it and searching for nearby better food sources \cite{ABCCompareStudy,ABCReconfigDistro,ABCNumericalOptimization}. More bees are lured towards a particular food source due to the high nectar amount that has been communicated to them by other employed bees\cite{ABCCompareStudy,ABCReconfigDistro,ABCNumericalOptimization}.

When a food source is abandoned, the previous bee that occupied the food source transitions to a scout bee \cite{ABCCompareStudy,ABCNumericalOptimization}. The scout bee is responsible for replacing the abandoned food source by finding a new one, and a new food source is generated and communicated back to the colony\cite{ABCCompareStudy,ABCImageEnhancement,ABCNumericalOptimization}. The generation of food sources is discussed in the next subsection.

Karaboga was not the first to base an algorithm on the above foraging behaviour. Other bee foraging inspired algorithms have been developed such as the BeeHive algorithm, \gls{BCO} and \gls{BSO} \cite{BCO,HybridABCClustering,ABCNumericalOptimization}. 

The BeeHive algorithm is based on the dance communication used inside the colony of bees. In \gls{BCO} solutions are randomly generated and assigned to bees\cite{HybridABCClustering,ABCNumericalOptimization}. Finally, \gls{BSO} solutions are iteratively constructed by forager (worker) bees and the best solution is communicated to the rest of the colony by performing a dance\cite{HybridABCClustering,ABCNumericalOptimization}.

Another bee algorithm is the \gls{VBA} which, like the previous algorithms, is also based on the foraging behaviour of bees, but it differs in that it is not designed for combinatorial problems \cite{ABCNumericalOptimization}. Instead the \gls{VBA} is a variant of the standard \gls{ABC} algorithm which is designed for numerical function optimisation \cite{ABCNumericalOptimization}. In \gls{VBA} bees move around in the search space communicating to each other any target nectar food sources that are found\cite{ABCNumericalOptimization}. Good food sources are function evaluations of particular coordinates in the numerical search space which produce low function evaluation values in the case of minimisation\cite{ABCNumericalOptimization}.

Karaboga developed the \gls{ABC} algorithm based on the previous research done on bee colony optimisation and the above algorithms. The \gls{ABC} algorithm is designed to be a multivariable optimisation algorithm and has to date been applied to the job scheduling problem, clustering \cite{HybridABCClustering}, neural network training and reconfiguration of distribution networks \cite{ABCReconfigDistro}. Due to the nature of the algorithm being similar to that of the \gls{ACO}, the \gls{ABC} algorithm will most likely also be applied to a whole host of other of problems.

\subsection{ABC Algorithm Characteristics}
Various characteristics of the \gls{ABC} algorithm define the algorithm and make it unique. The first characteristic is how food sources are handled in the algorithm. The second is how information is communicated to the colony.
\subsubsection{Food Sources}
\label{sec:foodsources}
As discussed previously, food sources represent solutions to the problem the \gls{ABC} algorithm is being applied to. When the algorithm starts, there are no defined food sources for the bees to evaluate and report on, and therefore initially a finite number of food sources are randomly generated\cite{ABCCompareStudy,ABCFusionGrid}. Since each food source needs an employed bee to evaluate the nectar amount of the source, the parameter that defines the number of food sources also defines the number of employed bees\cite{ABCCompareStudy,ABCLeafConstrained}.

Employed bees evaluate these food sources by determining their nectar amount\cite{ABCCompareStudy,ABCLeafConstrained}. The nectar amount is directly related to the fitness value calculated using a domain specific cost function\cite{ABCCompareStudy,ABCReconfigDistro}. After the amount is determined the employed bee advertises the food source to the colony by performing the waggle dance.

Onlooker bees witness a number of dances from a variety of employed bees\cite{ABCFusionGrid,BeeJobShop}. They therefore need to select a food source that is the most attractive while maintaining some diversity in the pool of solutions. Thus, an onlooker bee selects a food source based on a probability function which is formulated in equation \ref{eq:beeProbability}\cite{ABCCompareStudy}:
\begin{equation}
\label{eq:beeProbability}
p_i = \frac{{fit}_i}{\sum^{SN}_{n=1}{fit}_n}
\end{equation}

The parameter $p_i$ is the $i$th food source under consideration by the onlooker bee. The ${fit}_i$ parameter represents the value of the cost function and is directly related to the nectar amount of food source $i$. The parameter SN is the maximum amount of food source and hence the maximum employed onlooker bees \cite{ABCCompareStudy}.

In algorithm~\ref{alg:ABC} the waggle dance can be seen being applied in line 11 where the probability of all the employed bee' solutions are calculated using equation~\ref{eq:beeProbability}. From lines 12 -- 16 the onlooker bees evaluate the solutions of the employed bees based on the probability $p_i$ that was calculated. $P_i$ can be seen as the rating of the waggle dance that was performed by the employed bee.

\subsubsection{Employed and Onlooker Bees}
\label{sec:employonlookerbees}
As previously outlined, when recruited onlooker bees reach the advertised food source that is stored in memory, they do not occupy the same food source\cite{ABCCompareStudy,ABCNumericalOptimization}. Instead the bees explore the immediate neighbourhood of the food source that was communicated to them\cite{BeeJobShop,ABCFusionGrid,ABCReconfigDistro}. They seek to find a food source that improves on the previous one\cite{BeeJobShop,ABCNumericalOptimization}. Equation \ref{eq:beeGenerate} is used by the bees to generate new food sources in the neighbourhood of food source $x_i$\cite{ABCCompareStudy,ABCFusionGrid}.
\begin{equation}
\label{eq:beeGenerate}
v_{ij} = x_{ij} + \phi_{ij}(x_{ij} - x_{kj})
\end{equation}
The subscripts $k \in \{1,2,\dots,SN\}$ and $j \in \{1,2,\dots,D\}$ are indices which are randomly chosen. $D$ is the maximum dimensionality of the vector a solution represents. The index $k$ has a constraint tied to it -- whatever value is randomly assigned to $k$ \emph{must} differ from the value $i$. The position of the new food source in the neighbourhood of $x_{ij}$ is controlled by the $\phi_{ij}$ parameter, which is a bounded random value between $[-1,1]$. 

From equation \ref{eq:beeGenerate} it can be concluded that the randomness of the food source position decreases as the difference between $x_{ij} - x_{kj}$ decreases. Thus, as the algorithm moves closer to an optimal solution the finer grained the search process of the algorithm becomes\cite{ABCCompareStudy,ABCNumericalOptimization,ABCImageEnhancement}.

After a new solution $v_i$ is produced, the bee takes the new and old solutions from memory to compare their respective nectar contents. If the new solution is found to have higher quality nectar, the bee replaces the old solution in memory with the new solution\cite{ABCCompareStudy,ABCReconfigDistro}. Otherwise, the bee abandons the new solution and keeps the old solution in memory\cite{ABCCompareStudy,ABCNumericalOptimization}. Thus, the bee seeks to always move towards a better solution and therefore uses a greedy selection process\cite{ABCLeafConstrained,ABCReconfigDistro}.

One of the problems with the above approach is that little information about the food source is used in generating a neighbouring food source. In the research by Singh \cite{ABCLeafConstrained} a slight variation is proposed to generating food source neighbours by using more global information. The author adds a constraint to the algorithm that all neighbouring solutions generated by \emph{employed} bees must be unique. 

When an employed bee generates a neighbour and an identical solution already exists in the system, a \emph{collision} is said to have occurred. A collision is solved by letting the employed bee transition to a scout bee so that a completely random solution can be generated \cite{ABCLeafConstrained}. Scout and onlooker bee generated solutions are not checked if they collide with other solutions in the system since the aim for them is exploring and not exploiting as with employed bees\cite{BeeJobShop,ABCCompareStudy}. 
\subsubsection{Scout Bee}
The artificial bees are modelled on the behaviour of real bees. Thus an employed bee can also abandon certain food sources when it has outlived its usefulness. Abandonment of a food source can occur for the following reasons\cite{BeeJobShop,ABCNumericalOptimization,ABCImageEnhancement}:
\begin{itemize}
\item The employed bee has reached the maximum allowed cycles to improve the nectar amount. The maximum cycles spent on a food source allow the algorithm to avoid local optima\cite{ABCCompareStudy,ABCNumericalOptimization,ABCImageEnhancement}.
\item The bee cannot improve the search represented by the food source any further\cite{ABCCompareStudy,ABCNumericalOptimization,ABCImageEnhancement}.
\end{itemize}
When a food source in the algorithm is abandoned, it needs to be replaced by a new food source\cite{BeeJobShop,ABCCompareStudy,ABCImageEnhancement}. Note that a food source is not abandoned when it represents the globally best found solution. An employed bee transitions to a new role when it abandons a food source from an employed bee to a scout bee\cite{ABCCompareStudy,ABCNumericalOptimization,ABCImageEnhancement}. 

It is the responsibility of the scout bee to replace the abandoned food source with a new randomly generated one\cite{BeeJobShop,ABCCompareStudy,ABCImageEnhancement}. The scout bee uses equation \ref{eq:scoutGenerate} to produce a new food source that will replace food source $x_i$.
\begin{equation}
\label{eq:scoutGenerate}
x_{ij} = x_{yj} + rand[0,1](x_{zj} - x_{yj})
\end{equation}

The subscript $y$ represents the minimum value of $i$ and the subscript $y$ represents the maximum value of $i$.

In research done by G\'{o}mez-Iglesias et al. \cite{ABCFusionGrid} an extension is made to the scout bees. The scout bee individuals are divided into two types of bees, namely \emph{rovers} and \emph{cubs} bees\cite{ABCFusionGrid}.
\begin{itemize}
\item{Rover bees} are similar to traditional scout bees and hence use diversification strategies to explore the search space. 
\item {Cub bees} explore the search space relative to a good solution found by a rover by randomly changing configuration parameters. 
\end{itemize}
By using two different scout bees a good balance is achieved when searching the search space in the beginning where diversity is preferred and late in the algorithm where intensification is preferred \cite{ABCFusionGrid}.

In the next subsection the general flow of the \gls{ABC} algorithm is described, which will aid in the understanding of how the algorithm searches a particular problem space. 
\subsection{Flow of the Algorithm}
Most of the concepts that are used in the \gls{ABC} algorithm have been explained. The general search process of the algorithm will now be discussed using algorithm~\ref{alg:ABC} as a reference point.
\begin{algorithm}[H]
\caption{Basic Artificial Bee Colony Algorithm\cite{ABCCompareStudy}}
\label{alg:ABC}
	\begin{algorithmic}[1]
		\State$b_n \leftarrow \text{Initialize bees}$
		\State$s_n \leftarrow \text{Initialize starting solutions}$
		\State$\text{Evaluate starting solutions with fitness function $f(s_n)$}$
		\State$t \leftarrow 0$
		\While{stopping criteria not met}
			\For{each employed bee $eb_i = 0$ to max bees $b_n$}
				\State$\hat{v_i} \leftarrow \text{Generate new solution with equation~\ref{eq:beeGenerate}}$
				\State$\text{Evaluate with fitness function $f(\hat{v_i})$}$
				\State Apply greedy selection between $\hat{v_i}$ and the current solution $\hat{s_i}$ of bee $eb_i$
			\EndFor
			\algstore{ABC}
	\end{algorithmic}
\addtocounter{algorithm}{-1}
\end{algorithm}

\begin{algorithm}
	\caption{Basic Artificial Bee Colony Algorithm (continued)}
	\label{alg:ABC1}
	\begin{algorithmic}[1]
		\algrestore{ABC}
    \State$\text{Calculate probability $p_i$ for solutions $\hat{s_i}$ in $\hat{s_n}$ using equation~\ref{eq:beeProbability}}$
			\For{each onlooker bee $ob_i \leftarrow 0$ to max bees $b_n$}
				\State$\hat{x_i} \leftarrow \text{Select solution $\hat{s_i}$ based on $p_i$} $
				\State$\hat{v_i} \leftarrow \text{Generate new solution with $\hat{x_i}$ and $p_i$}$
				\State$\text{Evaluate $\hat{v_i}$ with fitness function $f(\hat{v_i})$}$
				\State$\text{Apply greedy selection between $\hat{v_i}$ and bee $ob_i$ current solution}$
			\EndFor
			\If{there is an abandoned solution for a scout bee}
				\State Replace with solution generated with equation~\ref{eq:scoutGenerate}
			\EndIf
			\State$t \leftarrow t + 1$
		\EndWhile
	\end{algorithmic}
\end{algorithm}
The algorithm starts off by generating a set number of possible solutions. The number of solutions is equal to the number of employed bees. Each starting solution is evaluated using a fitness function. The operations that peform these functions can be observed to occur from lines 1 -- 3.

At first each bee is assigned to one of the initial generated solutions (food sources). Hence the bees start off as employed bees and each bee has in its memory a particular possible solution with an associated nectar amount. The algorithm can now be considered to be initialised, and therefore the algorithm enters the next phase, which is where the actual optimisation and search procedure occurs. This phase stretches from lines 5 -- 22.

From lines 6 -- 10, each employed bee modifies its particular solution based on local information, which is also referred to as visual information in the literature. The modified solution is then tested to determine its nectar amount, i.e. the fitness of the generated solution is calculated. The employed bee then compares the newly generated nectar amount with the nectar amount of the search in the bee's memory. If the newly generated solution has a better nectar amount, the bee replaces the current solution in its memory with the newly generated solution.

After all the employed bees have determined whether to keep the newly generated solution or keep the one in memory, they then need to communicate to the rest of the bee hive the nectar amount of the food sources that they occupy. This phase is where the waggle dance occurs and can be observed in algorithm~\ref{alg:ABC} from lines 12 -- 17.

Each onlooker bee then selects which food source it will move towards based on a probability. The probability takes into account the nectar amount that was communicated through the waggle dance by a particular employed bee. The probability is calculated using equation~\ref{eq:beeProbability} which is discussed in section~\ref{sec:foodsources}.

Once an onlooker bee has selected a food source based on the calculated probability, it then starts to search the immediate neighbourhood of the selected food source for other food sources. The neighbouring food sources are generated using equation~\ref{eq:beeGenerate} which is discussed in section~\ref{sec:employonlookerbees}. This procedure of generating neighbouring food sources by an onlooker bee can be observed in line 14 in algorithm~\ref{alg:ABC}.

The onlooker bee then applies the same procedure as an employed bee with regard to determining if the newly generated food source should be remembered or discarded. The bee does this by evaluating each generated neighbouring food source to determine its nectar amount, which is then compared to the nectar amount of the food source in the bee's memory.

In the last phase of the algorithm (before the next iteration starts) the algorithm determines which food sources have been abandoned by the bees. A food source in the algorithm can be abandoned if, for a certain number of iterations the food source has not improved, meaning its nectar content has not increased. When a food source is abandoned the employed bee that occupied the particular food source transitions to a scout bee.

A scout bee aims to replace the abandoned food source with a new food source. In algorithm~\ref{alg:ABC} this occurs in lines 18 -- 22. The scout bee uses equation~\ref{eq:scoutGenerate} to generate a new food source. It then transitions to an employed bee and occupies the newly generated solution. The newly generated food source will now also be evaluated to determine its nectar amount as the rest of the employed bees do at the start of the next iteration.


\subsection{ABC algorithm on the \gls{FAP}}
The \gls{ABC} algorithm and all its variants are relatively new. To date it has only been applied to a select few problems such as the traveling salesman problem.

As yet, no research has been done to apply the \gls{ABC} algorithm to the \gls{FAP}. The following critique is based on a theoretic implementation of the \gls{ABC} algorithm on the \gls{FAP}. Based on this evaluation the following obstacles can be identified if one were to apply the algorithm to the \gls{FAP}:
\paragraph{Food source representation}
--- Each food source can either represent a frequency plan or it can be a particular cell and a collective of food sources represents a frequency plan. If each food source is a frequency plan the algorithm will require a fair amount of memory, since as onlooker bees select it, they will start searching for neighbouring solutions. These neighbouring solutions are \emph{also} frequency plans. However, if each food source is a cell, this would require less memory. The problem with the latter approach is that the bees would then single out one cell as the optimum, since they do not know that all food sources collectively represent a plan and each cell is actually unique.
\paragraph{Scout bee generation}
--- When a food source is abandoned a scout bee needs to generate a new food source to take its place. In particular with the \gls{FAP}, the newly generated solution cannot be completely random. The scout bee needs to incorporate knowledge already gained by the colony operating on different food sources, otherwise a completely random solution might not be even nearly lucrative enough for the rest of the bee colony to consider if it contains no knowledge gained by the algorithm.
\paragraph{Knowledge sharing}
--- As a food source becomes more popular due to its high nectar amount, more onlooker bees will select it. By selecting the food source the onlooker be will then proceed to search in its neighbourhood for better solutions. Therefore the bees are disregarding previously gained knowledge while searching for neighbouring sources on \emph{other} food sources. If a food source represents a complete frequency plan, a previous food source a bee operated on might have had one or more cells that were assigned to their optimal frequencies. Due to the larger majority of the cells not being optimised, these \emph{good} cells are overshadowed. Thus due to the \emph{bad} cells overshadowing the good cells, the food source nectar amount becomes lower. As a consequence of the low nectar amount by the food source the bees abandon the food source and those optimal cells are lost.

The above obstacles present real relevant challenges that would require new techniques to be developed. As the algorithm has not been applied to a wide variety of problems and taking into account the above obstacles, it is difficult to gauge if the \gls{ABC} is well suited to be applied. The algorithm first needs to be applied to a wider set of problems. Once the algorithm has matured in the research behind it the algorithm can be revisited and applied to the \gls{FAP}.

In this section the various obstacles one would encounter when applying the \gls{ABC} class of algorithms to the \gls{FAP} were identified. This concludes the discussion on the \gls{ABC} algorithm. The next section deals with the particle swarm optimisation algorithm.
\section{Particle Swarm Optimisation (PSO)}

\label{sec:PSO}
\subsection{Introduction}
\label{sec:psointro}
PSO is population-based stochastic search technique that was developed by Kennedy and Ebenhart in 1995 \cite{PSOGABreeding}. The basic model of the algorithm is based on simulations done to recreate the natural behaviour of a flock of birds \cite{PSOSoftTesting}.

In the early stages of the particle swarm development, simulations were developed to closely model the stigmergy (see page \pageref{sec:stigmergy} for a discussion on stigmergy) exhibited when a flock of birds cohesively move as one and are able to suddenly change direction in a unpredictable, graceful manner, only to regroup as one observed entity \cite{PSOHybridJobShop}. 

As the ``leading'' bird of the flock changes its movements the information is shared with all birds in the immediate vicinity of the leading bird. As the information is shared locally among birds, each bird modifies his own movement to that of the leading bird's movement\cite{PSOHybridJobShop}. 

Because birds obtain information by observing their neighbouring birds, the stigmergy can be deemed to be of a physical nature; therefore the particular stigmergy used by birds is sematectonic stigmergy (see page \pageref{def:sematectonic}).

The simulations based on this behaviour of the flock allowed researchers to discover the underlying patterns that governed the way birds are able to share information about the general movement of the flock. Based on these patterns and simulations, the particle swarm algorithm emerged into an optimisation algorithm \cite{CompuIntelligenceIntro}.

In the algorithm a particle is an individual\cite{FundamentalSwarm}. A group of particles, referred to in the literature as a swarm,  are moved through the search space of the problem the algorithm is being applied to\cite{FundamentalSwarm}. Each particle changes its movement based on information shared with it by neighbouring particles in the swarm \cite{FundamentalSwarm,CompuIntelligenceIntro}. 

As information is shared among particles, the success of one particle ripples through the rest of the swarm and each particle is able to utilise shared information that leads to success of another particle. Thus, each particle's own personal experience and knowledge of the search space has an effect on its neighbouring particles \cite{FundamentalSwarm,CompuIntelligenceIntro}.

Two variants of the initial \gls{PSO} algorithm were developed namely the global \gls{PSO} and local \gls{PSO}. The only difference between the two algorithms is how they go about sharing information with the rest of the swarm. The sharing models of these two algorithms along with other sharing models are discussed in the \gls{PSO} characteristics subsection \cite{SOSwarm}.

In the swarm, each particle is a potential solution that is represented by a D-dimensional vector \cite{PSOHybridJobShop,PSOSelfHierarch}. As a particle moves through the search space, it continually evaluates its current position and adjusts it accordingly to move in the general direction of its own personal best position and the position of the best particle in its neighbourhood. 

A particle evaluates its current position by using a heuristic function, or in more evolutionary algorithm terms, a fitness function. The fitness value indicates to the particle how far it is from an optimal position\cite{CompuIntelligenceIntro}. 

As a particle moves through the search space it keeps a memory of the personal best position it has achieved since the start of the algorithm. In the literature and in the algorithm this personal best position is referred to as \emph{pbest} \cite{SOSwarm}.

Most of the research done on \gls{PSO} has focused on the convergence of the algorithm as well as improving the diversity \cite{FundamentalSwarm}. Some of these improvements and modifications is discussed in the subsection on \gls{PSO} characteristics.

\subsection{PSO Characteristics}
\label{sec:psocharacteristics}
The defining characteristics of the \gls{PSO} algorithm that are discussed in this section include \emph{neighbourhood topology}, \emph{the partcle swarm}, \emph{movement of particles} and \emph{keeping particle velocities in check}.
\subsubsection{The Particle Swarm}
The initialising of particles in a swarm are the same as used by traditional population-based evolutionary algorithm to initialise their respective populations \cite{FixedFAPPSO}.  At the start of the algorithm the swarm is initialised by randomly generating possible solutions that will represent the position of particles\cite{CompuIntelligenceIntro}. 

The \gls{PSO} algorithm in some aspects resembles evolutionary algorithms like the genetic algorithm since it also has a population that operates in the problem space in search of an optimal solution. However unlike some of the variants that exist for the \gls{GA} utilise good mutation operators are able have new genetic material to be inserted into the population. At least in the initial search phase of the GA, this increases diversity\cite{CompuIntelligenceIntro}. The \gls{PSO} does not continually generate new solutions to be reinserted into the swarm to increase diversity \cite{PSOHybridUnitCommit}. Thus the swarm size needs to be adjusted to get an optimal representation of the search space because as particles move in the swarm, the diversity among particles decreases rapidly as information is shared \cite{FundamentalSwarm,CompuIntelligenceIntro}. 

The diversity of the swarm is not only dependant on the sharing model used but also on the parameters used for velocity updatign of partciles. Most important of these parameters are the inertia weight and accelaration coefficients. Depending on the values used the diversity of the swarm decreases as the swarm moves because, with each iteration, the swarm converges towards the neighbourhood best position\cite{PSOHybridJobShop,CompuIntelligenceIntro,FundamentalSwarm}. This occurs due to the velocity equation directs the general movement of a particle in the direction of the neighbourhood best\cite{PSOHybridJobShop,CompuIntelligenceIntro,FundamentalSwarm}. If the best position in the neighbourhood does not change as the algorithm processes more iterations, a larger portion of the swarm will soon occupy a position which is a weighted average between the neighbourhood and each individual particles personal best\cite{PSOHybridJobShop,CompuIntelligenceIntro,FundamentalSwarm}. On the other hand, if the wrong values are used, the diversity of the swarm will increase, but there is also the possibility that the swarm will diverge never to converge to a single solution but having increased diversity\cite{FundamentalSwarm}.

Diversity among the particles in the swarm is important and at least initially must be maintained for the search space to be explored adequeately. As discussed previously, depending on the neighbourhood topolgy used diversity can be increased. In the next section neighbourhood topolgies is discussed.
\subsubsection{Neighbourhood topolgies}
The neighbourhood topology (also called social structure) used by a \gls{PSO} algorithm dictates how information is shared among the particles of the swarm. According to Engelbrecht\cite{FundamentalSwarm} there are 6 neighbourhood topologies. Each topology will now be listed and a short description will also be given.
\begin{description}
\item{\textbf{star}} --- With the star topology all particles within a swarm are interconnected with each other. Any one particle can communicate with any other particle in the swarm\cite{FundamentalSwarm}. Using this topology each particle is attracted towards the best solution found globally by the swarm\cite{FundamentalSwarm}. 
\item{\textbf{ring}} --- Using the ring topology each particle communicates with its immediate adjacent neighbour\cite{FundamentalSwarm}. Each particle aims to mimic the best solution found within its neighbourhood\cite{FundamentalSwarm}. Neighbourhoods are allowed to overlap in the ring topology\cite{FundamentalSwarm}. Overlapping allows for information sharing among neighbourhoods and facilitates the swarm in converging to a single solution\cite{FundamentalSwarm}. 
\item{\textbf{wheel}} --- In the wheel topology there is a central particle with which all other particles in the swarm are connected to\cite{FundamentalSwarm}. The other particles are isolated and can only share information with the central particle\cite{FundamentalSwarm}. The central particle utilises information about all the particles in its neighbourhood and adjusts its own best position accordingly\cite{FundamentalSwarm}. Depending on whether the new best position represents a better solution than previously, the central particle shares the information to its neighbours\cite{FundamentalSwarm}. A consequence of the limited sharing that occurs in the wheel topology is that the propagation of good solutions through the swarm is slowed\cite{FundamentalSwarm}.
\item{\textbf{pyramid}} --- The pyramid topology interconnects particles so that their connected structure resembles a three-dimensional pyramid\cite{FundamentalSwarm}.
\item{\textbf{four clusters}} --- With this topology four clusters are formed. Each cluster containing interconnected particles\cite{FundamentalSwarm}. Between each cluster there exists only two connections to other clusters\cite{FundamentalSwarm}.
\item{\textbf{von Neumon}} --- Using this topology all particles are connected in a structure that resembles a grid\cite{FundamentalSwarm}. This structure has been shown to enable the swarm to produce better results than other neighbourhood topologies\cite{FundamentalSwarm}
\end{description}

Based on the neighbourhood topologies defined above the global \gls{PSO} uses a star neighbourhood to allow for information to be shared all particles in the swarm. The particle whose position in the search space indicates the best solution found by the swarm is denoted as \emph{gbest}\cite{SOSwarm, FundamentalSwarm, CompuIntelligenceIntro}. 

In contrast, the local \gls{PSO} follows the process of natural birds more closely and uses the ring neighbourhood for information sharing\cite{SOSwarm, FundamentalSwarm, CompuIntelligenceIntro}. Hence, particles only share information with their immediate neighbourhood and not with the whole swarm. The best particle in the local \gls{PSO} is denoted as \emph{lbest}\cite{SOSwarm, FundamentalSwarm, CompuIntelligenceIntro}.

\subsubsection{Movement of particles}
\label{sec:particleVelocity}
A particle moves with a certain velocity through the search space. As the information is shared the particle must take advantage of the newly gained knowledge and therefore needs to adjust its own velocity to match the movement of the swarm. The particle updates its own velocity to move in the direction of the \emph{gbest} shared position, its own \emph{pbest} position and its current heading.

A particle needs to systematically explore the search space; therefore when the particle needs to update its personal velocity, it does not use all the information it has available, otherwise it will start to cycle solutions. The particle uses a certain amount of global information together with a certain amount of local information to produce a direction and new velocity\cite{FundamentalSwarm,CompuIntelligenceIntro,PSOSelfHierarch,SOSwarm}. 

The amount of global knowledge is referred to as the \emph{social} \label{def:socialcomponent} component \cite{FundamentalSwarm,CompuIntelligenceIntro,PSOSelfHierarch,SOSwarm}. The amount of personal information used by a particle is referred to as the \emph{cognitive} \label{def:cognitivecomponent} component\cite{FundamentalSwarm,CompuIntelligenceIntro,PSOSelfHierarch,SOSwarm}.

The velocity calculation of each particle is where the optimisation procedure occurs in the \gls{PSO} algorithm. It is the only means by which the \gls{PSO} algorithm searches the search space and particles are moved\cite{CompuIntelligenceIntro}.

The velocity update is where the personal experience of a particle and the knowledge gained through social sharing are incorporated. By updating the velocity of a particle, the particle is steered into a more promosing direction. The velocity of a particle is updated based upon on equation~\ref{eq:velocityupdate}.
\begin{align}
\hat{v}_i(t+1) &= \hat{v}_i(t) + c_1\hat{\phi}_1(t)[\hat{pbest}_i - \hat{x}_i(t)] + c_2\hat{\phi}_2(t)[\hat{gbest}_i - \hat{x}_i(t)]\label{eq:velocityupdate}\\
\hat{x}_i(t+1) &= \hat{x}_i(t) + \hat{v}_i(t+1)\label{eq:positionupdate}
\end{align}
where $\hat{v}_i(t+1)$ is the new velocity of particle $i$ for the next time step $t+1$. The cognitive component is represented by the term $c_1\hat{\phi}_1(t)[\hat{pbest}_i - \hat{x}_i(t)]$ where $c_1$ is the cognitive coefficient. The social component is represented by the term $c_2\hat{\phi}_2(t)[\hat{gbest}_i - \hat{x}_i(t)]$ where $c_2$ is the social coefficient (discussed on page \pageref{def:cognitivecomponent})\cite{FundamentalSwarm,CompuIntelligenceIntro}. Each of the respective components $c_1$ and $c_2$ controls how much neighborhood information is used in the calculation of the new velocity. 

The variables $\hat{\phi}_i$ and $\hat{\phi}_2$ are vectors containing random scalar values in the range $[0,1]$. The current position of a particle in the search space at time step $t$ is represented by parameter $\hat{x}_i(t)$\cite{FundamentalSwarm,CompuIntelligenceIntro}. After the new velocity is calculated the position of the particle is updated for time step $t+1$ using equation \ref{eq:positionupdate} \cite{FundamentalSwarm,CompuIntelligenceIntro}. The velocity update can be visually depicted as shown in figure \ref{fig:particleVelocityUpdate}. 
\begin{figure}[H]
	\begin{center}
	\fbox{\includegraphics[width=4.5in,height=2.5in]{./pictures/geovelocity.pdf}}
	\caption{Visual particle velocity update \cite{SOSwarm,FundamentalSwarm,CompuIntelligenceIntro,PSOSelfHierarch}}
	\label{fig:particleVelocityUpdate}
	\end{center}
\end{figure}

As discussed earlier gbest is the best position the swarm has occupied since the start of the algorithm. In the literature there are two defined methods of determining gbest. The most common method used is where gbest is the best position obtained by a particle in the swarm since the start of the algorithm; thus long-term knowledge dictates the best position found which favours exploitation \cite{CompuIntelligenceIntro,FundamentalSwarm}.

The second method of determining the gbest is the best particle position occupied by any particle in the swarm, in the \emph{current} iteration of the algorithm; thus short-term knowledge dictates the best position found which favours exploration \cite{CompuIntelligenceIntro,FundamentalSwarm}.

Most of the literature has concentrated on the velocity of the particle because it is the main function performing the optimisation. In research done by Ratnaweera et al.\cite{PSOSelfHierarch} particle positions in the solutions space are continually monitored. If the particle appears to be stagnant in the search space, the velocity is first updated, and then the particle is reinitialised with a random position. The new position of the particle is then updated with the new velocity, thus knowledge of the discarded particle is retained by using the velocity it had\cite{PSOSelfHierarch}.

In research done by Kalivarapu et al. \cite{PSOPheromones} a \gls{PSO} algorithm is developed that seeks to incorporate the pheromone notion of \gls{ACO} algorithms into the velocity updating of particles. The premise of the method is to allow greater sharing of information about promising areas between particles. The algorithm developed by the authors achieved promising results, with it finding solutions faster and also better solutions than other \gls{PSO} algorithms \cite{PSOPheromones}. 

Other research done by Monson and Seppi \cite{adaptPSO} is more concerned with how the particle is presented. In the general \gls{PSO} algorithm, particles have no physical form or volume and so particles in the swarm move through each other. The authors changed this in their algorithm by letting each particle have a radius around itself. This means that as particles move through the search space and another particle at a certain time step occupies the same space, the particles are said to collide. As one would expect, when a collision occurs both particles are deflected into random directions \cite{adaptPSO}. At a greater expense of computational time due to constant collision detection, the \gls{PSO} gains greater exploration in the search space. 

Finally, in the research by Lenin and Monan a \gls{PSO} algorithm is developed that is called the \gls{ARPSO}. The algorithm continually monitors the solutions in the swarm. If it picks up that a certain percentage of the swarm is stagnating, it activates the repulse state. In the repulse state particles are repelled from other particles in the swarm, which facilitates greater exploration. After a certain number of iterations, the algorithm returns to its default state, where particles attract each other. The state of attraction facilitates exploitation \cite{PSOAttractRepulse}.
\subsubsection{Keeping velocity in check}
As can be observed in equation \ref{eq:velocityupdate} the new velocity is added to the old velocity. The velocity of particles can get very large, especially for those particles that are far from the pbest and gbest positions. Large velocities are necessary for early exploration. 

Velocities should be kept in check since if a particles velocity becomes too large, it can overstep the search spaces boundaries and produce infeasible solutions \cite{FundamentalSwarm}. Thus the velocity of a particle needs to be bounded to ensure that its movement with in the search space stays within acceptable bounds. One of the means to bound the velocity is to clamp it. Clamping of velocity is achieved by applying equation \ref{eq:velocityclamp}. The equation is applied on the velocity before its position is updated\cite{FundamentalSwarm}.
\begin{align}
	\hat{v_i}(t+1) &=
	\begin{cases}
	\hat{v'_i}(t+1), &\text{if $\hat{v'_i}(t+1) < \hat{V_{max}}$}\\
	\hat{V_{max}}, &\text{if $\hat{v'_i}(t+1) \geq \hat{V_{max}}$}
	\end{cases} \label{eq:velocityclamp}\\
	\hat{V_{max}} &= \delta(\hat{x_{max}} - \hat{x_{min}})
\end{align}
In equation~\ref{eq:velocityclamp} $\hat{v'_i}$ is calculated using equation~\ref{eq:velocityupdate} for the global \gls{PSO}. Where $\hat{V_{max}}$ is the maximum allowed velocity and $\delta \in (0,1]$. The values $\hat{x_{max}}$ and $\hat{x_{min}}$ are the respective maximum and minimum position vectors in the domain the algorithm is being applied to \cite{FundamentalSwarm}. The value of $\delta$ is very problem dependent and must be carefully chosen to maximise the exploration-exploitation trade-off \cite{FundamentalSwarm}. The use of velocity clamping is not mandatory and should be considered only if the problem requires it\cite{FundamentalSwarm}. Finally there is no guarantee that velocity clamping will prohibit velocities becoming too large\cite{FundamentalSwarm}. There is still a chance, just to a lesser extent\cite{FundamentalSwarm}.

Velocity clamping is not the only developed means by which  the exploration-exploitation trade-off of the \gls{PSO} can be controlled. Consider the case when an object moves with a certain velocity it carries momentum. If the object were to suddenly change direction, momentum would for a certain period still move the object in the previous direction. Inertia weight seeks to add this type of behaviour to the particles of the \gls{PSO} algorithm. The velocity update equation with added inertia is formulated in equation \ref{eq:inertia} \cite{FundamentalSwarm}.
\begin{equation}
\hat{v_i}(t+1) = w\hat{v_i}(t) + c_1\hat{\phi}_1(t)[\hat{pbest}_i - \hat{x}_i(t)] + c_2\hat{\phi}_2(t)[\hat{gbest}_i - \hat{x}_i(t)]\label{eq:inertia}
\end{equation}
Inertia ($w$ in equation \ref{eq:inertia}) was added to the general velocity update equation in an attempt to control the exploration and exploitation of the \gls{PSO} as well as eliminate the need for velocity clamping\cite{FundamentalSwarm}. Although the inertia component did succeeded in enabling the control of the \gls{PSO}'s exploration-exploitation in the search space, the need for velocity clamping could not be eliminated\cite{FundamentalSwarm}.

For values of $w > 1$ , the inertia of the particle is increased. With increased inertia the particle will explore more but it also more likely to leave the boundaries of the search space leading to infeasible solutions \cite{FundamentalSwarm}. 

When $w < 1$ and depending on the values of $c_1$ and $c_2$ each time a particles velocity is updated a certain amount of momentum is lost. The particle seems to slow down, allowing it to exploit the current solution space in finer detail \cite{FundamentalSwarm}. This is not always the case, as $w < 1$ can also lead to the particles in the swarm diverging never to converge on an optimal solution.

To allow for a greater trade-off between exploration and exploitation, the inertia value can be made dynamic. Exploration is favoured early on in an optimisation algorithm and  exploitation later on the algorithm when it is near an optimum. Various methods that are either linear decreasing or non-linear decreasing have been developed that modify the inertia component as the algorithm moves around in the search space \cite{CompuIntelligenceIntro,FundamentalSwarm}.

Finally, a similar inertia type component was developed from the analysis of particle dynamics \cite{FundamentalSwarm}. This new component is called the \emph{constriction coefficient} and, like the inertia above, also modifies the velocity update equation slightly\cite{adaptPSO,FundamentalSwarm,CompuIntelligenceIntro}. 

This modification can be observed in equation \ref{eq:velocityconstriction}, which is the standard velocity equation with the constriction coefficient. The constriction coefficient is formulated in equation \ref{eq:constriction}\cite{adaptPSO,FundamentalSwarm,CompuIntelligenceIntro}.
\begin{align}
v_i(t+1) &= \chi[v_i(t) + c_1\phi_{1}(t)[pbest - x_i(t)] + c_2\phi_{2}(t)[gbest - x_i(t)]]\label{eq:velocityconstriction}\\
\chi &= \frac{2\kappa}{\lvert 2 - \phi - \sqrt{\phi^2 - 4\phi}\rvert}\label{eq:constriction}
\end{align}

search constriction coefficient is represented by the value $phi$. The constriction coefficient evaluates to an ever-decreasing value between $[0,1]$. By using the constriction coefficient the \gls{PSO} algorithm is also guaranteed to converge for values of $phi \geq 4$ and $\kappa \in [0,1]$. As with the inertia discussed above, high values of $\kappa$ allow for greater exploration and slow convergence, whereas low values of $\kappa$ force the algorithm to exploit the search space and converge quickly \cite{adaptPSO,FundamentalSwarm,CompuIntelligenceIntro}.

\subsection{Flow of the Algorithm}
The general concepts that are evident in the \gls{PSO} algorithm have been covered. Using these concepts a general overview will now be given of the \gls{PSO} algorithm flow using algorithm~\ref{alg:PSO} as a reference point. Note that for the algorithm presented a start neighourhood topology is used and the algorithm is applied on a minimisation problem.
\begin{algorithm}[H]
\caption{Basic Global Particle Swarm Optimisation Algorithm\cite{CompuIntelligenceIntro}}
\label{alg:PSO}
	\begin{algorithmic}[1]
		\State Initialize $s_n$ swarm
		\While{Stopping condition not met}
			\For{each particle $\hat{p_i} \leftarrow 0$ in $s_n$}
				\State Evaluate particle with fitness function $f(\hat{p_i})$
				\If{$f(\hat{p_i}) \leq pbest(\hat{p_i})$}
					\State personal best of $\hat{p_i}$ to $f(\hat{p_i})$
				\EndIf
				\If{$f(\hat{p_i}) \leq f(\hat{gbest)}$}
					\}State $\hat{gbest} \leftarrow f(\hat{p_i})$
				\EndIf
			\EndFor
			\For{each particle $\hat{p_i} \leftarrow 0$ in $s_n$}
				\State update velocity of $\hat{p_i}$ with equation~\ref{eq:velocityupdate}
				\State update position of $\hat{p_i}$ with equation~\ref{eq:positionupdate}
			\EndFor
		\EndWhile
	\end{algorithmic}
\end{algorithm}

The \gls{PSO} algorithm starts off by initialising the swarm of particles. Each particle is randomly assigned a certain position in the problem space. After the swarm has been initialised the algorithm enters the optimization or search phase, which starts in line 2.

Before the swarm can start moving around in the problem space, it first needs to determine the gbest particle as well as each particle's own pbest position. Therefore as can be observed in line 3, each particle's current fitness $f(\hat{p_i})$ is determined using a problem-specific fitness function. The fitness determines the lucrativeness of the current position a particle occupies in the problem space.

Once the fitness of a particle's position is calculated, the algorithm needs to determine whether the current position of the particle is its pbest since the algorithm started. This comparison can be seen occur in line 5. 

If the fitness of the currently held position is indeed better than the previous personal best of the particle, then the new position is remembered as the personal best for that particular particle, as can be observed in line 6.

Regardless of whether the personal best of a particle has been updated or not, the algorithm performs another comparison also utilising the calculated fitness of the current position of the particle. The algorithm uses this fitness to also determine whether the current position of the particle is the best in the \emph{entire} swarm, i.e. whether it is  the \emph{global} best (gbest). This comparison occurs in line  8.

If the position of the particle is indeed the best position in the entire swarm, the algorithm replaces the current gbest with the position of the current particle being evaluated, as seen in line 9.

After the swarm has been evaluated, each particle should have a personal best and the swarm should have a global best. The swarm is therefore ready to move around in the problem space, which occurs in algorithm~\ref{alg:PSO} from lines 12 -- 15.

For each particle in the swarm the algorithm determines the particle's new velocity, as can be observed in line 13. The velocity of a particle is calculated using equation~\ref{eq:velocityupdate}. 

Once the velocity of a specific particle has been calculated, the particle is ready to move to a new position. Moving a particle from its current position to a new position using the calculated velocity is done by applying equation~\ref{alg:PSO} and occurs in line 14 in algorithm~\ref{alg:PSO}.

After the whole swarm has been moved, the algorithm continues to the next iteration to evaluate the new positions. This process occurs until certain stopping criteria are met.


\subsection{PSO on the \gls{FAP}}
\label{sec:psoonfap}
The \gls{PSO} algorithm is also a relatively new algorithm and has been applied to only a handful of NP-Complete problems, including the \gls{FAP}. In this dissertation the \gls{PSO} algorithm will be utilized on the \gls{FS-FAP} to try and produce optimal solutions. 

Only two groups have conducted research where the \gls{PSO} has been applied to the \gls{FAP} to produce a near optimal solution. The research concentrated on the \gls{MS-FAP} variant of the \gls{FAP}, and so the aim of their algorithm was to reduce the span of frequencies used. The problem this dissertation is concerned with is the \gls{FS-FAP} where the amount of interference generated needs to be minimised. 

To date, no \gls{PSO} algorithm has been designed to operate on the \gls{FS-FAP} variant. Therefore, the interest in the research mentioned above is more to do with how the authors went about encoding a particular frequency plan as a position for a particle, than with the actual optimisation procedure.

In the research presented by Elkamchouchi et al.\cite{EgyptFAPPSO} a \gls{PSO} algorithm is applied to produce optimal solutions for the \gls{MS-FAP}. The way the authors went about assigning frequencies in their algorithm is known as \gls{FEA}.
This method works by first generating a list of calls, called a \emph{call list}, denoting calls that occur in the system\cite{EgyptFAPPSO}. 

The \gls{FEA} method then iterates over the calls in the list and assigns the lowest possible frequencies to the calls without violating interference constraints\cite{EgyptFAPPSO}. The authors note that the specific frequency that is assigned to a particular call depends heavily on the order the calls are in the list\cite{EgyptFAPPSO}.

Because of the success of the \gls{PSO} on the \gls{MS-FAP}, for this dissertation the \gls{PSO} algorithm was selected as the primary means by which to address the \gls{FAP}.

The algorithm also makes extensive use of knowledge gained by the various particles as they search the problem space. Depending on the values used for $w, c_1$ and $c_2$, a particle does not only keep personal history (with pbest), but the swarm as a whole keeps a history of the best particle (neighbourhood best). Thus with regard to \gls{FAP}, it is possible that even though a particle might be in an overall bad position, it might have some small bit of good knowledge being overshadowed by bad knowledge. Through the extensive use of historical knowledge good information is more likely to be shared or kept slightly longer in the algorithms collective knowledge.

For this research the \gls{PSO} was applied to the \gls{FS-FAP} on the \gls{COST} 259 benchmark problems. The approach by the authors in the above literature could not be used. \gls{FS-FAP} is concerned with interference generated and there are some constraints which cannot be broken which are mentioned in section~\ref{sec:COST259} page~\pageref{sec:COST259}. In contrast with \gls{MS-FAP}, the performance measure is explicitly the number of constraints violated not interference.

\section{Summary}
\label{sec:SISummary}
In this chapter three swarm intelligence algorithms were discussed. The general flow of the ant colony optimisation algorithm was described with the help of a pesudo code as well as how the algorithm came about. The defining characteristics of the algorithm were identified and a literature review was given of the \gls{ACO} being applied to the \gls{FAP}.

The second swarm intelligence algorithm was the artificial bee colony optimization algorithm. How the algorithm was developed and how it performs its search in a problem space were explained. A diagram also outlined the general flow of the \gls{ABC} algorithm.

A series of defining characteristics was explained. Each characteristic is a defining attribute of the algorithm that makes it unique with regard to other algorithms. No literature is available on the algorithm being applied to the \gls{FAP} since to date no research has been conducted on such an \gls{ABC} algorithm.

This chapter concluded with the most important algorithm, which is used in this dissertation on the \gls{FAP}, namely the particle swarm optimization algorithm. The flow of the \gls{PSO} algorithm was described in algorithm~\ref{alg:PSO}. Furthermore, characteristics that make the algorithm unique were explained, and a literature review was given of the \gls{PSO} algorithm being applied to the \gls{FAP}.
%%% TEXEXPAND: END FILE ./chpt5.tex
\part{Discussion and results of implementing a PSO algorithm on the FAP}
%\include{chpt6}%PSO on benchmark functions
%%% TEXEXPAND: INCLUDED FILE MARKER ./chpt7.tex
\chapter{Applying the \gls{PSO} to the \gls{FAP}}
\label{chpt:psoapplicationFAP}
\section{Introduction}
PSO, as discussed previously (see page \pageref{sec:PSO}), is an algorithm that is largely based on the flying behaviour exhibited by a flock of birds. This is why the core of the algorithm is based upon vector mathematics, with new positions and velocities being calculated after each iteration of the algorithm. Thus a D-dimensional vector represents each particle position and is then simulated by flying through the D-dimensional space using the velocity equation (see section~\ref{sec:particleVelocity} on page~\pageref{eq:velocityupdate}).

Most of the problems to which \gls{PSO} has been applied to date have been problems where the position of particles has a constant D-dimensional space. In formal terms, therefore, \emph{the dimensionality of a particle position in its entirety is constant}. Therefore, each particle has a position which is defined in a set dimension like 2D where a position is represented at $x$ and $y$ coordinate pairs.

This constant dimensionality introduces an intriguing problem if one wants to apply the \gls{PSO} to an inherent multidimension problem like the \gls{FAP}. This chapter deals with how the \gls{PSO} was applied to the \gls{FAP}.

Firstly, the particle position is represented in the frequency planning domain is defined. This definition of the particle position is important because it plays a central part in
the movement of particles through the Frequency planning domain. A description is then given of how each position is evaluated as well as the fitness function that the \gls{PSO} will use in the \gls{FAP} domain.

Arguably the most important part of the swarm is how the velocity of a particle is calculated and then moving it to a new position in the problem space. The velocity update is important, as it is the primary means by which the algorithm searches problem space.

As was discussed in section~\ref{sec:psoonfap}, applying the \gls{PSO} to the \gls{FAP} introduces a variety of challenges. One of the challenges is how exactly one ``flies'' a frequency plan towards another frequency plan. This is an important question that needs to be addressed as the \gls{PSO} algorithms have no other way of searching the problem space by any other means.

To be able to allow the \gls{PSO} to operate in the \gls{FAP} space custom velocity functions had to be developed to enable the particles of the swarm to move. These velocity functions that were developed will expanded on in section~\ref{sec:velocityFAP}. 

Developing custom velocity functions for the \gls{PSO} was simply not enough to achieve good results with the \gls{PSO} . Therefore more innovations needed to be made to improve the solution quality of the \gls{PSO} . In section~\ref{sec:buildglobalbest} a new mechanism is presented for selecting the global best which enabled the \gls{PSO} to get better fitness values and therefore direct the swarm more towards better solutions. 

Finally, the chapter will conclude with how the swarm utilises history to produce better results to enable the \gls{PSO} to further improve the solution quality.
\section{Position in the Frequency Planning Domain}
In this section a description is given of what a position is in the frequency planning domain. First a frequency plan is defined and the general structure to represent such a plan is provided. The section will conclude with the hard and soft constraints and how the constraints aid in creating a frequency plan that is suitable for a network.

A frequency plan, is almost exactly what the name implies: A plan that outlines frequency usage for a mobile telecommunication network. The benchmark problems that were used to test the developed \gls{PSO} all pertained to cellular phone networks and were presented in section~\ref{sec:FAPBenchmarks}. For cellular networks, the frequency plan outlines which frequency must be allocated to which transceiver.

With this basic definition, the problem is deceptive as one naturally assumes that there are an infinite number of frequencies that can be used or the number of frequencies available for assignment is more than the number of transceivers in the network. 

The reality is that there are only a finite number of frequencies available for cellphone transmissions, as was discussed in chapters~\ref{chpt:celltech} and \ref{chpt:fap}. Hence a regulatory body needs to assign wireless spectrum to cellphone network operators for use in their networks. A regulatory body is needed because, if a network operator uses just any frequency it wants, it is bound to interfere with someone else also utilising the same frequency.

A network is not assigned to the entire wireless spectrum for wireless communication, but rather only a subset is assigned to the network. If one observes the \gls{FAP} benchmark problems the \gls{PSO} was applied to (see section~\ref{sec:FAPBenchmarks}) for instance Siemens1, the allotted spectrum is from frequency 16 to 90. Which gives the network operator 74 frequencies to use in its network without considering other constraints. 

Besides the electromagnetic constraints that are also applicable here, there are regulatory constraints, for instance frequencies in the spectrum that are by no means allowed to be used. These frequencies are referred to as globally blocked frequencies and are hard constraints. An in-depth discussion of these constraints was given in section~\ref{sec:Interference}.

As discussed in chapters~\ref{chpt:celltech} and \ref{chpt:fap}, a cellphone network is divided into a number of cells, and each cell requires a certain number of transceivers to service its corresponding area. 

The number of transceivers is based on the expected volume of traffic that a particular cell will experience at peak network usage. Some cells might be located in highly populous areas, which means the potential traffic that cell might need to handle during peak network usage is very high and thus the cell has more than one transceiver to handle the potential traffic. With cells that are located in areas that have a low population, the potential traffic the cell might experience during peak network usage is low and thus the cell only has one transceiver to handle potential traffic.

Based on the amount of traffic a cell needs to handle, the number of transceivers differs; thus in a frequency plan not all cells have the same number of transceivers, otherwise a frequency plan can be modelled as a series of constant D-dimensional vectors, where the D represents the number of transceivers. 
~
\begin{figure}[ht]
	\centering
	\setlength \fboxsep{0pt}
	\setlength \fboxrule{0.5pt}
	\fbox{\includegraphics[width=4.8in, height=3.5in]{./pictures/fapPlanDiagram.pdf}}
	\caption{The structure of a frequency plan}
	\label{fig:fapPlan}
\end{figure}
~
As can be seen in figure \ref{fig:fapPlan} a cellular network can have any number ($N$ in the figure) of cells to attain the desired coverage over the geographical landscape. In the COST 259 benchmark problems the cellular networks have a large number of cells that range from 500 to more than 1 000. 

The most important part of the plan is the actual transceivers within each cell. In figure~\ref{fig:fapPlan} it can be clearly seen how the number of transceivers (TRXs) varies from one cell to the next. $F(i)$ is a frequency at position $i$ from the available usable spectrum. 

Based on the structure of the plan depicted in figure \ref{fig:fapPlan} there is no concept of which cell interferes with which other cell and if there is indeed interference, the extent of this interference. Not all this information is part of the plan. Instead this information, for the purpose of this research is supplied by the COST 259 benchmark. 

The interference information is referred to as the interference matrix. A definition of the structure of an interference matrix was given in section~\ref{sec:Interference}. As discussed, each entry references two cells' entries: Cell A and Cell B. Along with the entry the amount of interference that occurs when Cell B interferes with Cell A is also listed\footnote{Interference occurs based on the electromagnetic constraints as defined in chapter~\ref{chpt:fap}}.

A frequency plan is a possible solution to the \gls{FAP}. Therefore in the \gls{PSO} that was developed each particle's position in the solution space is represented by a frequency plan. As illustrated in figure~\ref{fig:fapPlan}, a frequency plan is just a series of cells, where each cell has a set of transceivers; thus in the \gls{PSO} algorithm a plan is actually represented as an array of cells. This enables the algorithm to access particular cells in a plan by index as can be observed in listed algorithms~\ref{alg:velocitymethod1} and ~\ref{alg:velocitymethod2}. 

Before the particles can actually start to move around in the \gls{FAP} space, they first need to be assigned positions. In the developed \gls{PSO} listed in algorithm~\ref{alg:FAPPSO} line 1 the first operation that the algorithm executes is to initialise all the particles in the swarm. A particle position in the algorithm is initialised by assigning it a random position; thus a frequency plan (representing a position) is randomly generated by the algorithm.
\begin{algorithm}[H]
\label{alg:FAPPSO}
\caption{The \gls{FAP} \gls{PSO} Algorithm}
\begin{algorithmic}
\State $s_n$ = Initialize Swarm $s_n$
\While{Termination criterion not met}
	\State EvaluateSwarm($s_n$)
	\State UpdateGlobalBest($s_n$)
	\State UpdateSwarmMovement($s_n$,$gbest$)
\EndWhile
\end{algorithmic}
\end{algorithm}


The position is purely random in that the only considerations made by the position generator are that valid frequencies are assigned to transceivers installed at cells. Thus the generator does not check whether a frequency has already been assigned in the current cell or any other considerations. The intended purpose of the generator is just to place a particle in the problem space, not the premature start of the optimisation process.

Since particles are able to occupy positions in the \gls{FAP} space the \gls{PSO} algorithm is now able to move them around in the problem space. As mentioned previously, moving particles through the frequency plan solution space introduces an interesting problem due to the multidimensionality of a plan. A discussion of how particles are moved from one position to another through the solution space is provided in section \ref{sec:velocityFAP}

In the next section an explanation is given on the fitness function that determines the desirability of a particular particle's position or rather the frequency plan its position represents.
\section{The Fitness Function}
The fitness function rates the desirability of a particular particle's position in the problem space.

As discussed in the previous section, the COST 259 benchmark problems provide an interference matrix that lists the total amount of interference that occurs when a pair of cells interfere. As outlined in the structure definition (see section~\ref{sec:Interference}) each entry in the interference matrix defines a pair of cells that are said to interfere, along with two additional values. The first value is referred to as co-channel interference and is the total amount of interference that will occur on the communication link when the allocated frequency of one transceiver is equal to a transceiver in the other cell that is listed in the interference matrix. 

The second value is called adjacent channel interference and it is the total amount of interference that will occur on the communication link when the allocated frequency of a transceiver in one cell differs by 1 from another frequency allocated to the transceiver from the other cell that is listed in the interference matrix.

Particles move towards other particles because the other particles have indicated (through information sharing) that the positions they occupy are very lucrative and thus they have found potentially good solutions. The only way particles can know the lucrativeness of the position they occupy is if the position is evaluated with a fitness function. Thus the lucrativeness of a position is actually the fitness value obtained from the fitness function. 

Since a particle position is defined as a frequency plan, a procedure is needed that calculates the fitness of a frequency plan. With the \gls{FS-FAP} the primary concern is to keep interference to a minimum. Therefore in the \gls{PSO} that was developed the fitness value is the total amount of interference generated by all the cells with their allocated frequencies. 

The evaluation procedure goes through each pair of cells defined in the interference matrix where it looks up both cells in the frequency plan. The second cell is said to interfere with the first cell. Therefore each transceiver in the first cell is checked against all the transceivers of the other cell. Depending on whether the frequencies differ from each other, the fitness procedure adds either co-channel or the adjacent channel interference to a summing variable. This procedure is mathematically defined in chapter 3 (see page \pageref{E:costFunction} for the formal equation) and algorithm~\ref{alg:fapcost} is the pseudocode of the implement equation used by the \gls{PSO} . 

\begin{algorithm}
\caption{FAP Cost Function}
\label{alg:fapcost}
	\begin{algorithmic}[1]
	\Require normalCell
	\Require interferingCe;;
	\State $totalInterference \leftarrow $0
	\For{Each TRX $trx_i$ in interferingCell}
		\For{Each TRX $trx_j$ in normalCell}
			\State $interference \leftarrow 0$
			\State $difference \leftarrow$ $|trx_i - trx_j|$
			\If{difference is 0}
				\If{coChannelInterference $\leq$ minInterferenceThershold}
					\State $interference \leftarrow interference + 0$
				\Else
					\State $interference \leftarrow interference + coChannelInterference$
				\EndIf
			\Else
				\If{difference is 1}
					\If{adjChannelInterference $\leq$ minInterferenceThershold}
						\State $interference \leftarrow interference + 0$
					\Else
						\State $interference \leftarrow interference + adjChannelInterference$
					\EndIf
				\EndIf
			\EndIf
			\State $totalInterference \leftarrow totalInterference + interference$
		\EndFor
	\EndFor
	\end{algorithmic}
\end{algorithm}

As can be seen in algorithm~\ref{alg:fapcost} not all interference values are added to the total amount of interference variable. The COST 259 benchmarks define a minimum tolerable interference variable. This means that if a given interference value is either equal to or less than this defined value the interference generated is negligible and can be disregarded as it will not have a noticeable impact on the communication link.

In the next section a description is given of how particles are moved from one iteration to the next using frequency plans as positions in the solution space.
\section{Velocity Function for Frequency Planning}
\label{sec:velocityFAP}
The elocity function is arguably the core of the \gls{PSO} algorithm. It is the procedure by which particles in the swarm move from one point to another in the solution space. 

The velocity function does not blindly move a particle from one point to another, but instead it takes the particle history into account as well as the best particle in the swarm. Therefore the velocity function is the core means by which the swarm explores the solution space. A more thorough explanation is provided in section~\ref{sec:particleVelocity}.

The development of a velocity function that is suitable for particles to move from one frequency plan to another is covered next. The section will start off with the first velocity function that was developed. With each method discussed, the problems associated with it will also be mentioned. 

This section will conclude with the second method that was developed and that is also the primary method the developed \gls{PSO} uses.

\subsection{Movement in the Frequency Planning Domain}
The standard velocity equation works on the basis of vector mathematics. Each particle has a velocity and position, which is represented by a standard mathematical vector. The standard equation alters the direction of the particle to move to a more promising position in the solution space that is in the general direction of the global best particle and a previous personal best position the particle held..

Vector mathematics has standard basic operations defined for adding, subtracting and multiplying; hence applying the \gls{PSO} to problems that are either mathematical functions or problems that map well to the vector domain is a defined process. With regard to the frequency planning domain an important question needs to be answered: How can one multidimension frequency plan be moved to another?

With any difficult problem it is better to break the problem down into its most basic constructs and then solve each piece individually until the problem as a collective is solved. This technique is also commonly known as divide and conquer. This technique was first applied to the nature of a frequency plan.

A frequency plan is a plan that consists of a series of different cells that are in use in the network. The plan specifies the frequencies that each individual transceiver installed at a cell must use for communication. Thus a frequency plan can broken up into three important constructs:
\begin{enumerate}
\item A plan is a list of different cells.
\item Each cell in a plan has a list of transceivers that it has installed.
\item Each installed transceiver has a single number allocated to it called the frequency. This frequency is used for communication.
\end{enumerate}

Now that a frequency plan has been broken up into its constructs, the question of how to move one frequency plan to another can be rephrased. How does one move a frequency allocated to a \emph{transceiver} in a particular \emph{cell} of one frequency plan to another frequency of the \emph{same} transceiver and cell in another \emph{different} plan? An important realisation needs to be noted here. In the \gls{PSO} at any one time the algorithm is only considering two positions and for the \gls{FAP} the two positions are frequency plans. Both plans are \emph{identical} except for the specific that frequencies transceivers use. Thus a cell that exists in the one plan, also exists in another plan. Both the cells have exactly the same number of transceivers installed; only the frequencies each individual transceiver uses for communication differ.

Using this realisation, the conclusion can be made that the velocity equation can only work with the frequencies assigned to transceivers. Therefore a potential velocity equation mechanism needs to operate on the finest granularity of a frequency plan, i.e. the frequencies.

The principle on which the first velocity method developed is based, is for the movement of the swarm to be at a much finer granularity and hence movement is based on frequencies. Therefore when a particle needs to move towards a global best particle, the velocity procedure goes into the intricate details of the particle wanting to move and the global best particle. The procedure goes into each cell defined in the frequency plan represented by the standard particle as well as the global best particle to be able to access each installed transceiver.

To be able to move from one frequency plan to another by utilising the standard velocity equation, the equation needs to be broken up into its smaller operations. In this way, small operations can be developed that perform the same function as the individual parts. 

The velocity equation in section~\ref{sec:particleVelocity} can be broken up into the following parts:
\label{lst:velocitybreakup}
\begin{itemize}
\item \textbf{Subtraction} --- $pbest - x_i(t)$ --- (SubtractionResultPbest) and $gbest - x_i(t)$ --- (SubtractionResultGbest)
\item \textbf{Multiplication} --- $c_1\phi_1 * SubtractionResultPbest$ --- (MultiPbestResult) and $c_2\phi_2 * SubtractionResultGbest$ --- (MultiGBestResult)
\item \textbf{Addition} --- $v_i(t) + MultiPbestResult + MultiGBestResult$
\end{itemize}
There are no mathematical constructs that define how two frequency plans are added together or subtracted, let alone multiplied. As discussed earlier, a frequency plan is just a series of cells that have frequencies and these frequencies are numbers that internally are just integers and there are mathematical constructs that define how two integers should be added, subtracted or multiplied. Both velocity methods that were developed utilise the basic principle that on a fine granularity of a frequency plan one is merely working with integers.


The first velocity method is listed in algorithm~\ref{alg:velocitymethod1}. Velocity method 1 works on the principle of moving one cell in a particular frequency plan to the same cell in a different frequency plan. As noted earlier, the cells are the \emph{same}, but the frequencies that have been allocated to each transceiver within a cell differs. Thus in velocity method 1, each cell has an array of transceivers. The array of transceivers contains the individual frequency numbers that have been allocated to a cell.
\begin{algorithm}[H]
\caption{Velocity Method 1}
\label{alg:velocitymethod1}
	\begin{algorithmic}[1]
	\Require currentParticle
	\Require globalBestParticle
	\State $pbest \leftarrow $currentParticle position
	\State $gbest \leftarrow $globalBestParticle position
	\State $localCoeff \leftarrow getLocalCoefficient()$
	\State $globalCoeff \leftarrow getGlobalCoefficient()$
	\State $pBestSubtractResult \leftarrow $Subtract current Particle position from pbest
	\State $gBestSubtractResult \leftarrow $Subtract current Particle position from gbest
	\State $a \leftarrow $Multiply localCoeff with pBestSubtractResult and a random value
	\State $b \leftarrow $Multiply globalCoeff with gBestSubtractResult and a random value
	\If{first time velocity is calculated for current Particle}
		\State $currentParticle.Velocity \leftarrow $Add a and b
	\Else
		\State $abAdditionResult \leftarrow $Add a and b
		\State $inertia \leftarrow getInertia()$
		\State $newVelocity \leftarrow $Add abAdditionResult and currentParticle.Velocity
		\State $currentParticle.Velocity \leftarrow $Multiply inertia with newVelocity
	\EndIf
	\State $currentParticle.Position \leftarrow $Add currentParticle.Velocity and currentParticle.Position
	\State SanatizePosition(currentParticle.Position)
	\end{algorithmic}
\end{algorithm}

Velocity method 1 actually moves one array of transceivers to another array of transceivers. This is why, if one observes lines 5 -- 17 in algorithm~\ref{alg:velocitymethod1}, each particle position is passed to methods that are named Subtraction, Multiplication and Addition. As discussed in the previous section, each position of a particle is actually a frequency plan.


The first method that is used to calculate the velocity of a frequency plan, is the first basic operation defined in the velocity equation, namely subtraction, as can be observed from algorithm~\ref{alg:arraySubtract}. The particular algorithm expects two positions to be given to it: the position it must be moved from and the position it must be move to. Because each position is a frequency plan that contains an array of cells, a for-loop is started on line 1 that allows the algorithm to go through each cell that is defined in the frequency plan. Each cell has a number of transceivers, each with an assigned frequency. 
\begin{algorithm}[H]
\caption{Subtract One Position From Another} (Method 1)
\label{alg:arraySubtract}
\begin{algorithmic}[1]
	\Require fromPosition
	\Require toPosition
	\For{Each cell $c$ in fromPosition}
		\For{Each transceiver $f_{trx}$ in $c$}
			\State $t_{trx} \leftarrow$ Get same $f_{trx}$ in toPosition
			\State $f_{trx} \leftarrow f_{trx} - t_{trx}$
		\EndFor
	\EndFor
\end{algorithmic}
\end{algorithm}


To be able to subtract two transceivers from each other, the algorithm needs access to a particular transceiver of a cell. The algorithm gains this access by entering another for-loop based on the number of transceivers a cell has, as can be observed to occur in line 2. Within this for-loop the actual subtraction of transceivers occurs.

The algorithm first obtains the exact same transceiver in the toPosition frequency plan. This operation is quick, as the two plans are identical except for the frequencies assigned to transceivers for each cell. Thus the algorithm is able to refer to the cell and specific transceiver in the toPosition plan by the same index it utilises to access the cell and transceiver in the fromPosition.

Once the toPosition plan transceiver frequency value has been obtained, the algorithm performs a standard integer subtraction as seen in line 4 of algorithm~\ref{alg:arraySubtract}.
After the subtraction algorithm is completed, a position is returned which is the result of subtracting the fromPosition from the toPosition. Using this result the velocity method 1 algorithm is now ready to apply the next operation in the velocity update equation, namely multiplication which is depicted in algorithm~\ref{alg:arrayMultiply}.

\begin{algorithm}[H]
\caption{Multiply Position by a Value (Method 1)}
\label{alg:arrayMultiply}
\begin{algorithmic}[1]
	\Require fromPosition
	\Require value
	\Require mustRandom
	\For{Each cell $c$ in fromPosition}
		\For{Each transceiver $trx$ in $c$}
			\If{must multiply with random number}
				\State $trx \leftarrow trx * value * random()$
			\Else
				\State $trx \leftarrow trx * value$
			\EndIf
		\EndFor
	\EndFor
\end{algorithmic}
\end{algorithm}

The multiplication algorithm is where the local Coefficient and the global coefficient\footnote{Local coefficient is the cognitive component and the global coefficient is the social component. These components are discussed in section~\ref{sec:psointro}} defined for the \gls{PSO} are multiplied into a position, i.e. frequency plan. As with the subtraction algorithm the multiplication algorithm enters two for-loops. The first for-loop is to access each cell defined in the frequency plan. The second loop allows the algorithm to access each transceiver within a particular cell. These for-loops can be observed to occur in algorithm~\ref{alg:arrayMultiply} in lines 1 and 2.

Once the algorithm is able to access each individual transceiver and get its assigned frequency, it is able to perform the multiplication operation. As can be observed in the algorithm in line 3 the algorithm checks whether it needs to multiply the frequency by an additional random number besides the $value$ passed to the algorithm. The reason this is done is that multiplication is required in the \gls{PSO} in the following cases:

\begin{itemize}
\item The inertia case --- $0.5 * v(t+1)$, where 0.5 is the inertia value and $v(t+1)$ is velocity that has already been calculated for a particular particle $t$. Note, a velocity that has been calculated is still a frequency plan.
\item Standard velocity calculation randomisation case --- As can be observed from the velocity equation~\ref{eq:velocityupdate} and also from the multiplication bullet point on page~\pageref{lst:velocitybreakup}, the equation requires that a position be multiplied by a coefficient $c_1$ or $c_2$ and then a random value $\phi_1$ or $\phi_2$. 
\end{itemize}

Regardless of which case is executed, the actual operation that is performed is integer multiplication, which therefore means that even though the inertia and random numbers are decimal, the fractional component of the result is discarded. Channels are integers so the loss of the fractional component is warranted as it is of no use.

As per the last bullet point on page~\pageref{lst:velocitybreakup} the last basic operation that occurs in the velocity equation is an integer addition operation. Algorithm~\ref{alg:arrayAdd} is the addition procedure used by velocity method 1 (algorithm~\ref{alg:velocitymethod1}).
\begin{algorithm}[H]
\caption{Add One Position to Another (Method 1)}
\label{alg:arrayAdd}
\begin{algorithmic}[1]
	\Require fromPosition
	\Require toPosition
	\For{Each cell $c$ in fromPosition}
		\For{Each transceiver $f_{trx}$ in $c$}
			\State $t_{trx} \leftarrow$ Get same $f_{trx}$ in toPosition
			\State $f_{trx} \leftarrow f_{trx} + t_{trx}$
			\State Bound($t_{trx}$)
		\EndFor
	\EndFor
\end{algorithmic}
\end{algorithm}

In the addition algorithm, as with multiplication and subtraction, two for-loops are started as can be observed in lines 1 -- 2. The algorithm first starts iterating through all the cell's present in the fromPosition frequency plan and then within the cell for-loop starts another for-loop which iterates through each cells transceivers. Inside the transceiver for-loop the algorithm actually performs the addition of two frequencies.

Two frequencies are added based on integer addition. Once the fromPosition cell transceiver is accessed, the algorithm retrieves the exact transceiver and cell in the toPosition in order to get its allocated frequency value. After both values have been retrieved the algorithm performs the addition as can be observed in line 4 of algorithm~\ref{alg:arrayAdd}.

The addition operation is the last operation that occurs in the velocity equation and is also the only operation that occurs when the resultant velocity is applied to the current position of a particle as in equation~\ref{eq:positionupdate}. Since the addition operation is also used in the final position update of the particle, its last operation in the transceiver loop a bound operation. 

The purpose of the bound operation is to keep the frequencies within valid value ranges.
\subsection{Keeping Frequencies Bounded}
In the previous section the first velocity method that was developed was discussed. The velocity method is important as it calculates the direction and next position of a particle in the problem space, where the problem space is the \gls{FAP} and a position of a particle is a possible frequency plan. With the velocity method defined, the swarm is now able to move around in the problem space, but this alone is not enough. The swarm has no concept of the constraints\footnote{Constraints in the \gls{FAP} are discussed in chapter~\ref{chpt:fap}} that are imposed inherently by the domain as well as the network for which a frequency plan is being created.

Due to the swarm not having a concept of the constraints a constraint handling mechanism needs to be used. Each of the methods discussed in this section fall under the category of using the \emph{repair method} which is discussed in section~\ref{sec:chm}

The first method that was developed was the BoundValue method and is depicted in algorithm~\ref{alg:boundvalue}.
\begin{algorithm}[H]
\caption{BoundValue Method}
\label{alg:boundvalue}
\begin{algorithmic}[1]
	\Require Position
	\For{Each cell $c_i$ in Position}
		\For{Each transceiver $trx_j$ in $c_i$}
			\State $trx_j = \left|trx_j\right|$
			\If{$trx_j \geq maxChannelValue$}
				\State $trx_j = minChannelValue + (\text{$trx_j$ mod $maxChannelValue$})$
			\Else 
				\If{$trx_j \leq minChannelValue$}
					\State BoundValue($trx_j + minChannelValue$)
				\EndIf
			\EndIf
		\EndFor
	\EndFor
\end{algorithmic}
\end{algorithm}
The constraints that are imposed are usually some part of the spectrum that may under no circumstances be used anywhere in the network, which as discussed in chapter~\ref{chpt:fap} is known as globally blocked frequencies. Some frequencies that are only allowed to be used in certain parts of the network are known as locally blocked frequencies. Then of course the swarm also needs to take into account the electromagnetic constraints\footnote{Discussed in section~\ref{sec:Interference}}.

The velocity function used by the \gls{PSO} needs to be altered to make the swarm in some sense more aware of the domain it is operating in and hence keep the particle positions bounded within the allowable search space. By not bounding particle positions in the \gls{FAP} problem space, transceivers of some cells might be assigned a frequency that is not allowed or not even allocated to the network. The \gls{PSO} will accept this assignment since the fitness function operates on the assumption that under no circumstances will these invalid frequencies be assigned and thus does not penalise invalid assignments.

To keep assigned frequency values to transceivers in the allocated spectrum of the network a boundary check needs to be added to the velocity method. The purpose of the boundary check is to validate all assignments in a position, i.e. the frequency plan that a particle currently occupies, and if any assignments violate the defined boundary constraints then it must take the violating value and modify it to be in the acceptable value range.

The boundary check that is used by velocity method 1 operates on the basis that for any range of values there is a defined lower bound (a minimum value) and upper bound (a maximum value). The frequency boundary check is only applied when one of the following conditions is met after the calculated velocity has been applied to the current position:
\begin{itemize}
\item If a frequency allocated to a transceiver is above the maximum allowable frequency (upper bound) given to the network. 
\item If a frequency allocated to a transceiver is below the minimum allowable frequency (lower bound) given to the network.
\end{itemize}

As can be seen in line 5 of algorithm~\ref{alg:boundvalue}, a mod operation is applied to the value to bring it within the allowable range. The integer mod operation is similar to integer division, the only difference being in the result that is produced. Division produces the result of two numbers being divided. Mod produces the remainder of two numbers being divided. If two numbers divide perfectly into one another there will not be any remainder; if the numbers do not divide perfectly into one another there will be a remainder. 
\begin{align}
	10 mod 50 =& 10 \\
	60 mod 50 =& 10 \\
	50 mod 50 =& 0 \\
	100 mod 50 =& 0 \\
	35 mod 50 =& 35 
\end{align}

As can be seen in the above example mod operations, any value that is modded will be kept in the range $[0,50]$. With regard to frequencies, the following occurs: If, for instance, the maximum allowable frequency is 50, and the transceiver has a frequency value (after velocity) of 56, the 56 value is modded by 50 to produce a value of 6. This modded value is then added to the minimum allowable frequency. In essence, the value is wrapped around to always be within acceptable range. 

The difficult case is when the frequency value is lower than the minimum frequency given to the network. This is because modding the frequency value has no effect. For example, if the lowest allowable frequency is 20 and the transceiver value after movement is 15, modding the transceiver value of 15 by 20 has no effect. To solve this, the following options are then considered:

\begin{enumerate}
\item First subtract the lower value from the minimum allowable frequency. Then add the result to the minimum allowable frequency. The resultant value is checked again as to whether it oversteps the bounds of the maximum allowable frequency and is bounded accordingly.
\item Add the lower value to the minimum allowable frequency. The resultant value is checked as towhether it oversteps the bounds of the maximum allowable frequency and is bounded accordingly.
\item Repeatedly subtract the lower value from the maximum allowable frequency until the resultant frequency is within the acceptable frequency range.
\end{enumerate}

An important notion to consider is that, based on the velocity equation, it is entirely within the realm of possibility that a frequency value after movement might contain a negative value. As can be seen in line 3 of algorithm~\ref{alg:boundvalue} the algorithm solves this problem by first taking the absolute value of the negative frequency value. The boundary check then treats the now positive frequency value as a normal value that needs to be bounded.

It is better to use frequency index values rather than actual frequency values for frequency plans, and this is explained below.
\subsection{Using Indices instead of Frequencies}
\label{sec:velocityFAP2}
As discussed in section~\ref{sec:velocityFAP} and as can be observed from algorithm~\ref{alg:velocitymethod1}, the first velocity method that was developed for the \gls{PSO} worked with raw frequency values. This is not ideal since upon closer inspection the frequency range that the swarm used to move around was indeed incorrect. The bound value algorithm only keeps frequencies within a minimum and maximum allowable frequency range, but globally blocked frequencies and locally blocked frequencies can be in between this minimum and maximum frequency range. 

With velocity method 1 and the \gls{PSO} using raw frequency values, the swarm increasingly moved towards allocating these blocked frequencies to trans-ceivers since the fitness function does not penalise the use of blocked or invalid frequency values. This is partly due to the fact that these values are under no circumstances allowed to be used and thus the fitness function is not designed to check for these values explicitly to impose a penalty.

Frequency plans that utilise these blocked frequencies are invalid and cannot be used. If a network were to use a plan that uses blocked frequencies, it could cause unexpected interference to other services and the network could be fined by the governing body that controls the spectrum. A bare minimum requirement then is that the \gls{PSO} must generate valid frequency plans and hence swarm particles can only occupy valid positions. The following options were presented to solve the problem of particles moving towards invalid positions and hence having invalid frequency plans:
\begin{enumerate}
\item Modify the fitness function to penalise a frequency plan if it uses any globally blocked frequencies or locally blocked frequencies.
\item Instead of letting the swarm work with raw frequency values, rather let it work with indices of an array. The array index values indicate positions in an array that has been pre-filled with only \emph{valid} frequencies. Thus the swarm then moves around in a range from 0 to $F$, where $F$ is the size of the frequency array.
\end{enumerate}

With the first solution, the fitness function would have to be modified to impose a penalty if a prohibited frequency value were used. The first proposed solution was disregarded because it introduces complexity which can be completely avoided with the second proposed solution.

With the second solution the fitness function does not have to be modified and the boundary check is simplified since there is no need to check for a lower bound. The boundary check now only has to check for negative index values and whether the upper bound, which is now the size of the array, is violated. 

The second method is also a method known in constraint handling as \emph{preserving feasibility} (see section~\ref{sec:chm} for a discussion on constriant handling methods). By using only valid frequencies the search space is even more constricted to only feasible solutions.


Working with index values rather than with raw frequency values led to  a second velocity method. Algorithm~\ref{alg:velocitymethod2} is the pseudocode for the second velocity method. The second velocity method differs from velocity method 1 due to it being designed to only work with indices of an array.
\begin{algorithm}[H]
\caption{Velocity Method 2}
\label{alg:velocitymethod2}
\begin{algorithmic}[1]
	\Require currentParticle
	\Require globalBestParticle
	\State $currPos \leftarrow$ currentParticle position
	\State $pbestPos \leftarrow$ currentParticle best position
	\State $gbestPos \leftarrow$ global best particle position
	\For{Each cell $c$ in $currPos$}
		\State $c_{pbestPos} \leftarrow $ Same cell in $pbestPos$
		\State $c_{gbestPos} \leftarrow $ Same cell in $gbestPos$
		\State $movedIndices \leftarrow $MoveIndices($c_{pbestPos},c,c_{gbestPos}$)
		\If{First time velocity is calculated}
			\State ApplyVelocity(c,movedIndices)
		\Else
			\State $newVelocity \leftarrow CalculateIndexVelocity(currPos.velocity,movedIndices)$
			\State ApplyVelocity(c,newVelocity)
		\EndIf
	\EndFor
	\State SanatizePosition(currPos)
\end{algorithmic}
\end{algorithm}

Velocity method 2 also differs from method 1 due to the manner in which it applies the velocity equation. Velocity method 1 applies the velocity equation in stages. Each stage is applied to the entire position, i.e. frequency plan before applying the next stage. With velocity method 2 the algorithm first enters a for-loop as in line 6. Within this for-loop the algorithm obtains the current cell, the cell stored in its previous best-held position $pbestPos$ and the same cell stored in the global best position $gbestPos$.

Once all the correct cells have been obtained the algorithm calls a method named \emph{MoveIndices} (which is presented in algorithm~\ref{alg:moveindices}) to which all the cells are passed.
\begin{algorithm}
\caption {MoveIndices}
\label{alg:moveindices}
\begin{algorithmic}[1]
	\Require pbestCell
	\Require currCell
	\Require gbestCell
	\For{Each $trx_i$ in currCell}
		\State $pbestTRX_i$ = Get $trx_i$ in pbestCell
		\State $gbestTRX_i$ = Get $trx_i$ in gbestCell
		\State $r1 \leftarrow$ Random double number
		\State $r2 \leftarrow$ Random double number
		\State $localCoeff \leftarrow getLocalCoefficient()$
		\State $globalCoeff \leftarrow getGlobalCoefficient()$
		\State $a \leftarrow localCoef * r1 * (pbestTRX_i - trx_i)$
		\State $b \leftarrow globalCoef * r2 * (pbestTRX_i - gbestTRX_i)$
		\State $trx_i \leftarrow a + b$
	\EndFor
\end{algorithmic}
\end{algorithm}

In the MoveIndices algorithm three cells are passed to it. The current cell of the velocity algorithm that is being moved, as is the same cell that is stored in the previous best-held position of the particle and also the same cell in the global best position. The algorithm starts off by iterating through all the transceivers installed at the current cell as can be seen in line 1 of algorithm~\ref{alg:moveindices}. In lines 2 -- 3 the algorithm obtains the frequency values from the \emph{pbestCell} and \emph{gbestCell}.

After the MoveIndices algorithm has obtained the frequency values it is ready to apply the velocity equation. As can be seen in lines 8 -- 10 the algorithm applies the standard velocity equation~\ref{eq:velocityupdate} formulated in chapter~\ref{chpt:swarm}. 

Once the MoveIndices algorithm has completef, the currCell variable now stores the calculated velocity. Algorithm~\ref{alg:velocitymethod2} uses the return calculated velocity to update the cell position of the current particle. The algorithm accomplishes this by first determining whether the particle has had a previously calculated velocity. If it is the first time the velocity has been calculated, the algorithm simply applies the velocity by using algorithm~\ref{alg:applyvelocity}. 

\begin{algorithm}
\caption{ApplyVelocity}
\label{alg:applyvelocity}
\begin{algorithmic}[1]
	\Require currPos
	\Require velocity
	\For{Each index $c_i$ in currPos}
		\State $c_i \leftarrow c_i + velocity_i$
	\EndFor
\end{algorithmic}
\end{algorithm}

If the particle does have a current velocity, the algorithm first executes algorithm~\ref{alg:calcindexvelocity} as can be observed to occur in line 11 of algorithm~\ref{alg:velocitymethod2} before applying the calculated velocity with algorithm~\ref{alg:applyvelocity}. Velocity method 2 first executes algorithm~\ref{alg:calcindexvelocity} to apply the concept of inertia\footnote{Inertia is discussed in chapter~\ref{chpt:swarm} in the subsection entitled ``Inertia Weight'' of section~\ref{sec:psocharacteristics}.}.

\begin{algorithm}
\caption{CalculateIndexVelocity}
\label{alg:calcindexvelocity}
\begin{algorithmic}[1]
	\Require currVelocity
	\Require newVelocity
	\For{Each value $v_i$ in currVelocity}
		\State $inertia \leftarrow getInertia()$
		\State $v_i \leftarrow v_i + (inertia * newVelocity_i)$
	\EndFor
\end{algorithmic}
\end{algorithm}

As can be observed in algorithm~\ref{alg:calcindexvelocity} the CalculateIndexVelocity method loops the current velocity. Within the loop the algorithm retrieves the inertia value that needs to be applied, after which the inertia value is multiplied by the newVelocity value.

After the CalculateIndexVelocity algorithm has finished executing, the concept of inertia has been applied to the velocity. Velocity method 2 therefore applies the velocity using the ApplyVelocity method listed in algorithm~\ref{alg:applyvelocity} to the current cell found in the particle position to move it in order to obtain a new position.

The observant reader might have noticed that in all the presented and associated velocity algorithms the procedures operate and store the result in the current particle position that is currently being worked on. Naturally one might think that this overwrites the position information currently in that position. In the developed \gls{PSO} algorithm when velocity is calculated the respective velocity methods operate on clones of the original position. The original position is only used once the velocity has been calculated and the particle has actually moved.

Another important note, is that if one analyses velocity method 1, the switch to using index values instead of raw frequencies does not affect the method's operation. Since the method only requires explicit knowledge on the data to operate on in the BoundValue algorithm, the algorithm is still able to calculate velocity. 

It is up to the algorithm designer to update the bound value method to use the array index bounds rather than the raw lower and upper bounds of the frequencies. The BoundValue algorithm needs to be updated since it is the primary means by which velocity method 1 ensures valid positions.

Both the velocity methods that are utilised by the developed \gls{FAP} \gls{PSO} algorithm have now been explained with corresponding pseudocode. Why the developed \gls{PSO} was modified to operate on frequency index values rather than frequency values was also explained. All the algorithms that enable the main algorithm to accomplish particle movement with indices were also discussed. The \gls{PSO} is hence able to move the particles in the \gls{FAP} using two different methods, but for a particle to be moved it needs a personal best and most importantly, a global best to move towards. The next section deals with on how the developed \gls{PSO} algorithm differs from the standard \gls{PSO} with regard to selecting a global best.
\section{Building a Global Best}
\label{sec:buildglobalbest}
Selection of the global best particle by the swarm is a very important procedure. After the swarm has determined which particle has achieved the best position, the swarm enters the velocity function phase. 

As discussed previously each particle position is then modified to move in the general direction of the global best and personal best position. Therefore the global best acts as a beacon for the rest of the swarm in the solution space to indicate where good solutions seem to be for the rest of the swarm.

\begin{algorithm}
\caption{Standard Gbest Selection in \gls{FAP} \gls{PSO} }
\label{alg:psogbestselection}
\begin{algorithmic}[1]
\Require swarm
\Require gbest
\State $gbestCost$ = Evaluate(gbest)
\For{Each particle $p_i$ in swarm}
	\State $cost$ = Evaluate($p_i$)
	\If{$cost \leq gbestCost$}
		\State $gbestCost = cost$
		\State gbest = $p_i$
	\EndIf
\EndFor
\Return gbest
\end{algorithmic}
\end{algorithm}

Initially the \gls{FAP} \gls{PSO} algorithm used the standard method for selecting the global best particle from the swarm and did not differ at all from the traditional global \gls{PSO} algorithm. The standard global best selection is listed in algorithm~\ref{alg:psogbestselection}. 

As can be observed in lines 2 -- 8 the \gls{FAP} \gls{PSO} algorithm loops through all the particles in the swarm and applies the fitness function to evaluate the fitness of the particle's position. The fitness value is also referred to as the cost. In the \gls{FAP} \gls{PSO} the cost or fitness value of a particle position is the amount of interference the frequency plan that represents the particles position generates.

A low cost value is preferred to a high cost value, since a low cost value indicates low interference. In lines 4 -- 6 of algorithm~\ref{alg:psogbestselection} the \gls{FAP} \gls{PSO} algorithm determines whether the current particle position has a lower cost value than the current global best particle position.

If the current particle position evaluates to a lower cost value than the stored global best, the algorithm replaces the current global best with the current particle being evaluated, which in the algorithm is $p_i$.

Selecting the global best by evaluating the position as a whole seems to be a natural fit. As outlined in the critical evaluation of each algorithm in chapters~\ref{chpt:heuristic} and \ref{chpt:swarm}, some of the algorithms had a problem with regard to some cells or even transceivers overshadowing better cells or transceivers.

For this dissertation, overshadowing is a term that describes a scenario where a bad value of one part of the frequency plan is so large that it causes other smaller values within the frequency plan not to be considered. 

As per the following example a few cells in a frequency plan might have the worst possible frequencies assigned to their respective transceivers, and other might have the best. Now the few cells with the worst frequencies generate a great deal of interference, whereas the cells with the best frequencies generate almost nothing.

When the example frequency plan is evaluated, the bad cells push up the cost value. The high cost value of the frequency plan causes the \gls{PSO} algorithm to disregard the whole plan. By discarding the whole plan the \gls{FAP} \gls{PSO} algorithm loses the knowledge gained on the few cells that had their best frequencies assigned to their respective transceivers.

In the traditional method of selecting the global best, a particle is actually selected as the swarm best because it contains fewer overshadowing cells or transceivers, and potentially good frequency assignments are lost.

The \gls{FAP} \gls{PSO} therefore needed to exploit the knowledge that the fitness function exposes much more thoroughly. The information exposed by the fitness function allows one to see what effects certain frequency assignments have on the interference of the cell when assigned to the individual transceivers. To make better use of this fitness information two methods were developed for the \gls{FAP} \gls{PSO} , each one being finer grained than the other.

\begin{enumerate}
\item Besides the particle storing its fitness or cost, the particle also needed to store the interference generated by an entire cell due to the frequencies allocated to its installed transceivers.
\item Besides the particle storing the total fitness, it also needed to store the interference generated by a frequency allocated to a particular transceiver of a cell.
\end{enumerate}

With both these methods, the global best selection scheme needs to be changed to allow the swarm to take advantage of this newly exposed information. As discussed, initially the \gls{FAP} \gls{PSO} used the standard global best selection scheme listed in algorithm~\ref{alg:psogbestselection}, but now with these new methods, a global best position is no longer selected, but built.

Before the \gls{FAP} \gls{PSO} is able to build a global best, the way a particle stores its evaluated fitness needs to change. For the standard global selection scheme, the particle only needs to store one fitness value that is a result of evaluating the whole frequency plan. To be able to build a global best as described above, the fitness value cannot simply be one lump sum representing interference. Instead in the \gls{FAP} \gls{PSO} algorithm the interference generated by every transceiver is stored.

The \gls{FAP} \gls{PSO} is able to know the performance of every single frequency allocated to a particular transceiver and also compare the allocation with other similar transceivers in other frequency plans.

Each global best scheme developed for the \gls{FAP} \gls{PSO} is more finely grained than the other with regard to what the scheme uses to build a gbest. Algorithm~\ref{alg:gbestcells} uses interference information of cells to build a gbest. Algorithm~\ref{alg:gbesttrx} uses the interference generated by each transceiver installed at a cell to build a gbest. Since each cell has transceivers, the second algorithm is therefore more finer grained than algorithm~\ref{alg:gbestcells}.

\begin{algorithm}[H]
\caption{Building Global Best with Cells}
\label{alg:gbestcells}
\begin{algorithmic}[1]
\Require gbest
\Require swarm
\For{Each particle $p_i$ in swarm}
	\For{Each cell $c_j$ in $p_i$}
		\State $gbestcell_j$ = Get cell $c_j$ in gbest
		\State $cellCost$ = Get total interference for cell $c_j$
		\State $gbestCellCost$ = Get total interference for cell $gbestcell_j$
		\If{$cellCost \leq gbestCellCost$}
			\State $gbestcell_j$ = $c_j$
		\EndIf
	\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
\caption{Building Global Best with Transceivers}
\label{alg:gbesttrx}
\begin{algorithmic}[1]
\Require gbest
\Require swarm
\For{Each particle $p_i$ in swarm}
	\For{Each cell $c_j$ in $p_i$}
		\For{Each transceiver $trx_k$ in $c_j$}
			\State $gbestTrx_k$ = Get $trx_k$ in $c_j$ in gbest
			\State $trxCost$ = Get total interference for $trx_k$
			\State $gbestTrxCost$ = Get total interference for cell $gbestTrx_j$
			\If{$trxCost \leq gbestTrxCost$}
				\State $gbestTrx_k$ = $trx_k$
			\EndIf
		\EndFor
	\EndFor
\EndFor
\end{algorithmic}
\end{algorithm}
Each algorithm will now be discussed since the difference between them is subtle. Algorithm~\ref{alg:gbestcells} was the first global best building scheme which was developed and is discussed first. The algorithm starts off in line 1 by iterating through all the particles in the swarm. For each particle the algorithm enters another loop as can be observed in line 2 of algorithm~\ref{alg:gbestcells}.

The second loop of the algorithm iterates through all the cells in the frequency plan that represent a position of the particle. Once the algorithm has obtained a cell it looks for the same cell in the gbest frequency plan. Since the algorithm now has the current cell and the gbest cell it is able to compare the two cells based on the interference their respective transceivers generate.

The interference generated by the cell is retrieved and then compared as can be observed to occur in line 6. If the current cell has a lower interference (cost) value than the same cell in the global best plan, then the algorithm replaces the cell in the global best with the current cell.

The second algorithm is the finer grained algorithm and was developed because, after analysing the algorithm using cells, it was concluded that it is possible that a single bad frequency allocation to a transceiver within a cell can overshadow other potentially good frequency allocations to other cells within the cell.

Algorithms~\ref{alg:gbestcells} and \ref{alg:gbesttrx} have very similar flow, except that the second algorithm has an extra for-loop. In line 3 of algorithm~\ref{alg:gbesttrx} a third for-loop is started, which iterates through all the transceivers a particular cell $c_j$ has installed. The algorithm then obtains the frequency allocated to the same transceiver in the global best frequency plan.

Once both transceivers have been obtained, the algorithm determines the interference (cost) their respective frequency allocations generated. Using the cost values the algorithm determines whether the current transceiver frequency allocation generates less interference than the frequency allocated to the same transceiver in the global best frequency plan.

If the current transceiver frequency generates less interference, the algorithm then proceeds to replace the transceiver frequency in the global best with the current transceiver frequency. Thus it can be seen that algorithm~\ref{alg:gbesttrx} utilises individual transceivers to build a global best.

Initially when the \gls{FAP} \gls{PSO} algorithm was tested using both of these global best schemes, the \gls{PSO} did not produce noticeably better results. This was due to the algorithm at each iteration discarding the interference or cost information calculated in that iteration and making it zero. Making the cost values zero does initially seem correct, but effectively what is happening is that the algorithm is discarding knowledge gained by that iteration.

To enable this information to direct the swarm a bit more, the \gls{FAP} \gls{PSO} algorithm was modified to not reset the interference values for every transceiver and cell to 0. Instead, the interference values for an iteration are now added to the previous iteration interference values stored by the cell and transceiver. 

By letting interference values compound after each iteration the \gls{PSO} becomes much more aggressive. This is because as the interference compounds bad decisions made by the swarm for a particular particle become progressively worse as the swarm progresses through more iterations.

With compounding interference values the \gls{FAP} \gls{PSO} was able to produce much better positions and had lower total interference (cost) than all previously generated positions by previous \gls{FAP} \gls{PSO} algorithms. 

The \gls{FAP} \gls{PSO} algorithm is able to produce better results by allowing particles to keep a history of their previous movements. This is covered in the next section.
\section{Keeping History}
\label{sec:keepinghistory}
In the traditional \gls{PSO} history is kept by using the particle personal best position to direct the next movement of the particle. Other methods such as inertia also allow history to direct the movement of the particle. With regard to the developed \gls{PSO} on the \gls{FAP}, the algorithm also uses these concepts. But these concepts are not able to effectively exploit the history of a particle since they have no concept of what combinations of frequency values have previously been used in a cell.

In the \gls{FAP} \gls{PSO} algorithm more historical information is kept. The algorithm accomplishes this by incorporating the concept of tabu lists from the \gls{TS} algorithm. Using tabu lists a particle will be able to better exploit the problem space it currently finds itself in. In the \gls{FAP} \gls{PSO} algorithm, tabu lists were incorporated by adding to each cell a list which keeps track of each frequency value that has been assigned to the transceivers in the cell for 20 iterations.

Initially the \gls{FAP} \gls{PSO} algorithm calculated the velocity of a particle and then applied this to the current position of the particle. This moved the particle to its next position in the problem space. With tabu lists this movement step becomes more complicated.

Tabu lists are there to prevent cycling of movements to the same position. Thus to stop the particle from moving to a position that was previously occupied, an extra check has to occur before the particle can occupy a new position. As can be seen in the two developed velocity methods in algorithms~\ref{alg:velocitymethod1} and \ref{alg:velocitymethod2} the last step that occurs in both algorithms is that the SanitizePosition method is called.


The SanitizePosition method is listed in algorithm~\ref{alg:sanitizeposition}. Within this algorithm a particle's future position is first checked and sanitised before the particle is allowed to move to that position. The main purpose of this algorithm is to check if the future position has been occupied previously and hence is in the tabu list.
\begin{algorithm}[H]
\caption{SanitizePosition}
\label{alg:sanitizeposition}
\begin{algorithmic}[1]
	\Require currPosition
	\For{Each cell $c_i$ in currPosition}
		\State $tbList = $ Get Tabu List of currPosition
		\State ResolveCollision($c_i$,$tbList$)
		\State AdhereToSeparation($c_i$)
	\EndFor
\end{algorithmic}
\end{algorithm}


In the \gls{FAP} \gls{PSO} the tabu list check works slightly differently from what one would expect. As can be observed in algorithm~\ref{alg:sanitizeposition}, it enters a loop which iterates through all the cells in the position of the particle. Note that the position passed to the SanitizePosition algorithm is a \emph{future} position; thus the particle does not yet occupy the position yet. Within the for-loop in line 2 the method \emph{ResolveCollision} is called which is listed in algorithm~\ref{alg:resolvecollision}.

\begin{algorithm}[H]
\caption{ResolveCollision}
\label{alg:resolvecollision}
\begin{algorithmic}[1]
	\Require cell
	\Require tabuList
	\For{Each $trx_i$ in cell}
			\While{$trx_i$ exists in TabuList}
				\State $trx_i = $ Generate random frequency
				\If{Collision not resolved after 20 attempts}
					\State Break out of while loop
				\EndIf
			\EndWhile
	\EndFor
\end{algorithmic}
\end{algorithm}

As can be observed in algorithm~\ref{alg:resolvecollision}, when a frequency value is found to exist in the tabu list a collision is said to occur. In the \gls{FAP} \gls{PSO} a collision means that the specific frequency value that has been assigned to a transceiver for a particular cell was found in the tabu list. Once a collision occurs, the algorithm tries to generate a new random frequency that can be assigned to the transceiver as can be seen to occur within the while-loop in lines 2 -- 3.

The algorithm generates a new random frequency value and then checks to see if the generated value collides with the tabu list. If collision still occurs, the algorithm will generate another random frequency. As long as a collision occurs the algorithm will continually generate a new random frequency until it has attempted 20 random frequencies with no frequency colliding. 

After 20 attempts the algorithm just accepts the last generated frequency as the new frequency. The maximum number of 20  attempts was selected through testing and can be increased at the expense of more computational time. 

The resolution of collisions can be seen as a mechanism to increase the exploration of the \gls{PSO} algorithm as well as to increase the diversity. By making certain frequency assignments to transceivers tabu the algorithm is forced to try new frequency assignments and thus explore more of the problem space.

Care must be taken to select a maximum size of the tabu List since one wants to keep enough history so that the problem space can be adequately exploited. The maximum tabu List size must be less than the number of available frequencies otherwise the algorithm will not be allowed to make any assignments. 

Finally the maximum tabu List cannot be too large, since the checks the algorithm has to do to see if a value is tabu are very expensive. The operation is expensive, since the tabu list needs to be iterated through for each potential value to see if the frequency value is tabu.

By incorporating tabu lists and the collision resolving procedure, the efficiency of the algorithm reduces dramatically. To increase efficiency of the operations in the algorithm, the \gls{FAP} \gls{PSO} algorithm utilises parallelisation. Since the collision resolving procedure is very expensive it was one of the first operations to be parallelised. Other procedures that were also parallelised to increase efficiency were the velocity and any other procedures which involved constraint checks.

By parallelising these operations the efficiency of the algorithm increased and it was able to produce results significantly faster. This is because parallelisation is a good fit to the now standard multicore CPUs in desktop computers.

With the parallelisation of the procedures a slight side effect was noticed. The randomness of the random number generator decreased. This effect was noticed because during testing the counter variable of the collision resolver was displayed on the console. When the value was being displayed on the console the \gls{FAP} \gls{PSO} algorithm produced much better results. 

The reason for this is that outputting the variable inherently introduces a delay and therefore the random number generators in other threads have different seed values. Hence with a delay in each parallel thread the numbers generated by the random number generator are more distinct. 

Due to how parallel threads are scheduled by the operating system, some threads might start off with similar seed values because in  the \gls{FAP} \gls{PSO} algorithm the current time is used as a seed value\footnote{This is the default behaviour of the .Net 4.0 random number generator}.

Keeping the delay counter variable displayed on the console introduced a delay in the collision resolving procedure. The reason the particular procedure was selected was that it was where the effect of delay was first noticed. After performing tests with delays of 5 milliseconds (ms), 10 ms, 15 and 20 it was found that 20 ms was the best-suited delay, as it gave just enough time for a reasonable distinction to be made between seed values used by other parallel threads.

In this section a discussion was presented on how the \gls{FAP} \gls{PSO} keeps additional history. The reason why the \gls{FAP} \gls{PSO} needs to keep more history was discussed as well as what mechanism the algorithm uses to store this information, namely tabu lists. Also covered was how the algorithm deals with collisions, which occurs when positions are in the tabu list. Finally collision resolution was explained with the aid of pseudocode of the algorithm that is utilised.

\section{Summary}
In this chapter an algorithm was presented based on the standard particle swarm optimisation algorithm to operate on the frequency assignment problem encountered in cellular networks.

At the beginning of the chapter it was explained how a frequency plan is represented by the algorithm for use internally. Reasons were given for choosing the particular representation in the algorithm.

One of the most important phases of the \gls{PSO} algorithm is velocity calculation. The problem was outlined as to why the standard velocity calculation was unsuitable for the \gls{FAP}. The customised velocity calculation used by the algorithm developed in this research was presented along with suitable pseudocode.

The chapter concluded with small additions made to the algorithm to improve performance and, most important of all, improve solution quality.
%%% TEXEXPAND: END FILE ./chpt7.tex
%%% TEXEXPAND: INCLUDED FILE MARKER ./chpt8.tex
\chapter{Results}
\label{chpt:results}
\section{Introduction}
In the previous chapter the FAP PSO algorithm was discussed. This algorithm was developed by modifying the standard PSO algorithm to operate on the FS-FAP. Thus far, no other PSO algorithms have been attempted on the FS-FAP. The only PSO algorithm that has been attempted in the FAP domain was discussed in chapter~\ref{chpt:swarm} and was not relevant to the study in this dissertation, as the PSO was applied to an entirely different FAP variant (MS-FAP). The PSO on the MS-FAP was not relevant because the performance measures and what the algorithms optimise differ.

With the FS-FAP, the main performance measurement is interference and the PSO aims to allocate frequencies in an optimal way to internally produce a frequency plan. On the other hand, the MS-FAP is concerned with the span of frequencies used and the performance measurement is based on the calls dropped. The main purpose of the PSO in the MS-FAP is to minimise the span of frequencies used and keep the number of dropped calls to a minimum.

In the previous chapter all the modifications that were made to the standard PSO were discussed. The modifications were made to enable to PSO to operate on the FAP. Two velocity methods were developed and in addition to the standard global best selection scheme, two additional global best selection schemes were put forward. The algorithm presented was benchmarked against the Siemens instances of the COST 259 benchmark.

In this chapter the results are given of applying the FAP PSO algorithm with its different velocity methods as well as different global selection schemes. This is followed by how the different velocity methods affected the PSO performance as well as how the global selection schemes affected the final produces results.

\section{PSO COST 259 Siemens Results}
The PSO was applied to the benchmarks on the following machine and frameworks:
\begin{itemize}
\item 4 GB RAM
\item Windows 7
\item Intel Quad Core CPU
\item C\# using .Net 4 Framework with Parallel Extensions
\end{itemize}
The FAP PSO was applied to Siemens1, Siemens2, Siemens3 and Siemen4 of the COST 259 benchmark suite. For more information about the nature of the benchmarks, the reader is directed to section \ref{sec:COST259}.

For each benchmark, 12 results are presented. The following changes were made to the FAP PSO to obtain 12 different results:
\begin{itemize}
\item The two velocity methods that were developed for the PSO were tested.
\item Each velocity method also used the three different global best mechanisms that were developed.
\item The swarm size was set to 20, 50, 100, 500.
\item Inertia was set to 0.5.
\item Cognitive coefficient was set to 0.4.
\item Social coefficient was set to 0.5.
\item Each variant of FAP PSO was allowed 15 minutes on each of the benchmarks.
\end{itemize}
The velocity methods and global selection schemes were discussed in the previous chapter.

In the following sections the results obtained are tabulated.
\subsection{Siemens1}
In table~\ref{tab:siem1m1} the results obtained using the FAP PSO with velocity method 1. In table~\ref{tab:siem1m2} presents the results for the FAP PSO that used velocity method 2.
\begin{table}[H]
\centering
	\begin{tabular}{| c | c | c | c |}
	\hline
	GBest selection & Population & Interference\\ \hline
	Standard & 20 & 106.855\\ \hline
	Built with cells & 20 & 39.945\\ \hline
	Built with TRXs & 20 & 114.121\\ \hline
	Standard & 50 & 102.666\\ \hline
	Built with cells & 50 & \textbf{34.689}\\ \hline
	Built with TRXs & 50 & 116.150\\ \hline
	Standard & 100 & 104.649\\ \hline
	Built with cells & 100 & 38.252\\ \hline
	Built with TRXs & 100 & 126.630\\ \hline
	Standard & 500 & 106.132\\ \hline
	Built with cells & 500 & 44.171\\ \hline
	Built with TRXs & 500 & 118.911\\ \hline
	\end{tabular}
	\caption{Siemens1 results using velocity method 1}
	\label{tab:siem1m1}
\end{table}
\begin{table}[H]
\centering
	\begin{tabular}{| c | c | c | c |}
	\hline
	GBest selection & Population & Interference\\ \hline
	Standard & 20 & 817.161\\ \hline
	Built with cells & 20 & 336.102\\ \hline
	Built with TRXs & 20 & 312.120\\ \hline
	Standard & 50 & 637.030\\ \hline
	Built with cells & 50 & 258.049\\ \hline
	Built with TRXs & 50 & 217.247\\ \hline
	Standard & 100 & 517.347\\ \hline
	Built with cells & 100 & 252.827\\ \hline
	Built with TRXs & 100 & 197.421\\ \hline
	Standard & 500 & 272.717\\ \hline
	Built with cells & 500 & \textbf{123.427}\\ \hline
	Built with TRXs & 500 & 141.060\\ \hline
	\end{tabular}
	\caption{Siemens1 results with velocity method 2}
	\label{tab:siem1m2}
\end{table}
\subsection{Siemens2}
Below the results obtained by applying FAP PSO on the siemens2 benchmark is presented in table~\ref{tab:siem2m1} and table~\ref{tab:siem2m2}.
\begin{table}[H]
\centering
	\begin{tabular}{| c | c | c | c |}
	\hline
	GBest selection & Population & Interference\\ \hline
	Standard & 20 & 76.199\\ \hline
	Built with cells & 20 & 55.051\\ \hline
	Built with TRXs & 20 & 82.262\\ \hline
	Standard & 50 & 78.181\\ \hline
	Built with cells & 50 & 55.488\\ \hline
	Built with TRXs & 50 & 81.076\\ \hline
	Standard & 100 & 77.511\\ \hline
	Built with cells & 100 & 55.436\\ \hline
	Built with TRXs & 100 & 82.857\\ \hline
	Standard & 500 & 77.104\\ \hline
	Built with cells & 500 & \textbf{54.880}\\ \hline
	Built with TRXs & 500 & 86.794\\ \hline
	\end{tabular}
\caption{Siemens2 results with velocity method 1}
\label{tab:siem2m1}
\end{table}
\begin{table}[H]
\centering
	\begin{tabular}{| c | c | c | c |}
	\hline
	GBest selection & Population & Interference\\ \hline
	Standard & 20 & 217.025\\ \hline
	Built with cells & 20 & 316.679\\ \hline
	Built with TRXs & 20 & 111.535\\ \hline
	Standard & 50 & 240.186\\ \hline
	Built with cells & 50 & 197.572\\ \hline
	Built with TRXs & 50 & 103.896\\ \hline
	Standard & 100 & 228.486\\ \hline
	Built with cells & 100 & 195.921\\ \hline
	Built with TRXs & 100 & 100.298\\ \hline
	Standard & 500 & 236.228\\ \hline
	Built with cells & 500 & \textbf{96.605}\\ \hline
	Built with TRXs & 500 & 96.832\\ \hline
	\end{tabular}
\caption{Siemens2 results with velocity method 2}
\label{tab:siem2m2}
\end{table}
\subsection{Siemens3}
Table~\ref{tab:siem3m1} and table~\ref{tab:siem3m2} below present the results obtained by applying the FAP PSO algorithm to the siemens3 benchmark.
\begin{table}[H]
\centering
	\begin{tabular}{| c | c | c | c |}
	\hline
	GBest Selection & Population & Interference\\ \hline
	Standard & 20 & 135.078\\ \hline
	Built with cells & 20 & 50.543\\ \hline
	Built with TRXs & 20 & 141.538\\ \hline
	Standard & 50 & 138.418\\ \hline
	Built with cells & 50 & 51.300\\ \hline
	Built with TRXs & 50 & 144.444\\ \hline
	Standard & 100 & 138.774\\ \hline
	Built with cells & 100 & 50.652\\ \hline
	Built with TRXs & 100 & 157.552\\ \hline
	Standard & 500 & 141.105\\ \hline
	Built with cells & 500 & \textbf{54.417}\\ \hline
	Built with TRXs & 500 & 148.643\\ \hline
	\end{tabular}
\caption{Siemens3 result with velocity method 1}
\label{tab:siem3m1}
\end{table}
\begin{table}[H]
\centering
	\begin{tabular}{| c | c | c | c |}
	\hline
	GBest Selection & Population & Interference\\ \hline
	Standard & 20 & 1104.006\\ \hline
	Built with cells & 20 & 415.866\\ \hline
	Built with TRXs & 20 & 460.403\\ \hline
	Standard & 50 & 2197.760\\ \hline
	Built with cells & 50 & 1014.373\\ \hline
	Built with TRXs & 50 & 1182.665\\ \hline
	Standard & 100 & 764.894\\ \hline
	Built with cells & 100 & 311.646\\ \hline
	Built with TRXs & 100 & 316.998\\ \hline
	Standard & 500 & 361.118\\ \hline
	Built with cells & 500 & \textbf{167.185}\\ \hline
	Built with TRXs & 500 & 186.705\\ \hline
	\end{tabular}
\caption{Siemens3 result with velocity method 2}
\label{tab:siem3m2}
\end{table}
\subsection{Siemens 4}
\begin{table}[H]
\centering
	\begin{tabular}{| c | c | c | c |}
	\hline
	GBest Selection & Population & Interference\\ \hline
	Standard & 20 & 528.162\\ \hline
	Built with cells & 20 & 287.665\\ \hline
	Built with TRXs & 20 & 555.445\\ \hline
	Standard & 50 & 542.143\\ \hline
	Built with cells & 50 & \textbf{283.473}\\ \hline
	Built with TRXs & 50 & 557.154\\ \hline
	Standard & 100 & 541.617\\ \hline
	Built with cells & 100 & 293.238\\ \hline
	Built with TRXs & 100 & 551.930\\ \hline
	Standard & 500 & 538.812\\ \hline
	Built with cells & 500 & 302.441\\ \hline
	Built with TRXs & 500 & 582.992\\ \hline
	\end{tabular}
\caption{Siemens4 results using velocity method 1}
\label{tab:siem4m1}
\end{table}
\begin{table}[H]
\centering
	\begin{tabular}{| c | c | c | c |}
	\hline
	GBest Selection & Population & Interference\\ \hline
	Standard & 20 & 2300.40\\ \hline
	Built with cells & 20 & 1091.827\\ \hline
	Built with TRXs & 20 & 2966.514\\ \hline
	Standard & 50 & 1877.781\\ \hline
	Built with cells & 50 & 2197.760\\ \hline
	Built with TRXs & 50 & 1014.373\\ \hline
	Standard & 100 & 1182.665\\ \hline
	Built with cells & 100 & 814.950\\ \hline
	Built with TRXs & 100 & 930.631\\ \hline
	Standard & 500 & 1934.260\\ \hline
	Built with cells & 500 & \textbf{631.668}\\ \hline
	Built with TRXs & 500 & 723.772\\ \hline
	\end{tabular}
\caption{Siemens4 results using velocity method 2}
\label{tab:siem4m2}
\end{table}
\subsection{Comparison with best results in COST259}
Below the best results achieved by the FAP PSO is compared to the best results obtained with each siemens problem as published on the FAP website\cite{FAPWeb}.
\begin{table}[H]
\centering
	\begin{tabular}{| c | c | c | c | c |}
	\hline
	Algorithm & Siemens1 & Siemens2 & Siemens3 & Siemens4 \\ \hline
	FAP PSO & 34.689 & 54.880 & 54.417 & 283.473 \\ \hline
	k-thin FAP & \textbf{2.200} & \textbf{14.271} & \textbf{5.129} & \textbf{77.246} \\ \hline
	Dynamic Tabu Search & --- & 14.275 & 5.186 & 81.876 \\ \hline
	SAG FAP Tool & 2.301 & 14.751 & 5.259 & 80.967 \\ \hline
	\end{tabular}
\caption{FAP PSO results compared to best obtained results}
\label{tab:siem4m2}
\end{table}
\section{The Performance of the PSO}
In this section the effects of the changes made to the FAP PSO algorithm in terms of the results is discussed. 

Firstly, the effect of the two developed velocity methods in terms of the results is described. In section~\ref{sec:diffglobalschemes} the three global schemes that are used by the algorithm are discussed. Finally this section concludes with the effect of a larger population size on solution quality rather than a small population.
\subsection{Velocity Method 1 vs Method 2}
The FAP PSO algorithm is able to utilise two different velocity methods to move the swarm around in the FAP space. The algorithms that implement these two methods were presented in section~\ref{sec:velocityFAP} and section~\ref{sec:velocityFAP2}.

By analysing the results, it becomes abundantly clear that velocity method 1 is by far the superior method for moving in the problem space. In each of the results, when comparing end fitness values produced by algorithm variants that use method 1 one can easily come to the conclusion that method 1 performs better than method 2.

As discussed in chapter~\ref{chpt:psoapplicationFAP}, method 1 uses a stage-based approach when applying the velocity function whereas method 2 applies the velocity function as is without it being broken up. Based on the results, using a stage-based approach to apply the velocity function is far better than applying the velocity equation directly to the transceiver in the plan.

Method 1 works by moving the whole swarm through to each stage before applying the next stage in the velocity equation. Thus after each stage, the whole swarm is at the same phase of the equation which keeps the swarm structured.

With method 2, the whole velocity equation is applied to whatever value is exposed to be operated on. Thus when method 2 moves a particle the frequency plan is moved piece by piece to some destination in the problem space.

By applying the velocity equation it is difficult to control the algorithm search process. With the FAP PSO control is necessary as there are various constraints which must not only be avoided but also adhered to for the generated plan to be usable. With method 2 adding domain knowledge is difficult, since after the velocity equation has been calculated the particle is very close to being moved to a new position. All that still needs to be done, before a particle is moved, is to apply inertia, which means there is a little check that can be done to ensure that all the frequency values are within acceptable bounds.

By breaking the velocity equation up into smaller parts (stages) using method 1 the algorithm is able to direct and ensure that the swarm is moving in the general direction of valid frequency allocations.

Also the algorithm is able to embed domain knowledge earlier into the calculation of the velocity and is therefore able to intercept early on movements that will result in invalid frequency allocations at each stage of the velocity equation.

\subsection{Different Global Schemes}
\label{sec:diffglobalschemes}
In the previous chapter three global selection schemes were identified. The first global selection scheme uses the standard PSO selection and the particle with the best fitness is the global best. This scheme is called ``Standard GBest''.

As discussed in section~\ref{sec:buildglobalbest}, using the standard gbest selection scheme is not preferable as it can lead to the swarm losing out on good frequency allocations due to overshadowing of frequencies\footnote{Overshadowing is discussed in chapter~\ref{chpt:psoapplicationFAP}}.

Even with overshadowing the standard global scheme does not produce bad results, which seems to indicate that overshadowing of frequency allocations does not impact the frequency plans as significantly as thought initially.

In addition to the standard gbest selection scheme, two other selection schemes were tested. It is actually incorrect to call these schemes selection schemes of gbest, since they build global best rather than select them.

By far the worst performing scheme is where the global best is built from transceivers. In every benchmark performed where this scheme was paired with a velocity method and population size, the algorithm was simply not able to produce any relatively good solutions. All possible solutions had high interference values, making them undesirable.

The bad performance of the build from transceivers scheme can be attributed to the granularity it uses to build a global best. As outlined in section~\ref{sec:buildglobalbest} the scheme only considers the interference generated by a single frequency allocated to a transceiver. This would have worked well if there were some sort of guarantee that a particular transceiver would only be interfered with by one other transceiver.

In reality and in the Siemens4 benchmarks this is definitely not the case. More often than not, transceivers are interfered with by more than one other transceiver. Thus by only concentrating on a single case-by-case basis of frequencies allocated to transceivers, the scheme is discarding all other possible interferences. 

It might select a frequency at one point as the best, since in that scenario, the interference generated with the only other transceiver that is considered at that point is low. But this particular frequency is too close on the spectrum to another frequency allocated to some other transceiver that also interferes. Due to the algorithm only considering individual cases, this potential interference with the other transceiver will not be noticed by the algorithm and it will go ahead in selecting the frequency as the best for the transceiver.

By analysing the results produced by the various FAP PSO algorithms, it can be concluded that the best global best selection scheme is by far the one in which cells are used to build a global best. With the cell selection scheme, the algorithm does not suffer the pitfall that is the reason for the transceiver gbest building scheme's bad performance.

As discussed the build from cells scheme uses cells to build a gbest, and thus each cell stores the interference that the frequencies allocated to its transceivers generate by interfering with other cells. As a cell interferes with other cells, the interference generated is added to the cell causing the interference.

After the PSO has calculated the fitness of all positions, each cell will contain the interference it personally has caused throughout the network to other cells. A cell with low interference means the frequencies that have been allocated to this particular cell are the best combination which causes the least amount of interference. Therefore, with the build gbest from cells scheme, the algorithm is able to make informed choices when selecting a cell to be included in the global best. 
\subsection{Population Size}
As discussed in chapter~\ref{chpt:swarm} the population parameter of the PSO is a sensitive parameter. For problems with big search spaces, it is better to have a large population. A large population increases diversity, meaning more particles occupy different positions in the problem space and hence the space is better explored, which internally increases the likelyhood of finding a better solution. Thus, in the results the population size was also varied.

In the results using a larger population did not significantly improve the possible solutions. In only one benchmark, namely Siemens2, the algorithm was able to produce a better possible solution than an algorithm that used a lower population size. In Siemens1, Siemens3 and Siemens4 the algorithm using a lower population was able to produce the best overall results.

Due to the complexity of the FAP it is difficult to use the PSO with a large population. The algorithm's efficiency greatly decreased with the increase in population, taking significantly longer to iterate through the same number of iterations as the algorithms with lower populations. The decrease in efficiency was not unexpected due to the function evaluations, movements and considerations increasing fivefold over the lower population size. What was unexpected was the degree to which the efficiency degraded.
\section{Summary}
In this chapter the results produced by the algorithm discussed in chapter~\ref{chpt:psoapplicationFAP} were presented. The FAP PSO algorithm was applied to four COST 259 benchmarks namely Siemens1, Siemens2, Siemens3 and Siemens4. These four benchmarks were discussed in detail in chapter~\ref{chpt:fap}. For each of the benchmarks, 12 different variants of the FAP PSO algorithm were tested. Each variant used a different velocity function, global best selection scheme or population size. The chapter concluded with critical analyses of each of the different algorithms developed in this study to enable the PSO to operate in the FAP space.
%%% TEXEXPAND: END FILE ./chpt8.tex
%%% TEXEXPAND: INCLUDED FILE MARKER ./chpt9.tex
\chapter{Conclusion}
\label{chpt:conclusion}
\section{Introduction}
The aim of this dissertation was to develop a modern artificial intelligence optimisation algorithm which would be applied to a problem in the cellular technology domain. This aim was achieved: an algorithm was developed based on the standard PSO algorithm which was then applied to operate on the FAP. 

In current research no similar PSO algorithm to date has been presented that has been applied to the FS-FAP using interference as a performance measurement. In chapter~\ref{chpt:psoapplicationFAP} the innovation and new techniques that made it possible for an algorithm based on the PSO to operate in the FS-FAP domain were discussed.

\section{Research Questions}
At the start of the dissertation a series of research questions were outlined. These questions were identified and served as a roadmap to understand the problem domain as well as to gather enough background information on optimisation algorithmic techniques to allow innovation.

Six questions were identified in total. Each original question will now be listed together with a short discussion on how the question was answered and to which chapter it is related to.
\begin{itemize}
\item \textbf{Question 1} --- \emph{What is cellular technology, how was it got developed and what improvements have been made since its initial development?} This question was answered in chapter 2, which provided the history of cellular technology and also highlighted improvements that have been made since the inception of cellular networks.
\item \textbf{Question 2} --- \emph{What is the architecture behind a modern cellular network, how do the various hardware entities within a network communicate with each other and how is a communicational link established between two users of the network?} This question was answered in chapter 2 where the architecture of a modern-day cellular network was outlined and discussed in depth. Each entity used by the network to facilitate communication was identified and discussed in detail.
\item \textbf{Question 3} --- \emph{What exactly is the frequency problem and how does it affect modern wireless communication? } This question was answered in chapter 3, which contains a description of the general problem of the frequency assignment problem as well as exactly what happens in a cellular network for this problem to occur.
\item \textbf{Question 4} --- \emph{What variants of the frequency problem exist and which are most applicable to cellular networks?} The variants that currently exist in the problem domain were listed in chapter 3, together with their respective history and what domain they affect. The particular variant concentrated on in this dissertation concentrated on was formally stated. 
\item \textbf{Question 5} --- \emph{What are the most popular optimisation algorithms and what characteristics make them unique?} This question was answered in two chapters namely chapters 4 and 5. In these chapters the most popular and modern optimisation algorithms were evaluated.
\item \textbf{Question 6} --- \emph{With algorithms that achieved success in their respective optimisation problems, what particular technique is used by the algorithms that them it to achieve better performance?} Chapters 4 and 5 covered modern optimisation algorithms, which were also evaluated. Exactly what made the algorithm unique and allowed it to achieve success in the domain it was applied to was also dealt with
\end{itemize}

\section{Research Objective}
As stated in the introduction, the objective of this research was to determine whether it is viable and possible to apply a modern-day swarm-based algorithm to the frequency assignment problem. 

The question therefore is whether this research objective was achieved. The answer is yes. An algorithm based on the PSO algorithm was presented that operated on the frequency assignment problem. The only part still left is the viability of applying this algorithm to modern cellular networks.

Before the viability analysis is presented, the chapter breakdown in the introduction is revisited in the next section.

\section{Chapter Breakdown Revisited}
The chapter breakdown presented in the introduction is provided once more but with a summary of exactly what was discussed in each particular chapter.
\subsection{Part I - Background}
\subsubsection{Chapter 1}
This chapter provided an introduction to the research as well as a broad overview of the topics the dissertation discussed. 
\subsubsection{Chapter 2}
In this chapter a broad discussion was given on modern cellular technology, specifically the GSM cellular network technology. A brief history on how GSM was developed to be the most widely used cellular technology in use today was presented in section \ref{sec:gsmhistory}. This was followed by various GSM architecture entities.

A broad overview followed in section \ref{sec:gsminterfaces} on the various communication interfaces used between the various GSM entities to communicate with each other. The different GSM channels which are used on the interfaces to communicate information were covered.

The chapter concluded with the handover process which is used to allow an MS device to move freely geographically within the network. 
\subsubsection{Chapter 3}
The problem defined in this dissertation is the frequency assignment problem (FAP). The problem where the problem was categorised as being part of the set of NP-Complete problems. The NP-Complete nature of the problem is an important concept to understand.

Within the FAP domain there exists are different techniques when assigning frequencies, discussed in section \ref{sec:FreqAssignmentTypes}. 

The FAP is not just one problem but consists of various subproblems that have different goals for the resulting frequency plan. Some problems are concerned with the number of frequencies used, others are more concerned with the amount of interference that is generated on the network because of the assignment. The various FAP subproblems were outlined in section~\ref{sec:FAPVariants}.

A formal mathematical definition of the MI-FAP was also given. Finally, the chapter concluded with the various benchmark problems which are used to test the viability of frequency assignment algorithms.
\subsubsection{Chapter 4}
In this chapter a definition was given of what it means for an algorithm to be classified as metaheuristic and also what characteristics these algorithms must exhibit.

Three metaheuristic algorithms were discussed in this chapter. Each algorithm was accompanied by a flow chart depicting the general flow of the algorithm. How the algorithm works as well as the various characteristics that make the algorithm unique were described.

For each algorithm, a brief overview of literature using the particular algorithm was given as well as some of the disadvantages or challenges faced when applying the particular algorithm to the FAP.

\subsubsection{Chapter 5}
In this chapter a discussion was presented on three swarm intelligence algorithms. For each of the three algorithms a flow chart was given to allow the reader a more visual view of the operation of the algorithm. 

Each algorithm was analysed in detail to identify its strengths and the techniques it uses to achieve good results. Finally the algorithm was critically evaluated in the terms of being applied to the FAP.
\subsection{Part II - Implementation}
\subsubsection{Chapter 6}
In this chapter a series of mathematical optimisation problems were presented. Each problem was mathematically formulated as well as categorised as to whether the particular problem was multimodal and separable.
To get a better idea of how the particle swarm optimisation (PSO) algorithm operates and performs, two PSO algorithms were developed. Finally, this chapter concluded with the results obtained by the algorithms.
\subsubsection{Chapter 7}
This chapter contained an algorithm based on the standard PSO algorithm to operate on the FAP encountered in cellular networks.

All the various problems as well as how they were solved during the development of the main algorithm of this dissertation were described. For each new or old technique used by the algorithm pseudocode was given for a better idea of how the algorithm uses it.

The chapter concluded with small additions made to the algorithm to improve performance and, most important of all, improve solution quality.
\subsubsection{Chapter 8}
In this chapter results produced by the algorithm discussed in chapter~\ref{chpt:psoapplicationFAP} were presented. The FAP PSO algorithm was applied to four COST 259 benchmarks namely Siemens1, Siemens2, Siemens3 and Siemens4. These four benchmarks were discussed in detail in chapter~\ref{chpt:fap}. For each of the benchmarks, 12 different variants of the FAP PSO algorithm were tested. Each variant used a different velocity function, global best selection scheme or population size. The chapter concluded with a critical analysis of each of the different algorithms developed for this dissertation to enable the PSO to operate in the FAP space.
\subsection{The Conclusion}
In chapter~\ref{chpt:psoapplicationFAP} new velocity methods were created to enable the PSO swarm to move around in the problem space. To further improve the performance of the PSO additional techniques were developed.

The additional techniques were mainly concerned with how the gbest for the swarm is selected. The algorithms for these methods and techniques were also listed in the chapter. Not all the techniques used in the FAP PSO were entirely new; some techniques that were used can be easily identified like the use of tabu lists. Other techniques are a bit more difficult to identify. The building of the gbest actually borrows a concept used by ants in the ACO algorithm to build solutions. 

The FAP PSO algorithm uses random collision resolution when a particle position is already in the tabu list. The random collision resolution works by randomly selecting a new channel until it is found not to be tabu. This procedure is very similar to the mutation operation used by the GA algorithm.

In chapter~\ref{chpt:results} the results of the FAP PSO algorithm applied to the COST 259 Siemens benchmark were discussed. By critically evaluating the results one can conclude that the best performing PSO variant is the particular algorithm using the first developed velocity method, which utilises cells to build the global best. The results achieved by this variant of the algorithm greatly outweigh those of the other algorithms, but when compared with the best achieved in the literature the algorithm still has some way to go.

Being so far off the best achieved results in the literature is not surprising, as applying the PSO to the FS-FAP and to the COST 259 benchmark is a first. Nonetheless this research has shown that it is indeed viable to apply the PSO to the FS-FAP, and with more research it is possible that the PSO algorithm might be able to either come near the best presented results or actually improve upon them.

\section{Future Work}
Most of the techniques developed for the FAP PSO, aim to stay true to the standard PSO algorithm. The next step is to hybridise the FAP PSO algorithm. A good candidate for hybridisation would be the GA as the algorithm naturally ``purifies'' results in finding the right genes that make up a good possible solution.

In the PSO a good entry point for the GA to be incorporated would be twofold. The first point would be to take a certain global best selected with the standard procedure and then mate it with successive global bests, with the offspring global best being a best for a future iteration. With this method the PSO is able to use the history of the algorithm from the start.

The second method takes a swarm of a certain iteration and then mates all the particles with each other for a certain number of iterations. This method can be seen as a means to clean the swarm of inefficient genes and could serve as an intensification phase for the algorithm.

Another point of interest is to disregard the PSO and rather try and produce an ABC algorithm on the FS-FAP. As mentioned, the ABC algorithm was not chosen for this research, since it is new and has not been applied to a wide variety of problems. 

By using some of the techniques developed in this research for instance the selection schemes, a viable ABC algorithm could be developed. The ABC algorithm is not that specific as to how new solutions are generated, as with the PSO which relies on vector mathematics, which allows an algorithm designer considerably more freedom.





%%% TEXEXPAND: END FILE ./chpt9.tex
%\appendix
%\appendixpage
%\addappheadtotoc
%\include{apdxA}
\backmatter
\printglossaries
\bibliography{ReferenceDB}
\bibliographystyle{plain}
\end{document}
