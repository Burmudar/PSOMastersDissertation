\chapter{Metaheuristics Algorithms}

\section{Introduction}
Metaheuristics is a sub domain of the artificial intelligence domain. It evolved out of a need for more efficient search techniques with regard to hard problems. 

Metaheuristics forms part of a collective body of algorithms that use heuristics to search a particular domain's problem space, for the most optimal solution adhering to certain hard and soft constraints. Some of the most important Algorithms that form part of this collectivee body is:
\begin{itemize}
\item Tabu Search
\item Simulated Annealing
\item Genetic Algorithm
\end{itemize}
The above mentioned algorithms aren't the only algorithms to form part of this sub-domain, but they are the algorithms that have recieved the most attention in the literature and generally produce good results \cite{SweepMeta}.

In this chapter our main focus will be to discuss each of the above listed algorithms. We will start of by briefly discussing the characteristics of metaheuristic algorithms after which we will discuss each of the above algorithms in detail. We will also provide a literature study for each algorithm inorder for us to see how an algorithm needs to be changed and optimised for a particular problem domain. 

\section{Characteristics of Metaheuristics}
NP-Complete problems have been proven to not be solveble in polinomial time by traditional search methods such as A* search, Breath First Search and Depth-First Search. Metaheuristic algorihtms on the other hand are much more efficient in searching the problem space and produce much better results in a short amount of time. 

These algorihms are considered to be \emph{general-purpose} algorithsm and can thus be applied to a wide variety of optimization problems with only small modifications that need to made to the algorithm model\cite{MetaGraph}.

Metaheuristic Algorihtms do not search statically by testing and evalutating every possible permutation in the solution space. Instead these algorithms make use of certain strategies and heuristics (specific to the problem domain) to search the solution space intelligently through trail and error \cite{MetaAgricultural}. 

These algorithms iteratively move through the solution space, using a heuristic to guide the search to move to more desireable regions in the solution space where there is a high probability of obtaining high qaulity candidate solutions \cite{HeuristicManipulation,SweepMeta}.

Metaheuristic based search methods aren't gauranteed to find the most optimal solutions in the solution space, instead these methods are usually used to find near-optimal solutions. Thus most algorithmic development in the metaheuristic domain focus developing new techniques that will increase the probability that a good solution will be obtained in difficult combinatorial problems \cite{MetaAgricultural}.

Similarly, Metaheuristics aren't gauranteed to find ``good'' solutions or perform well in each problem domain it is applied. The quality of the solution and performance of the metaheuristic is very much depended on the expertise of the algorithm designer \cite{AutoComplexMeta}. 

The standard metaheuristic algorithms won't take advantage of specific domain knowledge to exploit the search domain and will produce relatively poor results. It is up to the algorithm designer to modify the algorithm sufficiently based on domain knowledge he/she as obtained\cite{AutoComplexMeta}.

Although heuristics play a key role in the performance of metauheuristic algorithms, it isn't the only factor that has an impact on performance and results.  Algorithms also use techniques and concepts from other system paradigms like multi-agent systems. 

In multi-agent systems, multiple agents have to communicate with each other and the system as a whole has to perform some sort of autonomous self-organization. This social and self-organization concepts enable these systems to be distrubuted,robust and flexible. Which is why in metaheuristic algorithms that are population-based,hybird and/or distributed these same concepts are used to beter exploit the solution space\cite{Self-AdaptiveMeta}.

Metaheuristics tend to slowly converge on an optimal solution, hence wasting valuable computing cycles. Therefore, a recent trend in research using metaheuristics for problem solving often pair the algorithms with local search methods to increase the convergeance rate of the algorithm to obtian a solution faster\cite{NonlinearGlobalTabu}.

In this section we introduced the characteristics of metaheuristics which sets these algorithms apart from the convential algorithms used on difficult problems. We gave a general overview on how solutions are obtained as well as the quality of solutions. We also briefly discussed why for each problem domain the algorithm used, must be changed to fit the domain. 

In the next section of this chapter we will discuss the Tabu Search metaheuristic which we are investigating.
\section{Tabu Search}
\subsection{Introduction}
Tabu Search (TS) was first proposed by Glover as a new searching technique to help algorithms avoid getting  stuck in local optima present in combinatorial and optimization problems \cite{TabuRCAProblem}. Since Glover introduced the algoritm in the 1980's, Tabu Search has been applied to a wide range of problems that include a wide variety of problems such as the Vehicle Routing Problem, Frequency assignment Problem, Capacitated-Lot Sizing Problem, Nurse Scheduling and the Resource Constrained Assignment Problem. Even though the problems mentioned differ by a large margin, the algorithm has been relatively successful in most of optimization problems it has been applied to. If we observe the results presented in the following research \cite{TabuCarryOver,TabuSingleMachineScheduling,TabuVechicleRoutingWithTimeWindows,TabuBiddingStrats,TabuCrewSchedulingProblem,ReactiveTabuVHR,TabuRCAProblem,TabuCSP,TabuMontemanniSmith,tabuglobalplanning3g} we can deduce that Tabu Search has on average obtained the best results compared to previous attempts with other algorithms. 

Tabu search resembles in its most basic form the Hill-climbing search algorithm, but it differs in the sense that Tabu Search keeps a memory of its recent moves in the solution space \cite{TabuBiddingStrats}. 

General search algorithsm like Hill-climbing, Random-restart or Scatter search tend to get stuck on local optima. The local optima might be a very attractive solution and thus general search algorithms will not move to beter solutions since according the algorihtms built in strategy it has found the best solution, but in actual fact its solution is the best it its \emph{local} search space but not in the \emph{global} search space. This is why an important charateristic that algorithms being applied on optimisation problems need to posess is breaking out of local optima.

In the next section we will explain what makes Tabu Search such a better algorithm that previous algorihtms and why it is able on average to produce better results.
\subsection{Algorithm and Data flow}
\begin{figure}[h]
	\centering
	\setlength \fboxsep{0pt}
	\setlength \fboxrule{0.5pt}
	\fbox{\includegraphics[width=3.0in]{./pictures/captainplaceholder.png}}
	\caption{Pseudo code for Tabu Search Algorithm}
	\label{fig:TSAlgorithmPseudoCode}
\end{figure}
\begin{figure}[htbp!]
	\centering
	\setlength \fboxsep{0pt}
	\setlength \fboxrule{0.5pt}
	\fbox{\includegraphics[width=3.8in,height=7.0in]{./pictures/captainplaceholder.png}}
	\caption{Placeholder for algorithm data flow diagram code}
	\label{fig:TSFlowDiagram}
\end{figure}
\subsection{Important Tabu Search characteristics}
In this section we will discuss some of the key characteristics and tehcniques that Tabu search exibits that enables it to find relatively good solutions in a short amount of time. We will start of briefly discussing how the start solution Tabu Search iteratively improves upon. After initial solution generation we will give an overview of research done on neighbourhood strategies for TS. One of the most important features of TS will be discussed in the memory structures section. Finally, we will finish of this section with a discussion on the two search phases present in TS.

\subsubsection{Initial Solution Generation}
The core feature of the TS algorithm is sequentially improving the initial solution \cite{TSHazardous}. Thus an important consideration to make is how initial solutions are generated for the TS to start on. Random initial solutions might seem to be a good starting point, but by introducing randomization it becomes hard to control the quality of the end solution. Hence the generation of starting solutions must be controlled to limit the infeasibility of potential soltuions \cite{TSHazardous}.

\subsubsection{Neighbourhood search}
Tabu Search uses a neighbourhood local search process to explore the solution space. There is no set process of how neighbourhoud candidate solutions are selected. Depending on the problem the TS is applied different neighborhoud solution selection strategies are needed. The overall quality of the solution produced by TS is also dependent on the neighbourhood search strategy used \cite{TSHazardous}. 

The TS algorithm isn't limited to just one neighbourhood search strategy. In the paper by Gopalakrishnan et al.\cite{TabuCarryOver} five neighbourhood move strategies are developed and are used interchangebly, in some cases a strategy is used three times in a row due to stagnation in the search space. However to combat this stagnation, the authors opted to use all the move strategies 15 percent of the time, and the last four moves strategies for 85 percent of the time when generating neighbourhood solutions.

Other neighbourhood strategies developed is one developed by N. A. Wassan \cite{ReactiveTabuVHR}. In the authors paper a neighbourhood selection strategy is used that exchanges route nodes from initial vehicle routes for the Vehicle Routing Problem. This route exchange enalbes the TS algorithm to search much more broadly due to the constant supply of different solutions. Since initial solutions are constantly modified it enables the TS procedure to be a very fined grained process, because often a small changes in a potential solution can have a big impact on the overall proposed solution by the TS algorithm.

In the research done by Zhang et. al \cite{TSHazardous} an interesting neighbourhood selection scheme called \emph{dynamic penalty} is discussed. When the algorithm moves onto an infeasible solution a penalty is imposed. By dynamically changing the penalty that is imposed the ``feasibility'' of solutions produced is influenced. Therefore, when and if the algorithm continually produces infeasible solutions, the penalty imposed is increased as to guide to algorithm to produce more feasible solutions. Finally, in the case when the algorithm is stuck on local optima, the penalty is reduced, which allows the algorithm to consider moving onto infeasible solutions thus escaping local optima.

Considering all the research done to develop new neighbourhoud selection strategies that improve Tabu Search to search the solution space more efficiently and produce better faster solutions, Tabu Search still has some draw-backs, especially with problems that have very large solution spaces \cite{EvoParallelTabu}.

Tabu Search is an iterative algorithm, executing a set of operation sequentially until a stopping criterion is met as can be seen in the flow-diagram presented earlier. At each iteration the algorithm has to determine feasibility of the immedaite neighbourhood candidate solutions \cite{EvoParallelTabu,TabuVechicleRoutingWithTimeWindows}. Therefore each candidate must be evaluated by some function, which may be a costly operation in terms of computational cycles as well as in terms of time. Hence, this constant evaluation can drastically reduce the overall performance of the algorithm, since it spending more time calculating feasibility than actually searching the solution space \cite{EvoParallelTabu,TabuVechicleRoutingWithTimeWindows}.

\subsubsection{Memory structures of Tabu Search}
The Hill-climbing and Random-restart algorithms are able to break out of local minima, but there is nothing stopping these algorithms from avoiding the local optima with their second or n-pass in the search space. Tabu Search differs from these algorihtms by incorporating an important concept; the notion of memory.

In its most basic form Tabu Search keeps a local memory of all its recent best moves, and puts them into a \emph{Tabu List} that has a predefined size. In the literature the tabu list is also refered to as the \emph{Tabu tenure} \cite{TSHazardous,TabuCarryOver,ReactiveTabuVHR,TabuParameterization}. The algorithm is not allowed to move to any solution that is in the tabu list unless a solution that is \emph{tabu} is better than any current moves available in the immediate search neighborhoud \cite{TSHazardous,TabuCarryOver,ReactiveTabuVHR,TabuParameterization}. The process of overriding a solutions tabu status in the tabu tenure is called the \emph{aspiration citerion} \cite{TSHazardous,TabuCarryOver,ReactiveTabuVHR,TabuParameterization}. With the use of the tabu tenure and the aspiration criterion, the algorithm is able to avoid cycling,local optima as well as searching in a to narrow region \cite{TabuSingleMachineScheduling,CircuitTabu}.

Research done by Ashish Sureka and Peter R. Wurman makes an important distinction with regard to the memory scheme that is used in the TS algorithm. Two memory schemes are discussed; \emph{explicit} memory and \emph{attribute-based memory} \cite{TabuBiddingStrats,TabuFormGames}. Between the two memory schemes the explicit memory scheme is the most used in the literature \cite{TabuVechicleRoutingWithTimeWindows}.

With explicit memory the algorithm stores a complete solution in the tabu tenure, hence the algorithm is porhibited to move to that position in the solution for as long as the solution is in the tabu tenure\cite{TabuBiddingStrats,TabuFormGames}. With attribute-based memory the algorithm stores the \emph{operation} the is used to move from the previous solution, to the current solution\cite{TabuBiddingStrats,TabuFormGames}. Therefore with attribute-based memory, the tabu tenure intended function is changed from prohibiting certain solutions already encountered, to rather prohibit making changes to the current solution that would lead to solutions already present in the tabu tenure \cite{TabuBiddingStrats,TabuFormGames}.

%Discuss LTM,MTM,STM --- In TabuCrewSchedulingProblem Page 4, Talk about STM and LTM, Cell Planning Tabu Search paper Page 3
In research conducted by D.M. Jaeggi and G.T. Parks and T. Kipouros and P.J. Clarkson, the authors add two addtional memory structures called \emph{Medium Term Memory} (MTM) and \emph{Long Term Memory} (LTM) besides the stardard Short Term Memory, typically refered to as the Tabu List \cite{MultiObjTabu} . Each addtional structure remembers a different set of solutions for use by the diversification and intensification phases in the algorithm. These two phases will be discussed in the next section.

STM purpose is similar to the traditional tabu list, to store the most recent solutions produced by the algorithm. MTM is designed to remember optimal or near optimal solutions. These solutions are therefore used later in the intensification phase. Finally, the LTM structure stores all the regions that the algorithm has already explored and is thus used in the diversification phase of the algorithm \cite{MultiObjTabu}.

\subsubsection{Search phases}
As Tabu Search searches through the solution space, it goes through two cycles of search phases called \emph{diversification} and \emph{intensification} \cite{TabuParameterization,TabuCrewSchedulingProblem,NonlinearGlobalTabu,SelfControllingReactiveTabu}.

The diversification phase in the TS algorithm, is the phase where the algorithm is directed to areas in the solution space which hasn't been explored yet. Diversification is usually applied by the algorithm as soon as mechanisms monitoring the memory, notice that solutions being produced are being repeated \cite{ReactiveTabuVHR,SelfControllingReactiveTabu}. 

In the literature diversification is achieved by new and innovative methods. A diversification strategy developed in research presented by Wassan \cite{ReactiveTabuVHR} dicusses a strategy called \emph{escape diversification} where the algorithm is taken out of its current position in solution space as soons as solutions are being repeated. 

In Research done by Fescioglu-Unver and Kokar \cite{SelfControllingReactiveTabu} a strategy is presented that consists of two components namely the \emph{Observer} and the \emph{Diversifier}. The goal of the Observer is to continually monitor the best solution obtained by the algorithm whether it violates the \emph{stagnation period}. The stagnation period is defined as the amount of iterations where the current best obtained solution hasn't changed \cite{SelfControllingReactiveTabu}. 

As soon as the stagnation peroid is exceeded by the algorithm the Observer component activates and transfers the nessecery information needed by the Diversifier component. The Diversifier component dynamically changes the size of the tabu tenure based on the information the Observer gathered. The diversifier mainly targets older moves to diversify, but for short burst of time it would decrease the tabu list size to a very small value in an attempt to combine new and old moves \cite{SelfControllingReactiveTabu}.

The specific mechanism used to define a new position where the algorithm can continue search, should ideally select areas in the solution space which have not been explored yet. Therefore, the diversification phase typically makes extensive use of the knowledge present in the long term memory structures as an indication to what areas of the solution space have been previously explored and which areas have not \cite{TabuParameterization,TabuCrewSchedulingProblem,NonlinearGlobalTabu,SelfControllingReactiveTabu}.

Intensification is usually the first phase of the Tabu Search algorithm, since it is responsible to build up a history in memory for which the diversification phase can act upon. Fescioglu-Unver and Kokar also presented a intensification strategy based on control theory in their research \cite{SelfControllingReactiveTabu}. The authors identified the repition length as a ciritcal value for their intensification strategy to be based upon. The repition length is a control measure that defines how many times a solution may be repeated.

Repition length was chosen because the authors observed through experimentation, that as solutions were repeated the algorithm was intensifying around a point in solution space. As the repition length was increased that algorithm is forced to find more diverse solutions thus moving away from the intesification point \cite{SelfControllingReactiveTabu}.

In this sub section we discussed the different phases of the Tabu Search algorithm. We discussed the intended purpose of each phase and presented some revelant research done in this area.

In this section we presented the pseudo code for the Tabu Search algorithm as well as presented a Flow diagram depicted when and why certain phases are activated in the algorithm. We then gave a overview of the core characteristics that are important for the Tabu Search algorithm. In the next section we will discuss Simulated annealing, where will start off by giving the pseudo code and flow diagram for the algorithm and end of the section by giving a overview on the core fearures of the algorithm.

\section{Simulated Annealing}
\subsection{Introduction}
Simulated Annealing (SA) is a heuristic search technique proposed in the 80's by Kirkpatrick to solve combinatorial optimisation problems. The technique is based on a natural process which is known in metallurgical as Annealing \cite{CurveFittingSA,SASingleMultiObj,TempCyclingSA,ChaosSA}. Kirkpatrick was the first to use the simulated annealing to solve optimisations problems but the basic algorithm structure was defined in by Metropolis et. al. in 1953 \cite{CurveFittingSA,VeryFastSAImageEnchancement}

Annealing is the natural process of crystalization when a solid is heated to a high temperature and then systematically cooled to a low temperature to reach a crystalized form \cite{CurveFittingSA,NewSAs,MobileRobotSA,ConstantTempSA}. This crystalized form of the solid is known the be the global minimum of the solids internal energy state. When the solid is rapidly cooled from a high temperature, the molecules have no time to reach a termaldynamic equilibrium stage \cite{CurveFittingSA,NewSAs,MobileRobotSA,ConstantTempSA}. Therefore, the molecules of the solid have high energy and the resultant structure has no real crystaline form, thus the solid energy is at a local minima \cite{CurveFittingSA,NewSAs,MobileRobotSA}. When the solid is slowly cooled in a controlled manner, the molecules are able to reach a thermal equilibrium at each temperature \cite{ChaosSA,CurveFittingSA,NewSAs,MobileRobotSA,ConstantTempSA}.

In the algorithm the energy state is the \emph{cost function} that needs to be minimised, and the molecules are the \emph{variables} which reperesent the solutions, and thus their state needs to be optimised to reach the desired energy state.

The following equation is the standard propability function that is used to determine when an uphill move performed by the algorithm. This function is known in the literature as the \emph{Metropolis Criterion}. 
\begin{equation}
	M_{AC} =
	\begin{cases}
	1, &\text{if $f(y) \leq f(x)$}\\
	exp(-\frac{\Delta E}{T_k}), &\text{otherwise}\\
	\end{cases}
\end{equation}
The function $f$ is the objective function or a function that determines the state of a given position in solution space\cite{EcoEquilSA}. The parameter $T_k$ is the temperature of the algorithm at iteration $k$ \cite{EcoEquilSA}. Finally, $\Delta E$ is the change in ``energy'' between two solutions $x$ and $y$ \cite{EcoEquilSA}.


The main purpose of the SA algorithm (like most optimization algorithms) is to minimize or maximise the cost function \cite{SASingleMultiObj}. This cost function typically evaluates a solutions desirebility compared to other solutions in the immediate \emph{neighborhoud} of the algorithms current position \cite{TheoPraticalSA}. Typically a neighboring solution is only selected as the new best state if its desirebility ranks hire than the current solution. When the algorithm moves to a beter solution from the previous solution, the move is typically refered in the literature as a \emph{downhill} move \cite{CurveFittingSA}.

The best state isn't always selected, in some case the algorithm is also able to move to solutions which are worse than the current solution. A worse solution is only selected based on some probability which is controlled by the \emph{annealing temperature} of the algorithm \cite{TheoPraticalSA}. At a high annealing temperature the probability that the algorithm will select a bad solution is very good. As the annealing temperature decreases so does the probability that a bad solution will be selected \cite{CurveFittingSA}. When the algorithm moves to a worse solution, the move is typically in the literature referred to as a \emph{uphill} move \cite{CurveFittingSA}. Uphill moves allows the algorithm to breakout of local minima and can lead the algorithm down a different path which may ultimately result in obtaining the global optimum \cite{SASingleMultiObj}. 

The SA algorithm is also very popular due to the basic structure of the algorithm being generic\cite{VariousCoolingSA}. Therefore, applying the algorithm to other problems is relatively trivial since only small changes are required. These changes usually need to applied to the \emph{Neighborhood selection} scheme and the \emph{Cooling Schedule}\cite{VariousCoolingSA,DormRoomSA}. Both of these concepts will be discussed in the next sub section.

In this subsection we gave a brief overview of the Simulated Annealing (SA) algorithm. We briefly discussed what the algorithm is based on and how the algorithm goes about searching the solution space. We also introduced some concepts like move probability selection and annealing temperature, which forms part of the core the algorithm. In the next section we will explain some of the concepts we've touched upon in this section as well as more advanced concepts that makes the algorithm unique.
\subsection{Algorithm and Data flow}
\begin{figure}[h]
	\centering
	\setlength \fboxsep{0pt}
	\setlength \fboxrule{0.5pt}
	\fbox{\includegraphics[width=3.0in,height=3.5in]{./pictures/captainplaceholder.png}}
	\caption{Pseudo code for Tabu Search Algorithm}
	\label{fig:SAAlgorithmPseudoCode}
\end{figure}
\begin{figure}[htbp!]
	\centering
	\setlength \fboxsep{0pt}
	\setlength \fboxrule{0.5pt}
	\fbox{\includegraphics[width=3.8in,height=7.0in]{./pictures/captainplaceholder.png}}
	\caption{Placeholder for algorithm data flow diagram code}
	\label{fig:SAFlowDiagram}
\end{figure}
\subsection{Important Simulated Annealing characteristics}
\subsubsection{Markov Chain}
The SA Algorithm is typically modelled by using Markov chains due to each Markov chain represents a set of trails that the algorithm has executed at the same temperature.  It has been proven with the use of Markov Chain theory that SA will find the global minimum in the solution space \cite{ClusterSA}. This proof is only valid when the following properties for the underlying Markov chian hold \cite{VeryFastSAImageEnchancement}:
\begin{itemize}
\item It must be irreducible
\item It mustn't be periodic
\item The detailed balance condition must hold
\end{itemize}
Due to the above proof the SA algorithm has been applied to a wide range of optimisation problems because as long as the algorithm designer can uphold these properties the find the global optimum. Even though the algorithm will find the global optimum, the algorithm is known to take a very long time to do so.
\subsubsection{Cooling Schedule}
The Cooling Schedule / Annealing Schedule is the most defining characteristic of the SA algorithm. It is the procedure where the natural annealing process is mimiced. The temperature of the SA algorithm is a control parameter that defines how much the algorithm moves around in the solution space.

In general, when the SA algorithm temperature has a very high value most solutions that are produced from the neighborhood are accepted \cite{ClusterSA}. Thus the algorithm moves freely in the solution space with little constraints. As the temperature decreases the probability that the algorithm will select bad or just any solution gets lower. When the temperature is very low, the SA algorithm is similar to a greedy algorithm in a sense that it only accepts downhill movements\cite{ClusterSA}.

In the literature there are three annealing schedules in common use are namely \emph{the logarithmic schedule}, the \emph{geometric schedule} and the \emph{Cauchy schedule}\cite{VeryFastSAImageEnchancement,SASingleMultiObj}. 

The standard and most common used schedule is commonly known as the logarithmic schedule and is based on Boltzmann annealing \cite{VeryFastSAImageEnchancement}. The main disadvantage of this schedule is that is slow due to its logarithmic nature \cite{VeryFastSAImageEnchancement}. It also requires that moves be generated from a Gaussian distribution \cite{SASingleMultiObj} for it to be able to reach the global minimum. The logarithmic annealing function has the following form:
\begin{equation}
	T_k = \frac{T_0}{ln(k)},\text{where k is the iteration value}\\
\end{equation}

The Cauchy schedule is faster than the logarithmic schedule. Similar to the logarithmic, this schedule also has a movement requirement. Moves must be generated from a Cauchy distribution for the algorithm to be able to reach the global minimum \cite{SASingleMultiObj,VeryFastSAImageEnchancement}. The Cauchy schedule is also typically referred to as Fast annealing. The schedule has the following form:
\begin{equation}
	T_k = \frac{T_0}{k}
\end{equation}

Finally, the fastest annealing schedule is known as the geometric or exponential annealing schedule \cite{SASingleMultiObj}. This schedule introduces the concept of \emph{reannealing}. Reannealing is a procedure by which all SA temperatures are rescaled \cite{VeryFastSAImageEnchancement}. This schedule has no move generation requirement to reach the global minimum, since there is no regious proof in the literature to prove it \cite{SASingleMultiObj}. The geometric schedule has the following form:
\begin{equation}
	T(i)=T_0exp(-C_i),\text{where C is a constant}
\end{equation}
\subsubsection{Initial temperature}
The initial temperature is a very important parameter to define in the SA algorithm, since it defines a point from which the cooling schedule will start of from. Therefore, depending on what the initial value of the temperature is the final result that the algorithm will produce can be influenced\cite{SALongestCommon,VariousCoolingSA,AutoConfigSA}.

When the initial temperature is set to a very high value the algorithm takes a long time reach a result. On the other hand if the initial temperature is set to a very low temperature the algorithm might converge to quickly and thus produce a result which may be the local minima\cite{SALongestCommon,VariousCoolingSA,AutoConfigSA}.

The initial temperature together with the cooling factor allows the algorithm designer to defines the time window for the algorithm to escape local minima, as well as the rate of convergence to an optimum solution\cite{SALongestCommon,VariousCoolingSA}.

A low initial temperature together with a small cooling factor makes the time window for the algorithm to leave a local optimum very small\cite{SALongestCommon}. With a high initial temperature and cooling factor value that is almost 1, the time window for the algorithm to leave the local optimum is much larger \cite{SALongestCommon}. 

When the algorithm is near a global optimum, a low initial temperature and low cooling factor will allow the algorithm to reach the optimum faster in the solution space. In contrast, if a high temperature and a very low cooling factor is used the algorithm will take longer to reach the optimum even tough it is near the global optimum\cite{SALongestCommon}.

\subsubsection{Move generation}
Most of the research done on the SA algorithm focuses on the annealing schedule and not so much on the move/solution/neighborhoud generation. Typically an initial solution is generated and then small changes are made to the solution to represent a new solution. The solution is said the be preturbed to the next solution. 

In research done by Tseung and Lin \cite{CurveFittingSA} a initial solution isn't modified but a move generation technique known as \emph{Pattern} search is used. Pattern search has two forms of movement namely the exploratory move and the patter move. The exploratory move continually changes the certain variables of a solution \cite{CurveFittingSA}. This is done so that it can rapidly find and identify a ``downhill'' move. The Pattern move uses the information gathered by the exploratory move to move towards the minimum of the function \cite{CurveFittingSA}.
\subsubsection{Algorithm efficiency}
The algorithm is also efficient with regards to CPU cycles when compared to the Genetic Algorithm because it only has to evaluate a certain number of moves each iteration, instead of a evaluating a whole population each iteration. Unlike Tabu Search the basic SA algorithm does not keep any memory and is therefore memory efficient, but in contrast suffers the risk that solution will cyclicing. Which is hwy the number of iterations spent at a temperature, since the longer the algorithm spends at a temperature the higher the probability is that solutions will cycle.
\section{Genetic Algorithm}
%Training Recurrent Neural Networks for Dynamic System Identification Using Parallel Tabu Search Algorithm Page 115
\subsection{Introduction}
\subsection{Algorithm and Data flow}
\subsection{Important Genetic Algorithm characteristics}

\section {Summary}
