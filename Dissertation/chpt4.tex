\chapter{Metaheuristics Algorithms}

\section{Introduction}
Metaheuristics is a sub domain of the artificial intelligence domain. It evolved out of a need for more efficient search techniques with regard to hard problems. 

Metaheuristics forms part of a collective body of algorithms that use heuristics to search a particular domain's problem space, for the most optimal solution adhering to certain hard and soft constraints. Some of the most important Algorithms that form part of this collectivee body is:
\begin{itemize}
\item Tabu Search
\item Simulated Annealing
\item Genetic Algorithm
\end{itemize}
The above mentioned algorithms aren't the only algorithms to form part of this sub-domain, but they are the algorithms that have recieved the most attention in the literature and generally produce good results \cite{SweepMeta}.

In this chapter our main focus will be to discuss each of the above listed algorithms. We will start of by briefly discussing the characteristics of metaheuristic algorithms after which we will discuss each of the above algorithms in detail. We will also provide a literature study for each algorithm inorder for us to see how an algorithm needs to be changed and optimised for a particular problem domain. 

\section{Characteristics of Metaheuristics}
NP-Complete problems have been proven to not be solveble in polinomial time by traditional search methods such as A* search, Breath First Search and Depth-First Search. Metaheuristic algorihtms on the other hand are much more efficient in searching the problem space and produce much better results in a short amount of time. 

These algorihms are considered to be \emph{general-purpose} algorithsm and can thus be applied to a wide variety of optimization problems with only small modifications that need to made to the algorithm model\cite{MetaGraph}.

Metaheuristic Algorihtms do not search statically by testing and evalutating every possible permutation in the solution space. Instead these algorithms make use of certain strategies and heuristics (specific to the problem domain) to search the solution space intelligently through trail and error \cite{MetaAgricultural}. 

These algorithms iteratively move through the solution space, using a heuristic to guide the search to move to more desireable regions in the solution space where there is a high probability of obtaining high qaulity candidate solutions \cite{HeuristicManipulation,SweepMeta}.

Metaheuristic based search methods aren't gauranteed to find the most optimal solutions in the solution space, instead these methods are usually used to find near-optimal solutions. Thus most algorithmic development in the metaheuristic domain focus developing new techniques that will increase the probability that a good solution will be obtained in difficult combinatorial problems \cite{MetaAgricultural}.

Similarly, Metaheuristics aren't gauranteed to find ``good'' solutions or perform well in each problem domain it is applied. The quality of the solution and performance of the metaheuristic is very much depended on the expertise of the algorithm designer \cite{AutoComplexMeta}. 

The standard metaheuristic algorithms won't take advantage of specific domain knowledge to exploit the search domain and will produce relatively poor results. It is up to the algorithm designer to modify the algorithm sufficiently based on domain knowledge he/she as obtained\cite{AutoComplexMeta}.

Although heuristics play a key role in the performance of metauheuristic algorithms, it isn't the only factor that has an impact on performance and results.  Algorithms also use techniques and concepts from other system paradigms like multi-agent systems. 

In multi-agent systems, multiple agents have to communicate with each other and the system as a whole has to perform some sort of autonomous self-organization. This social and self-organization concepts enable these systems to be distrubuted,robust and flexible. Which is why in metaheuristic algorithms that are population-based,hybird and/or distributed these same concepts are used to beter exploit the solution space\cite{Self-AdaptiveMeta}.

Metaheuristics tend to slowly converge on an optimal solution, hence wasting valuable computing cycles. Therefore, a recent trend in research using metaheuristics for problem solving often pair the algorithms with local search methods to increase the convergeance rate of the algorithm to obtian a solution faster\cite{NonlinearGlobalTabu}.

In this section we introduced the characteristics of metaheuristics which sets these algorithms apart from the convential algorithms used on difficult problems. We gave a general overview on how solutions are obtained as well as the quality of solutions. We also briefly discussed why for each problem domain the algorithm used, must be changed to fit the domain. 

In the next section of this chapter we will discuss the Tabu Search metaheuristic which we are investigating.
\section{Tabu Search}
\subsection{Introduction}
Tabu Search (TS) was first proposed by Glover as a new searching technique to help algorithms avoid getting  stuck in local optima present in combinatorial and optimization problems \cite{TabuRCAProblem}. Since Glover introduced the algoritm in the 1980's, Tabu Search has been applied to a wide range of problems that include a wide variety of problems such as:\cite{TabuVechicleRoutingWithTimeWindows}. Even though these problem differ by a large margin, the algorithm has been relatively successful in most of optimization problems it has been applied to. If we observe the results presented in the following research 1,2,3,4,5,6,7,8,10 we can deduce that Tabu Search has on average obtained the best results compared to previous attempts with other algorithms. 

Tabu search resembles in its most basic form the Hill-climbing search algorithm, but it differs in the sense that Tabu Search keeps a memory of its recent moves in the solution space \cite{TabuBiddingStrats}. 

General search algorithsm like Hill-climbing, Random-restart or Scatter search tend to get stuck on local optima. The local optima might be a very attractive solution and thus general search algorithms will not move to beter solutions since according the algorihtms built in strategy it has found the best solution, but in actual fact its solution is the best it its \emph{local} search space but not in the \emph{global} search space. This is why an important charateristic that algorithms being applied on optimisation problems need to posess is breaking out of local optima.

In the next section we will explain what makes Tabu Search such a better algorithm that previous algorihtms and why it is able on average to produce better results.

\subsection{Important Tabu Search characteristics}
In this section we will discuss some of the key characteristics and tehcniques that Tabu search exibits that enables it to find relatively good solutions in a short amount of time. We will start of briefly discussing how the start solution Tabu Search iteratively improves upon. After initial solution generation we will give an overview of research done on neighbourhood strategies for TS. One of the most important features of TS will be discussed in the memory structures section. Finally, we will finish of this section with a discussion on the two search phases present in TS.

\subsubsection{Initial Solution Generation}
The core feature of the TS algorithm is sequentially improving the initial solution \cite{TSHazardous}. Thus an important consideration to make is how initial solutions are generated for the TS to start on. Random initial solutions might seem to be a good starting point, but by introducing randomization it becomes hard to control the quality of the end solution. Hence the generation of starting solutions must be controlled to limit the infeasibility of potential soltuions \cite{TSHazardous}.

\subsubsection{Neighbourhood search}
Tabu Search uses a neighbourhood local search process to explore the solution space. There is no set process of how neighbourhoud candidate solutions are selected. Depending on the problem the TS is applied different neighborhoud solution selection strategies are needed. The overall quality of the solution produced by TS is also dependent on the neighbourhood search strategy used \cite{TSHazardous}. 

The TS algorithm isn't limited to just one neighbourhood search strategy. In the paper by Gopalakrishnan et al.\cite{TabuCarryOver} five neighbourhood move strategies are developed and are used interchangebly, in some cases a strategy is used three times in a row due to stagnation in the search space. However to combat this stagnation, the authors opted to use all the move strategies 15 percent of the time, and the last four moves strategies for 85 percent of the time when generating neighbourhood solutions.

Other neighbourhood strategies developed is one developed by N. A. Wassan \cite{ReactiveTabuVHR}. In the authors paper a neighbourhood selection strategy is used that exchanges route nodes from initial vehicle routes for the Vehicle Routing Problem. This route exchange enalbes the TS algorithm to search much more broadly due to the constant supply of different solutions. Since initial solutions are constantly modified it enables the TS procedure to be a very fined grained process, because often a small changes in a potential solution can have a big impact on the overall proposed solution by the TS algorithm.

In the research done by Zhang et. al \cite{TSHazardous} an interesting neighbourhood selection scheme called \emph{dynamic penalty} is discussed. When the algorithm moves onto an infeasible solution a penalty is imposed. By dynamically changing the penalty that is imposed the ``feasibility'' of solutions produced is influenced. Therefore, when and if the algorithm continually produces infeasible solutions, the penalty imposed is increased as to guide to algorithm to produce more feasible solutions. Finally, in the case when the algorithm is stuck on local optima, the penalty is reduced, which allows the algorithm to consider moving onto infeasible solutions thus escaping local optima.

Considering all the research done to develop new neighbourhoud selection strategies that improve Tabu Search to search the solution space more efficiently and produce better faster solutions, Tabu Search still has some draw-backs, especially with problems that have very large solution spaces \cite{EvoParallelTabu}.

Tabu Search is an iterative algorithm, executing a set of operation sequentially until a stopping criterion is met as can be seen in the flow-diagram presented earlier. At each iteration the algorithm has to determine feasibility of the immedaite neighbourhood candidate solutions \cite{EvoParallelTabu,TabuVechicleRoutingWithTimeWindows}. Therefore each candidate must be evaluated by some function, which may be a costly operation in terms of computational cycles as well as in terms of time. Hence, this constant evaluation can drastically reduce the overall performance of the algorithm, since it spending more time calculating feasibility than actually searching the solution space \cite{EvoParallelTabu,TabuVechicleRoutingWithTimeWindows}.

\subsubsection{Memory structures of Tabu Search}
The Hill-climbing and Random-restart algorithms are able to break out of local minima, but there is nothing stopping these algorithms from avoiding the local optima with their second or n-pass in the search space. Tabu Search differs from these algorihtms by incorporating an important concept; the notion of memory.

In its most basic form Tabu Search keeps a local memory of all its recent best moves, and puts them into a \emph{Tabu List} that has a predefined size. In the literature the tabu list is also refered to as the \emph{Tabu tenure} \cite{TSHazardous,TabuCarryOver,ReactiveTabuVHR,TabuParameterization}. The algorithm is not allowed to move to any solution that is in the tabu list unless a solution that is \emph{tabu} is better than any current moves available in the immediate search neighborhoud \cite{TSHazardous,TabuCarryOver,ReactiveTabuVHR,TabuParameterization}. The process of overriding a solutions tabu status in the tabu tenure is called the \emph{aspiration citerion} \cite{TSHazardous,TabuCarryOver,ReactiveTabuVHR,TabuParameterization}. With the use of the tabu tenure and the aspiration criterion, the algorithm is able to avoid cycling,local optima as well as searching in a to narrow region \cite{TabuSingleMachineScheduling,CircuitTabu}.

Research done by Ashish Sureka and Peter R. Wurman makes an important distinction with regard to the memory scheme that is used in the TS algorithm. Two memory schemes are discussed; \emph{explicit} memory and \emph{attribute-based memory} \cite{TabuBiddingStrats,TabuFormGames}. Between the two memory schemes the explicit memory scheme is the most used in the literature \cite{TabuVechicleRoutingWithTimeWindows}.

With explicit memory the algorithm stores a complete solution in the tabu tenure, hence the algorithm is porhibited to move to that position in the solution for as long as the solution is in the tabu tenure\cite{TabuBiddingStrats,TabuFormGames}. With attribute-based memory the algorithm stores the \emph{operation} the is used to move from the previous solution, to the current solution\cite{TabuBiddingStrats,TabuFormGames}. Therefore with attribute-based memory, the tabu tenure intended function is changed from prohibiting certain solutions already encountered, to rather prohibit making changes to the current solution that would lead to solutions already present in the tabu tenure \cite{TabuBiddingStrats,TabuFormGames}.

%Discuss LTM,MTM,STM --- In TabuCrewSchedulingProblem Page 4, Talk about STM and LTM, Cell Planning Tabu Search paper Page 3

\subsubsection{Search phases}
As Tabu Search searches through the solution space, it goes through two cycles of search phases called \emph{diversification} and \emph{intensification} \cite{TabuParameterization,TabuCrewSchedulingProblem,NonlinearGlobalTabu,SelfControllingReactiveTabu}.

The diversification phase in the TS algorithm, is the phase where the algorithm is directed to areas in the solution space which hasn't been explored yet. Diversification is usually applied by the algoruithm as soon as mechanisms monitoring the memory notice, that solutions being produced are being repeated \cite{ReactiveTabuVHR,SelfControllingReactiveTabu}. 

In the literature diversification is achieved by new and innovative methods. A diversification strategy developed in research presented by Wassan \cite{ReactiveTabuVHR} dicusses a strategy called \emph{escape diversification} where the algorithm is taken out of its current position in solution space as soons as solutions are being repeated. 

In Research done by Fescioglu-Unver and Kokar \cite{SelfControllingReactiveTabu} presents a strategy that consists of two components namely the \emph{Observer} and the \emph{Diversifier}. The goal of the Observer is to continually monitor the algorithm best obtained solution to check whether it violates the \emph{stagnation period}. The stagnation period is the amount of iterations where the current best obtained solution hasn't changed. 

As soon as the stagnation peroid is exceeded by the algorithm the Observer component activates and transfers the nessecery information need by the Diversifier component. The Diversifier component dynamically changes the size of the Tabu tenure based on the information the Observer gathered. The diversifier mainly targets older moves but for short burst of time it would decrease the tabu list size to a very small value in an attempt to combine new and old moves.

The specific mechanism used to define a new position where the algorithm can continue search, should ideally select solution spaces which have not been searched yet. Therefore, the diversification phase typically makes extensive use of the knowledge present in the long term memory structures as an indication where the algorithm has searched and not searched \cite{TabuParameterization,TabuCrewSchedulingProblem,NonlinearGlobalTabu,SelfControllingReactiveTabu}.

%Discuss Intensification and Diversification diversification reference in TabuParameterization, Page 5 TabuCrewSchedulingProblem, Tabu Search directed by direct search methods for nonlinear global optimization Page 1 and 2.

\subsection{A parallel adaptive tabu search approach}
A Tabu move applied to a current solution may appear attractive because it gives, for example, a solution better than the best found so far. We would like to accept the move in spite of its status by defining \emph{aspiration conditions}. Other advanced techniques may be implemented in a \emph{a long-term-memory} such as intensification to encourage the exploutation of a primising region in the search spacem and diversification to encourage the exploration of new regions.

\subsection{A Tabu Search Approach to Automated Map Generalisation}
Tabu serach can be viewed as an iterative technique that explores a set of feasible states by a sequence of moves. In general, the best move is taken at each iteration. However, to help prevent the search process from returning to a previous solution (called cycling), some moves are based on the short-term and long-term history of the sequence of movies that meet defined criteria. For example, one might classiffy a move as tabu if the reverse move has been made recently (with in a given number of iterations) or frequently (a given number of times). It may sometimes be desirable to make an otherwise tabu move; in order to achieve this, a particular implementation may include aspiration criteria that override the tbau status of particular moves. Such aspiration criteria might include a case which, by ignoring that a move is tabu, leads to a that is the best obtained so far.

\subsection{Methodology for Service Restoration based Adaptive-Selective Tabu Search}
Tabu Search is an efficient heuristic procedure applied in solution of optimization problems, which is projected to help other optimization methods or its components escape from local valley.

It is based on combing the hill climbing method of local search with the adaptive memory in order to make the search more flexible. Therefore, TS differs from other tehcniques that do not use memory procedures, as Simulated Annealing (SA) do is; or utilize the technique in a strict way, as branch and bound. The memory application is based on procedures presented as follows:
\begin{itemize}
\item Flexible attributes --- memory structes which enable the variation of the parpamters and search past history;
\item Associative adjusting mechanism --- interaction between exclusion and inclusion mechanism parameters;
\item Different Times Memory Function --- enables intensification and diversification search.
\end{itemize}

This method can be applied in various areas, that is, financial analysis, distribution power system, environment protection, logistic, etc., and has presented optimal or near optimal results. TS has two distinct strategies to use memory: short period memory, more aggressive, and long period one, used as a strategy for technique improvement.

\subsection{Hybrid simulated annealing algorithm based on adaptive cooling schedule for TSP}
It hasb nee seeen that tabu search algorithm uses short term memory of recently visisted solution known as tabu list to escape from local optima, but tabu list has a deterministic nature and thus cannot avoid cycling. This drawback of tabu search has been taken care of by SA in which stochastic characteristic avoid cycling. Because SA has no memory of recently visisted solutions, the rate of improvement of solutions is very slow. There is always a probability for the search to return to the same solution again. However, with the help of a short-term memory, the search can be restricted from retiring to a previously visisted solution and performance of SA can be enchanced significantly.

\subsection{Basic Algorithm}

\subsection{Literature study}

\section{Simulated Annealing}

\subsection{Basic Algorithm}

\subsection{Literature study}

\section{Genetic Algorithm}
%Training Recurrent Neural Networks for Dynamic System Identification Using Parallel Tabu Search Algorithm Page 115


\subsection{Basic Algorithm}

\subsection{Literature study}
\section {Summary}
